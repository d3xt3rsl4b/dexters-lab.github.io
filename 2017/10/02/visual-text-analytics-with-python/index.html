<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><title>Visual text Analytics with python - Tainted Bits</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Tainted Bits"><meta name="msapplication-TileImage" content="/images/logo-header.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Tainted Bits"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Due to the flourish of internet and accessibility of technology incredible platforms like social media, forums, etc have been created for knowledge sharing. Exchanging ideas is not confined to a geogr"><meta property="og:type" content="article"><meta property="og:title" content="Visual text Analytics with python"><meta property="og:url" content="https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/"><meta property="og:site_name" content="Tainted Bits"><meta property="og:description" content="Due to the flourish of internet and accessibility of technology incredible platforms like social media, forums, etc have been created for knowledge sharing. Exchanging ideas is not confined to a geogr"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/wordcloud_plot.png"><meta property="og:image" content="https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/lexical_dispersion_plot.png"><meta property="og:image" content="https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/frequency_distribution_plot.png"><meta property="og:image" content="https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/lexical_distribution_plot.png"><meta property="og:image" content="https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/word_length_distribution_plot.png"><meta property="og:image" content="https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/n-gram_frequency_distribution_plot.png"><meta property="article:published_time" content="2017-10-02T10:54:03.000Z"><meta property="article:modified_time" content="2021-03-11T10:27:20.929Z"><meta property="article:author" content="D3xt3r"><meta property="article:tag" content="Python"><meta property="article:tag" content="Visualization"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/2017/10/02/visual-text-analytics-with-python/wordcloud_plot.png"><meta property="twitter:creator" content="@0xd3xt3r"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/"},"headline":"Tainted Bits","image":["https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/wordcloud_plot.png","https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/lexical_dispersion_plot.png","https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/frequency_distribution_plot.png","https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/lexical_distribution_plot.png","https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/word_length_distribution_plot.png","https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/n-gram_frequency_distribution_plot.png"],"datePublished":"2017-10-02T10:54:03.000Z","dateModified":"2021-03-11T10:27:20.929Z","author":{"@type":"Person","name":"D3xt3r"},"description":"Due to the flourish of internet and accessibility of technology incredible platforms like social media, forums, etc have been created for knowledge sharing. Exchanging ideas is not confined to a geogr"}</script><link rel="alternate" href="/atom.xml" title="Tainted Bits" type="application/atom+xml"><link rel="icon" href="/images/logo-header.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/railscasts.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-128181439-1" async></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-128181439-1")</script><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/logo-header.png" alt="Tainted Bits" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/publications">Publication</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/0xd3xt3r"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time datetime="2017-10-02T10:54:03.000Z" title="10/2/2017, 4:24:03 PM">2017-10-02</time></span><span class="level-item">Updated&nbsp;<time datetime="2021-03-11T10:27:20.929Z" title="3/11/2021, 3:57:20 PM">2021-03-11</time></span><span class="level-item"><a class="link-muted" href="/categories/NLP/">NLP</a></span><span class="level-item">17 minutes read (About 2534 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Visual text Analytics with python</h1><div class="content"><p>Due to the flourish of internet and accessibility of technology incredible platforms like social media, forums, etc have been created for knowledge sharing. Exchanging ideas is not confined to a geographical area. Due to this volume and variety of content is generated in the form of images, video, text, etc. The amount of information is so much that it’s unmanageable to perceive it in bounded time, in such times area of text analytics has got the attention of people in the field of linguistics, business, etc. The goal of the post is to summarize few of the visual text analytical techniques that could help you in your initial phase of text mining or help you create a new feature for creating machine learning model. I will describe few online and offline tools that you could use to help you get started. By offline tools, I mean using python based software packages to created visualization and text pre-processing. Online tools will be web-browser based applications to which just have to paste the text or upload the text file to visualise the results.</p><span id="more"></span><h3 id="Visual-Text-Analytics"><a href="#Visual-Text-Analytics" class="headerlink" title="Visual Text Analytics"></a>Visual Text Analytics</h3><p>Exploratory text analysis can help us to get the gist of the text data. I am going to use python for the code example and for text processing. For text processing and text corpus I will be using nltk package and for visualization matplotlib package. There are also other packages that we will use as we progress.</p><ol><li><p><strong>WordCloud</strong>: one of the simplest visualization technique which is a type of word frequency visualization. The size of the word in the image is bigger for more frequent word and smaller for less frequent word. This type of visualization can be of help in initial query formation. There are some drawbacks like the longer word may occupy more space giving the impression of the frequent word than it actually is. It may not help us to compare two frequent words about their relationship can be misleading sometimes even if using two words together may make sense. Frequent words may not be meaningful. For generating word cloud I am going to use <strong>wordcloud</strong> package you can install the package from pip. Below is the code to generate cloud. Text dataset used is the US presidential inaugural addresses which are part of nltk.corpus package.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import the dataset</span></span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> inaugural</span><br><span class="line"><span class="comment"># extract the datataset in raw format, you can also extract it in other formats as well</span></span><br><span class="line">text = inaugural.raw()</span><br><span class="line">wordcloud = WordCloud(max_font_size=<span class="number">60</span>).generate(text)</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">12</span>))</span><br><span class="line"><span class="comment"># plot wordcloud in matplotlib</span></span><br><span class="line">plt.imshow(wordcloud, interpolation=<span class="string">&quot;bilinear&quot;</span>)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2017/10/02/visual-text-analytics-with-python/wordcloud_plot.png" title="wordcloud for US presidential inaugural addresses"></li><li><p><strong>Lexical dispersion plot</strong>: this is the plot of a word vs the offset of the word in the text corpus.The y-axis represents the word. Each word has a strip representing entire text in terms of offset, and a mark on the strip indicates the occurrence of the word at that offset, a strip is an x-axis. The positional information can indicate the focus of discussion in the text. So if you observe the plot below the words America, democracy and freedom occur more often at the end of the speeches and words like duties and some words have somewhat uniform distribution in the middle. This way we can conclude that as the speech started the focus was on duties but then focus shifted to America, democracy and freedom. Below is the code to reproduce the plot.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span>  nltk.book <span class="keyword">import</span> text4 <span class="keyword">as</span> inaugural_speeches</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">5</span>))</span><br><span class="line">topics = [<span class="string">&#x27;citizens&#x27;</span>, <span class="string">&#x27;democracy&#x27;</span>, <span class="string">&#x27;freedom&#x27;</span>, <span class="string">&#x27;duties&#x27;</span>, <span class="string">&#x27;America&#x27;</span>,<span class="string">&#x27;principle&#x27;</span>,<span class="string">&#x27;people&#x27;</span>, <span class="string">&#x27;Government&#x27;</span>]</span><br><span class="line">inaugural_speeches.dispersion_plot(topics)</span><br></pre></td></tr></table></figure><img src="/2017/10/02/visual-text-analytics-with-python/lexical_dispersion_plot.png" title="Lexical dispersion plot for US presidential anaugural addresses"></li><li><p><strong>Frequency distribution plot</strong>: this plot tries to communicate the frequency of the vocabulary in the text. Frequency distribution plot is word vs the frequency of the word. The frequency of the word can help us understand the topic of the corpus. Different genre of text can have a different set of frequent words, for example, If we have news corpus then sports news may have a different set of frequent words as compared to news related to politics, nltk has <strong>FreqDist</strong> class that helps to create a frequency distribution of the text corpus. The code below will find 5 most and least frequent words.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> brown</span><br><span class="line">topics = [<span class="string">&#x27;government&#x27;</span>, <span class="string">&#x27;news&#x27;</span>, <span class="string">&#x27;religion&#x27;</span>,<span class="string">&#x27;adventure&#x27;</span>,<span class="string">&#x27;hobbies&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> topic <span class="keyword">in</span> topics:</span><br><span class="line">    <span class="comment"># filter out stopwords and punctuation mark and only create array of words</span></span><br><span class="line">    words = [word <span class="keyword">for</span> word <span class="keyword">in</span> brown.words(categories=topic)</span><br><span class="line">            <span class="keyword">if</span> word.lower() <span class="keyword">not</span> <span class="keyword">in</span> stop_words <span class="keyword">and</span> word.isalpha() ]</span><br><span class="line">    freqdist = nltk.FreqDist(words)</span><br><span class="line">    <span class="comment"># print 5 most frequent words</span></span><br><span class="line">    print(topic,<span class="string">&#x27;more :&#x27;</span>, <span class="string">&#x27; , &#x27;</span>.join([ word.lower() <span class="keyword">for</span> word, count <span class="keyword">in</span> freqdist.most_common(<span class="number">5</span>)]))</span><br><span class="line">    <span class="comment"># print 5 least frequent words</span></span><br><span class="line">    print(topic,<span class="string">&#x27;less :&#x27;</span>, <span class="string">&#x27; , &#x27;</span>.join([ word.lower() <span class="keyword">for</span> word, count <span class="keyword">in</span> freqdist.most_common()[-<span class="number">5</span>:]]))</span><br></pre></td></tr></table></figure><p>output for above code is presented in the table format below. It will be surprising to see that in least frequent table words belonging to a category of text corpus are more informative compared to the words found in the most frequent table which is the core idea behind <strong>TF-IDF</strong> algorithm. Most frequent words convey little information about text compared to less frequent words.</p><p><strong>Most 5 Frequently occurring words</strong></p><table><thead><tr><th>government</th><th>news</th><th>religion</th><th>adventure</th><th>hobbies</th></tr></thead><tbody><tr><td>year</td><td>said</td><td>god</td><td>said</td><td>one</td></tr><tr><td>states</td><td>would</td><td>world</td><td>would</td><td>may</td></tr><tr><td>united</td><td>one</td><td>one</td><td>man</td><td>time</td></tr><tr><td>may</td><td>last</td><td>may</td><td>back</td><td>two</td></tr><tr><td>would</td><td>two</td><td>new</td><td>one</td><td>first</td></tr></tbody></table><p><strong>Least 5 Frequently occurring words</strong></p><table><thead><tr><th>government</th><th>news</th><th>religion</th><th>adventure</th><th>hobbies</th></tr></thead><tbody><tr><td>wage</td><td>macphail</td><td>habitable</td><td>sprinted</td><td>majestic</td></tr><tr><td>irregular</td><td>descendants</td><td>reckless</td><td>rug</td><td>draft</td></tr><tr><td>truest</td><td>jointly</td><td>mission</td><td>thundered</td><td>gourmets</td></tr><tr><td>designers</td><td>amending</td><td>descendants</td><td>meek</td><td>fastenings</td></tr><tr><td>qualities</td><td>plaza</td><td>suppose</td><td>jointly</td><td>fears</td></tr></tbody></table><p>The code below will plot frequency distribution for a government text, you can change the genre to see distribution for a different genre like try humor, new, etc.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get all words for government corpus</span></span><br><span class="line">corpus_genre = <span class="string">&#x27;government&#x27;</span></span><br><span class="line">words = [word <span class="keyword">for</span> word <span class="keyword">in</span> brown.words(categories=corpus_genre) <span class="keyword">if</span> word.lower() <span class="keyword">not</span> <span class="keyword">in</span> stop_words <span class="keyword">and</span> word.isalpha() ]</span><br><span class="line">freqdist = nltk.FreqDist(words)</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">5</span>))</span><br><span class="line">freqdist.plot(<span class="number">50</span>)</span><br></pre></td></tr></table></figure><img src="/2017/10/02/visual-text-analytics-with-python/frequency_distribution_plot.png" title="Frequency distribution plot for government genre of text in brown text corpus"></li><li><p><strong>Lexical diversity dispersion plot</strong>: lexical diversity lets us what is the percentage of the unique words in the text corpus for example if there are 100 words in the corpus and there are only 20 unique words then lexical diversity is 20/100=0.2. The formula for calculating lexical diversity is as below :<br>$$ \text{Lexical diversity(LD)}= \frac{\text{Number of unique words}}{\text{Number of words}} $$<br>Below is the python function to calculate the lexical diversity</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lexical_diversity</span>(<span class="params">text</span>):</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(<span class="built_in">len</span>(<span class="built_in">set</span>(text)) / <span class="built_in">len</span>(text),<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_brown_corpus_words</span>(<span class="params">category, include_stop_words=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;helper method to get word array for a particular category</span></span><br><span class="line"><span class="string">     of brown corpus which may/may not include the stopwords that can be toggled</span></span><br><span class="line"><span class="string">     with the include_stop_words flag in the function parameter&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">if</span> include_stop_words:</span><br><span class="line">        words = [word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> brown.words(categories=category) <span class="keyword">if</span> word.isalpha() ]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        words = [word.lower() <span class="keyword">for</span> word <span class="keyword">in</span> brown.words(categories=category)</span><br><span class="line">                 <span class="keyword">if</span> word.lower() <span class="keyword">not</span> <span class="keyword">in</span> stop_words <span class="keyword">and</span> word.isalpha() ]</span><br><span class="line">    <span class="keyword">return</span> words</span><br><span class="line"></span><br><span class="line"><span class="comment"># calculate and print lexical diversity for each genre of the brown corpus</span></span><br><span class="line"><span class="keyword">for</span> genre <span class="keyword">in</span> brown.categories():</span><br><span class="line">    lex_div_with_stop = lexical_diversity(get_brown_corpus_words(genre, <span class="literal">True</span>))</span><br><span class="line">    lex_div = lexical_diversity(get_brown_corpus_words(genre, <span class="literal">False</span>))</span><br><span class="line">    print(genre ,lex_div , lex_div_with_stop)</span><br></pre></td></tr></table></figure><p>The table below summarizing the result of the above code, humor category seems to have most lexical diversity followed by science fiction, government genre has the least diversity. If we remove the <strong>stopwords</strong> then the metric seems to change which is shown in the rightmost column in the table, metrics seems to get almost half.</p><blockquote><p>stopwords are extremely common words that have very little or of no valuable information like the, are, as, by, etc.</p></blockquote><table><thead><tr><th>Genre</th><th align="center">LD (with stopwords)</th><th align="center">LD (w/o stopwords)</th></tr></thead><tbody><tr><td>Humor</td><td align="center">0.49</td><td align="center">0.25</td></tr><tr><td>Science Fiction</td><td align="center">0.47</td><td align="center">0.24</td></tr><tr><td>Reviews</td><td align="center">0.39</td><td align="center">0.21</td></tr><tr><td>Religion</td><td align="center">0.32</td><td align="center">0.16</td></tr><tr><td>Editorial</td><td align="center">0.29</td><td align="center">0.16</td></tr><tr><td>Fiction</td><td align="center">0.28</td><td align="center">0.14</td></tr><tr><td>Adventure</td><td align="center">0.26</td><td align="center">0.13</td></tr><tr><td>Mystery</td><td align="center">0.26</td><td align="center">0.13</td></tr><tr><td>Romance</td><td align="center">0.26</td><td align="center">0.13</td></tr><tr><td>Hobbies</td><td align="center">0.25</td><td align="center">0.13</td></tr><tr><td>News</td><td align="center">0.24</td><td align="center">0.13</td></tr><tr><td>Lore</td><td align="center">0.24</td><td align="center">0.13</td></tr><tr><td>Government</td><td align="center">0.20</td><td align="center">0.11</td></tr><tr><td>Belles Lettres</td><td align="center">0.20</td><td align="center">0.10</td></tr><tr><td>Learned</td><td align="center">0.16</td><td align="center">0.09</td></tr></tbody></table><p>It would also be interesting to see how to lexical diversity changes in the corpus. To visualise this we can divide a text corpus into small chunks and calculate the diversity for that chuck and plot it. Corpus can be divided by sentence or we can consider each paragraph as chunks but for sake of simplicity we can consider a batch of 1000 words as a chunk and plot its lexical diversity. So x-axis is the chunk offset and y-axis is the lexical diversity of that chunk. Below is the code to plot lexical diversity distribution for different genre of brown text corpus</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> cat <span class="keyword">in</span> brown.categories():</span><br><span class="line">    plot_array = lexical_array(cat)</span><br><span class="line">    plt.plot(np.arange(<span class="number">0</span>,<span class="built_in">len</span>(plot_array))*<span class="number">5000</span>,plot_array,label=cat)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Word offset&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Lexical diversity&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2017/10/02/visual-text-analytics-with-python/lexical_distribution_plot.png" title="Lexical diversity distribution for different genre of brown text corpus"><p>Observing the plot we can conclude that some genre of text starts with less diversity and diversity increases as the corpus offset increases like learned. But for some genre, the lexical distribution is high on an average example is belles_letters vs learned category.</p></li><li><p><strong>Word length distribution plot</strong>: This plot is word length on x-axis vs number of words of that length on the y-axis. This plot helps to visualise the composition of different word length in the text corpus. Below is the code the achieve this</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cfd = nltk.ConditionalFreqDist(</span><br><span class="line">           (genre, <span class="built_in">len</span>(word))</span><br><span class="line">           <span class="keyword">for</span> genre <span class="keyword">in</span> brown.categories()</span><br><span class="line">           <span class="keyword">for</span> word <span class="keyword">in</span> get_brown_corpus_words(genre))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">8</span>))</span><br><span class="line">cfd.plot()</span><br></pre></td></tr></table></figure><img src="/2017/10/02/visual-text-analytics-with-python/word_length_distribution_plot.png" title="Word length distribution plot for different genre of brown text corpus"></li><li><p><strong>N-gram frequency distribution plot</strong>: n-grams is the continuous sequences of n words that occur very often for example for n=2 we are looking for 2 words that occur very often together like New York, Butter milk, etc. such pair of words are also called bigram, for n=3 its called trigram and so on. N-gram distribution plot tries to visualise distribution n-grams for different value of n, for this example, we consider n from 1 to 5. In the plot, x-axis has the different value of n and y-axis has the number of time n-gram sequence has occurred. Below is the code to plot the distribution plot.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.util <span class="keyword">import</span> ngrams</span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>,<span class="number">8</span>))</span><br><span class="line"><span class="keyword">for</span> genre <span class="keyword">in</span> brown.categories():</span><br><span class="line">    sol = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">6</span>):</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        fdist = nltk.FreqDist(ngrams(get_brown_corpus_words(genre), i))</span><br><span class="line">        sol.append(<span class="built_in">len</span>([cnt <span class="keyword">for</span> ng,cnt <span class="keyword">in</span> fdist.most_common() <span class="keyword">if</span> cnt &gt; <span class="number">1</span>]))</span><br><span class="line">    plt.plot(np.arange(<span class="number">1</span>,<span class="number">6</span>), sol, label=genre)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><img src="/2017/10/02/visual-text-analytics-with-python/n-gram_frequency_distribution_plot.png" title="n-gram frequency distribution plot for different genre of brown text corpus"></li></ol><h3 id="Online-tools"><a href="#Online-tools" class="headerlink" title="Online tools"></a>Online tools</h3><p>This section of the post is for those people who might feel lazy or just don’t want to code to get the work done, you could use some of the tools available online which require no coding skills. You just have to paste the text or upload the file to get nice visualization. Below is the list of few tools that I found to be useful.</p><ol><li><a target="_blank" rel="noopener" href="https://voyant-tools.org/">Voyant</a>: this app produces some of the above plots on a nice web dashboards. The plots which could be found are wordcloud, trend graph, etc. If you click on the word in the reader tab you will able to see all the sentence in which the word appears which can be very helpful to do some query based on words. There are also other metrics to explore, I would suggest you to explore the dashboard in detail.</li><li><a target="_blank" rel="noopener" href="http://textexture.com/">Visualize text as a network</a> : This tool visualises text as a graph, the details of the algorithms on how to produce the graph is published in<a target="_blank" rel="noopener" href="http://noduslabs.com/research/pathways-meaning-circulation-text-network-analysis/">this paper</a>. If you click on one node it will highlight all connected nodes. The words which we see on the nodes are called concepts and the concepts which are related are connected by edges.</li><li><a target="_blank" rel="noopener" href="https://books.google.com/ngrams">Google n-gram viewer</a>: Google has a very big corpus of books data which could be queried with this tool. What this tool give is the tread of words used in the books written in English and publish in the United States, for example, you can query trends in three n-grams from 1950 to 2000: “health care” (a 2-gram or bigram), “healthy” (a 1-gram or unigram), and “child care” (another bigram). In the chart y-axis shows all the bigrams word contained in the books, what percentage of them are “health care” or “child care”? Of all the unigrams, what percentage of them are “healthy”? you can see how the use of the words have changed over time if you are querying multiple words then you can compare their trends. There few advanced features of the Ngram Viewer, for those who want to dig a little deeper into phrase usage: wildcard search, inflection search, case-insensitive search, part-of-speech tags and n-gram compositions, more info on these features can be found on <a target="_blank" rel="noopener" href="https://books.google.com/ngrams/info">this link</a>.</li><li><a target="_blank" rel="noopener" href="http://corpus-tools.org/annis/">ANNIS</a>: is an open source, web browser-based search and visualization architecture for complex multi-layer linguistic corpora with diverse types of annotation. ANNIS, which stands for ANNotation of Information Structure. ANNIS addresses the need to concurrently annotate, query and visualise data from such varied areas as syntax, semantics, morphology, prosody, referentiality, lexis and more. For projects working with spoken language, support for audio/video annotations is also required. You can query large-scale dataset as ANNIS store data in Postgres which faster as compared to other storage formats like XML.</li><li><a target="_blank" rel="noopener" href="https://sourceforge.net/projects/txm/">TokenX</a>: is a free and open-source cross-platform Unicode &amp; XML based text/corpus analysis environment and graphical client, supporting Windows, Linux and Mac OS X. It can also be used online as a J2EE standard compliant web portal (GWT based) with access control built in.</li></ol><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Exploratory text analytics can be really simple as we saw, some basic visualization can help you to get a good understanding of the text corpus and also some of the metrics discussed above can help you to compare different text corpus in your dataset. We also discussed some online tools which can help you to dig deeper you can try analysing some of the datasets whose link I have posted in below play around which these tools.</p><h3 id="Useful-links"><a href="#Useful-links" class="headerlink" title="Useful links"></a>Useful links</h3><ol><li><a target="_blank" rel="noopener" href="https://github.com/0xd3xt3r/blog-code/blob/master/visual-text-analytics-with-python/Visual%20Text%20Analytics.ipynb">Ipython Notebook for above code samples</a></li><li><a target="_blank" rel="noopener" href="http://hci.stanford.edu/courses/cs448b/f11/lectures/CS448B-20111117-Text.pdf">Stanford lecture slides on text visualization</a></li><li><a target="_blank" rel="noopener" href="https://catalog.ldc.upenn.edu/LDC2006T13">Linguistic datasets</a></li><li><a target="_blank" rel="noopener" href="http://guides.library.ucla.edu/text">Collection of tools and datasets</a></li><li><a target="_blank" rel="noopener" href="http://norvig.com/ngrams/">Some more data set</a></li></ol></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Python/">Python</a><a class="link-muted mr-2" rel="tag" href="/tags/Visualization/">Visualization</a></div></article></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2017/10/14/handling-categorical-features-in-python/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Handling categorical features with python</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2017/09/25/implementing-knn-from-scratch-in-python/"><span class="level-item">Implementing K-NearestNeighbour algorithm from scratch in python</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config=function(){this.page.url="https://www.taintedbits.com/2017/10/02/visual-text-analytics-with-python/",this.page.identifier="2017/10/02/visual-text-analytics-with-python/"};!function(){var t=document,i=t.createElement("script");i.src="//taintedbits.disqus.com/embed.js",i.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(i)}()</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen order-1"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Visual-Text-Analytics"><span class="level-left"><span class="level-item">1</span><span class="level-item">Visual Text Analytics</span></span></a></li><li><a class="level is-mobile" href="#Online-tools"><span class="level-left"><span class="level-item">2</span><span class="level-item">Online tools</span></span></a></li><li><a class="level is-mobile" href="#Conclusion"><span class="level-left"><span class="level-item">3</span><span class="level-item">Conclusion</span></span></a></li><li><a class="level is-mobile" href="#Useful-links"><span class="level-left"><span class="level-item">4</span><span class="level-item">Useful links</span></span></a></li></ul></div></div><style>#toc .menu-list>li>a.is-active+.menu-list{display:block}#toc .menu-list>li>a+.menu-list{display:none}</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time datetime="2021-02-14T18:30:00.000Z">2021-02-15</time></p><p class="title"><a href="/2021/02/15/arm-architecture-webinar/">ARM Architecture and Shellcode Webinars</a></p><p class="categories"><a href="/categories/Binary-Exploitation/">Binary Exploitation</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2020-07-17T18:30:00.000Z">2020-07-18</time></p><p class="title"><a href="/2020/07/18/binary-exploitation-pwnable-tw-tcache-tear/">Binary Exploitation [pwnable.tw] - Tcache Tear</a></p><p class="categories"><a href="/categories/CTF-Writeups/">CTF Writeups</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2020-07-11T18:30:00.000Z">2020-07-12</time></p><p class="title"><a href="/2020/07/12/binary-exploitation-pwnable-tw-caov/">Binary Exploitation [pwnable.tw] - CAOV</a></p><p class="categories"><a href="/categories/CTF-Writeups/">CTF Writeups</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2020-07-10T18:30:00.000Z">2020-07-11</time></p><p class="title"><a href="/2020/07/11/binary-exploitation-pwnable-tw-spirited-away/">Binary Exploitation [pwnable.tw] - Spirited Away</a></p><p class="categories"><a href="/categories/CTF-Writeups/">CTF Writeups</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2020-07-04T18:30:00.000Z">2020-07-05</time></p><p class="title"><a href="/2020/07/05/binary-exploitation-pwnable-tw-realloc/">Binary Exploitation [pwnable.tw] - Realloc</a></p><p class="categories"><a href="/categories/CTF-Writeups/">CTF Writeups</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Binary-Exploitation/"><span class="level-start"><span class="level-item">Binary Exploitation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Brain-Logs/"><span class="level-start"><span class="level-item">Brain Logs</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CTF-Writeups/"><span class="level-start"><span class="level-item">CTF Writeups</span></span><span class="level-end"><span class="level-item tag">13</span></span></a></li><li><a class="level is-mobile" href="/categories/Exploitation/"><span class="level-start"><span class="level-item">Exploitation</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/IoT/"><span class="level-start"><span class="level-item">IoT</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Machine-Learning/"><span class="level-start"><span class="level-item">Machine Learning</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Malware-Analysis/"><span class="level-start"><span class="level-item">Malware Analysis</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Reverse-Engineering/"><span class="level-start"><span class="level-item">Reverse Engineering</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/ACS712/"><span class="tag">ACS712</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Arduino/"><span class="tag">Arduino</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bare-Metal/"><span class="tag">Bare-Metal</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CTF/"><span class="tag">CTF</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Chat-Bots/"><span class="tag">Chat Bots</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Wrangling/"><span class="tag">Data Wrangling</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dev/"><span class="tag">Dev</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dropper/"><span class="tag">Dropper</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ESP8266/"><span class="tag">ESP8266</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Editor/"><span class="tag">Editor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Emacs/"><span class="tag">Emacs</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Exploitation/"><span class="tag">Exploitation</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GandCrab/"><span class="tag">GandCrab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Grey-Energy/"><span class="tag">Grey Energy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Heap-Exploitation/"><span class="tag">Heap Exploitation</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kernel-Debugging/"><span class="tag">Kernel Debugging</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux-Malware/"><span class="tag">Linux Malware</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Malware-Analysis/"><span class="tag">Malware Analysis</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ROP/"><span class="tag">ROP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Regression/"><span class="tag">Regression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reverse-Engineering/"><span class="tag">Reverse Engineering</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Visualization/"><span class="tag">Visualization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WarGames/"><span class="tag">WarGames</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Windows-Malware/"><span class="tag">Windows Malware</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Windows-Reversing/"><span class="tag">Windows Reversing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/glibc/"><span class="tag">glibc</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/javascript-obfuscation/"><span class="tag">javascript obfuscation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pwnable/"><span class="tag">pwnable</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pwnable-kr/"><span class="tag">pwnable-kr</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pwnable-tw/"><span class="tag">pwnable-tw</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/radare2/"><span class="tag">radare2</span><span class="tag">4</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/logo-header.png" alt="Tainted Bits" height="28"></a><p class="is-size-7"><span>&copy; 2021 D3xt3r</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by-sa/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Subscribe" href="https://mailchi.mp/d744c1f04904/taintedbits"><i class="fa fa-envelope"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/0xd3xt3r"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en")</script><script>var IcarusThemeSettings={article:{highlight:{clipboard:!0,fold:"unfolded"}}}</script><script src="/js/column.js"></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load",()=>{"function"==typeof $.fn.lightGallery&&$(".article").lightGallery({selector:".gallery-item"}),"function"==typeof $.fn.justifiedGallery&&($(".justified-gallery > p > .gallery-item").length&&$(".justified-gallery > p > .gallery-item").unwrap(),$(".justified-gallery").justifiedGallery())})</script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now</a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load",(function(){outdatedBrowser({bgColor:"#f25648",color:"#ffffff",lowerThan:"object-fit"})}))</script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener("DOMContentLoaded",(function(){loadInsight({contentUrl:"/content.json"},{hint:"Type something...",untitled:"(Untitled)",posts:"Posts",pages:"Pages",categories:"Categories",tags:"Tags"})}))</script></body></html>